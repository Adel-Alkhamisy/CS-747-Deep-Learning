{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install gym pyvirtualdisplay\n",
    "# !sudo apt-get install -y xvfb python-opengl ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade setuptools --user\n",
    "# !pip3 install ez_setup \n",
    "# !pip3 install gym[atari] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import find_max_lives, check_live, get_frame, get_init_state\n",
    "from model import DQN\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -q gym[atari]\n",
    "# !pip install -q autorom[accept-rom-license]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "/home/aalkhami/miniconda3/envs/myenv/lib/python3.9/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/aalkhami/miniconda3/envs/myenv/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/aalkhami/miniconda3/envs/myenv/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/aalkhami/miniconda3/envs/myenv/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:137: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting a numpy array, actual type: <class 'tuple'>\u001b[0m\n",
      "  logger.warn(\n",
      "/home/aalkhami/miniconda3/envs/myenv/lib/python3.9/site-packages/gym/spaces/box.py:226: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "  logger.warn(\"Casting input x to numpy array.\")\n",
      "/home/aalkhami/miniconda3/envs/myenv/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:167: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space with exception: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space with exception: {e}\")\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('ALE/Breakout-v5')\n",
    "state = env.reset()\n",
    "#print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. \n",
    "\n",
    "In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('BreakoutDeterministic-v4')\n",
    "# state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aalkhami/miniconda3/envs/myenv/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "number_lives = find_max_lives(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3 #fire, left, and right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n",
    "\n",
    "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
    "\n",
    "__Frame__ : Number of frames processed in total.\n",
    "\n",
    "__Memory Size__ : The current size of the replay memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_dqn = False # set to True if using double DQN agent\n",
    "\n",
    "if double_dqn:\n",
    "    from agent_double import Agent\n",
    "else:\n",
    "    from agent import Agent\n",
    "\n",
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "memory_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_975387/1450953243.py:21: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 2.0   memory length: 198   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 1   score: 3.0   memory length: 445   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 2.5\n",
      "episode: 2   score: 0.0   memory length: 568   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6666666666666667\n",
      "episode: 3   score: 3.0   memory length: 815   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 4   score: 2.0   memory length: 1012   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 5   score: 2.0   memory length: 1210   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 6   score: 3.0   memory length: 1438   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 2.142857142857143\n",
      "episode: 7   score: 1.0   memory length: 1606   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 8   score: 5.0   memory length: 1913   epsilon: 1.0    steps: 307    lr: 0.0001     evaluation reward: 2.3333333333333335\n",
      "episode: 9   score: 2.0   memory length: 2111   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 2.3\n",
      "episode: 10   score: 3.0   memory length: 2339   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 2.3636363636363638\n",
      "episode: 11   score: 1.0   memory length: 2511   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 2.25\n",
      "episode: 12   score: 3.0   memory length: 2757   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 2.3076923076923075\n",
      "episode: 13   score: 4.0   memory length: 3016   epsilon: 1.0    steps: 259    lr: 0.0001     evaluation reward: 2.4285714285714284\n",
      "episode: 14   score: 1.0   memory length: 3188   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 2.3333333333333335\n",
      "episode: 15   score: 0.0   memory length: 3311   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 2.1875\n",
      "episode: 16   score: 1.0   memory length: 3480   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 2.1176470588235294\n",
      "episode: 17   score: 1.0   memory length: 3649   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 2.0555555555555554\n",
      "episode: 18   score: 1.0   memory length: 3800   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 19   score: 2.0   memory length: 4018   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 2.0\n",
      "episode: 20   score: 3.0   memory length: 4265   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 2.0476190476190474\n",
      "episode: 21   score: 2.0   memory length: 4452   epsilon: 1.0    steps: 187    lr: 0.0001     evaluation reward: 2.0454545454545454\n",
      "episode: 22   score: 0.0   memory length: 4574   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.9565217391304348\n",
      "episode: 23   score: 2.0   memory length: 4792   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.9583333333333333\n",
      "episode: 24   score: 0.0   memory length: 4914   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.88\n",
      "episode: 25   score: 1.0   memory length: 5085   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.8461538461538463\n",
      "episode: 26   score: 0.0   memory length: 5208   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7777777777777777\n",
      "episode: 27   score: 1.0   memory length: 5377   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 28   score: 3.0   memory length: 5602   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.793103448275862\n",
      "episode: 29   score: 2.0   memory length: 5821   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 30   score: 0.0   memory length: 5943   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7419354838709677\n",
      "episode: 31   score: 4.0   memory length: 6257   epsilon: 1.0    steps: 314    lr: 0.0001     evaluation reward: 1.8125\n",
      "episode: 32   score: 0.0   memory length: 6379   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7575757575757576\n",
      "episode: 33   score: 0.0   memory length: 6502   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7058823529411764\n",
      "episode: 34   score: 1.0   memory length: 6673   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6857142857142857\n",
      "episode: 35   score: 2.0   memory length: 6873   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.6944444444444444\n",
      "episode: 36   score: 0.0   memory length: 6996   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6486486486486487\n",
      "episode: 37   score: 0.0   memory length: 7119   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.605263157894737\n",
      "episode: 38   score: 1.0   memory length: 7270   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.5897435897435896\n",
      "episode: 39   score: 3.0   memory length: 7539   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.625\n",
      "episode: 40   score: 2.0   memory length: 7737   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6341463414634145\n",
      "episode: 41   score: 2.0   memory length: 7935   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6428571428571428\n",
      "episode: 42   score: 0.0   memory length: 8058   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6046511627906976\n",
      "episode: 43   score: 1.0   memory length: 8227   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5909090909090908\n",
      "episode: 44   score: 0.0   memory length: 8349   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5555555555555556\n",
      "episode: 45   score: 1.0   memory length: 8517   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.5434782608695652\n",
      "episode: 46   score: 2.0   memory length: 8720   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.553191489361702\n",
      "episode: 47   score: 3.0   memory length: 8968   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.5833333333333333\n",
      "episode: 48   score: 2.0   memory length: 9165   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.5918367346938775\n",
      "episode: 49   score: 2.0   memory length: 9383   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 50   score: 1.0   memory length: 9552   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.588235294117647\n",
      "episode: 51   score: 3.0   memory length: 9777   epsilon: 1.0    steps: 225    lr: 0.0001     evaluation reward: 1.6153846153846154\n",
      "episode: 52   score: 3.0   memory length: 10023   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.6415094339622642\n",
      "episode: 53   score: 3.0   memory length: 10270   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.6666666666666667\n",
      "episode: 54   score: 0.0   memory length: 10393   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6363636363636365\n",
      "episode: 55   score: 2.0   memory length: 10591   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6428571428571428\n",
      "episode: 56   score: 0.0   memory length: 10714   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6140350877192982\n",
      "episode: 57   score: 2.0   memory length: 10913   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.6206896551724137\n",
      "episode: 58   score: 0.0   memory length: 11036   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5932203389830508\n",
      "episode: 59   score: 3.0   memory length: 11285   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.6166666666666667\n",
      "episode: 60   score: 9.0   memory length: 11632   epsilon: 1.0    steps: 347    lr: 0.0001     evaluation reward: 1.7377049180327868\n",
      "episode: 61   score: 3.0   memory length: 11880   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.7580645161290323\n",
      "episode: 62   score: 0.0   memory length: 12003   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7301587301587302\n",
      "episode: 63   score: 5.0   memory length: 12329   epsilon: 1.0    steps: 326    lr: 0.0001     evaluation reward: 1.78125\n",
      "episode: 64   score: 0.0   memory length: 12451   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7538461538461538\n",
      "episode: 65   score: 0.0   memory length: 12573   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7272727272727273\n",
      "episode: 66   score: 4.0   memory length: 12891   epsilon: 1.0    steps: 318    lr: 0.0001     evaluation reward: 1.7611940298507462\n",
      "episode: 67   score: 0.0   memory length: 13014   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7352941176470589\n",
      "episode: 68   score: 1.0   memory length: 13183   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.7246376811594204\n",
      "episode: 69   score: 3.0   memory length: 13446   epsilon: 1.0    steps: 263    lr: 0.0001     evaluation reward: 1.7428571428571429\n",
      "episode: 70   score: 9.0   memory length: 13843   epsilon: 1.0    steps: 397    lr: 0.0001     evaluation reward: 1.8450704225352113\n",
      "episode: 71   score: 3.0   memory length: 14089   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.8611111111111112\n",
      "episode: 72   score: 3.0   memory length: 14336   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.8767123287671232\n",
      "episode: 73   score: 2.0   memory length: 14533   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.8783783783783783\n",
      "episode: 74   score: 2.0   memory length: 14731   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.88\n",
      "episode: 75   score: 0.0   memory length: 14853   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.855263157894737\n",
      "episode: 76   score: 2.0   memory length: 15033   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.8571428571428572\n",
      "episode: 77   score: 1.0   memory length: 15185   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.8461538461538463\n",
      "episode: 78   score: 2.0   memory length: 15367   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.8481012658227849\n",
      "episode: 79   score: 1.0   memory length: 15518   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.8375\n",
      "episode: 80   score: 0.0   memory length: 15641   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.8148148148148149\n",
      "episode: 81   score: 1.0   memory length: 15791   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.8048780487804879\n",
      "episode: 82   score: 1.0   memory length: 15941   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.7951807228915662\n",
      "episode: 83   score: 2.0   memory length: 16139   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.7976190476190477\n",
      "episode: 84   score: 2.0   memory length: 16354   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 85   score: 0.0   memory length: 16477   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7790697674418605\n",
      "episode: 86   score: 0.0   memory length: 16600   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7586206896551724\n",
      "episode: 87   score: 4.0   memory length: 16895   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.7840909090909092\n",
      "episode: 88   score: 0.0   memory length: 17018   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7640449438202248\n",
      "episode: 89   score: 0.0   memory length: 17141   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7444444444444445\n",
      "episode: 90   score: 0.0   memory length: 17264   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.7252747252747254\n",
      "episode: 91   score: 2.0   memory length: 17482   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.7282608695652173\n",
      "episode: 92   score: 2.0   memory length: 17680   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.7311827956989247\n",
      "episode: 93   score: 2.0   memory length: 17878   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.7340425531914894\n",
      "episode: 94   score: 2.0   memory length: 18077   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.736842105263158\n",
      "episode: 95   score: 2.0   memory length: 18274   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.7395833333333333\n",
      "episode: 96   score: 1.0   memory length: 18443   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.731958762886598\n",
      "episode: 97   score: 3.0   memory length: 18688   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.7448979591836735\n",
      "episode: 98   score: 1.0   memory length: 18838   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.7373737373737375\n",
      "episode: 99   score: 3.0   memory length: 19103   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 100   score: 3.0   memory length: 19332   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 101   score: 2.0   memory length: 19550   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 102   score: 1.0   memory length: 19721   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 103   score: 1.0   memory length: 19889   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 104   score: 2.0   memory length: 20086   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 105   score: 1.0   memory length: 20254   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 106   score: 1.0   memory length: 20405   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 107   score: 0.0   memory length: 20527   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 108   score: 0.0   memory length: 20650   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 109   score: 1.0   memory length: 20801   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 110   score: 3.0   memory length: 21049   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 111   score: 0.0   memory length: 21172   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 112   score: 1.0   memory length: 21324   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 113   score: 3.0   memory length: 21592   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 114   score: 1.0   memory length: 21763   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 115   score: 2.0   memory length: 21943   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 116   score: 5.0   memory length: 22245   epsilon: 1.0    steps: 302    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 117   score: 3.0   memory length: 22474   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 118   score: 2.0   memory length: 22694   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 119   score: 1.0   memory length: 22863   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 120   score: 0.0   memory length: 22985   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 121   score: 2.0   memory length: 23165   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 122   score: 2.0   memory length: 23385   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 123   score: 2.0   memory length: 23567   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 124   score: 2.0   memory length: 23765   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 125   score: 1.0   memory length: 23933   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 126   score: 1.0   memory length: 24101   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 127   score: 2.0   memory length: 24298   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 128   score: 0.0   memory length: 24421   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 129   score: 0.0   memory length: 24544   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 130   score: 0.0   memory length: 24667   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 131   score: 3.0   memory length: 24910   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 132   score: 5.0   memory length: 25238   epsilon: 1.0    steps: 328    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 133   score: 2.0   memory length: 25457   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 134   score: 2.0   memory length: 25655   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 135   score: 4.0   memory length: 25917   epsilon: 1.0    steps: 262    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 136   score: 2.0   memory length: 26115   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 137   score: 1.0   memory length: 26285   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 138   score: 1.0   memory length: 26456   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 139   score: 3.0   memory length: 26683   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 140   score: 1.0   memory length: 26851   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 141   score: 1.0   memory length: 27001   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 142   score: 1.0   memory length: 27170   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 143   score: 1.0   memory length: 27339   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 144   score: 2.0   memory length: 27556   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 145   score: 2.0   memory length: 27737   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 146   score: 2.0   memory length: 27935   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 147   score: 1.0   memory length: 28106   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 148   score: 2.0   memory length: 28289   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 149   score: 2.0   memory length: 28506   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 150   score: 3.0   memory length: 28773   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 151   score: 3.0   memory length: 29020   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 152   score: 1.0   memory length: 29189   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 153   score: 4.0   memory length: 29486   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 154   score: 3.0   memory length: 29733   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 155   score: 1.0   memory length: 29903   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 156   score: 3.0   memory length: 30131   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 157   score: 1.0   memory length: 30282   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 158   score: 1.0   memory length: 30434   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 159   score: 3.0   memory length: 30679   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 160   score: 1.0   memory length: 30830   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 161   score: 2.0   memory length: 31047   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 162   score: 2.0   memory length: 31249   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 163   score: 4.0   memory length: 31565   epsilon: 1.0    steps: 316    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 164   score: 5.0   memory length: 31896   epsilon: 1.0    steps: 331    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 165   score: 1.0   memory length: 32048   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 166   score: 3.0   memory length: 32292   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 167   score: 0.0   memory length: 32415   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 168   score: 1.0   memory length: 32565   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 169   score: 1.0   memory length: 32734   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 170   score: 1.0   memory length: 32902   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 171   score: 2.0   memory length: 33120   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 172   score: 0.0   memory length: 33243   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 173   score: 1.0   memory length: 33393   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 174   score: 0.0   memory length: 33516   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 175   score: 2.0   memory length: 33714   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 176   score: 2.0   memory length: 33913   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 177   score: 1.0   memory length: 34064   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 178   score: 1.0   memory length: 34233   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 179   score: 0.0   memory length: 34356   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 180   score: 2.0   memory length: 34553   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 181   score: 1.0   memory length: 34722   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 182   score: 1.0   memory length: 34890   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 183   score: 2.0   memory length: 35106   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 184   score: 1.0   memory length: 35256   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 185   score: 0.0   memory length: 35379   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 186   score: 0.0   memory length: 35502   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 187   score: 1.0   memory length: 35671   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 188   score: 1.0   memory length: 35842   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 189   score: 2.0   memory length: 36039   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 190   score: 2.0   memory length: 36238   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 191   score: 1.0   memory length: 36406   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 192   score: 2.0   memory length: 36604   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 193   score: 0.0   memory length: 36727   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 194   score: 2.0   memory length: 36929   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 195   score: 1.0   memory length: 37098   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 196   score: 1.0   memory length: 37267   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 197   score: 2.0   memory length: 37465   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 198   score: 3.0   memory length: 37693   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 199   score: 0.0   memory length: 37815   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 200   score: 0.0   memory length: 37938   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 201   score: 4.0   memory length: 38198   epsilon: 1.0    steps: 260    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 202   score: 1.0   memory length: 38349   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 203   score: 1.0   memory length: 38518   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 204   score: 3.0   memory length: 38768   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 205   score: 2.0   memory length: 38965   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 206   score: 2.0   memory length: 39148   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 207   score: 1.0   memory length: 39316   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 208   score: 2.0   memory length: 39533   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 209   score: 3.0   memory length: 39782   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 210   score: 1.0   memory length: 39952   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 211   score: 3.0   memory length: 40196   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 212   score: 3.0   memory length: 40464   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 213   score: 1.0   memory length: 40632   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 214   score: 2.0   memory length: 40830   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 215   score: 3.0   memory length: 41096   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 216   score: 1.0   memory length: 41266   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 217   score: 1.0   memory length: 41434   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 218   score: 0.0   memory length: 41556   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 219   score: 1.0   memory length: 41728   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 220   score: 3.0   memory length: 41974   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 221   score: 1.0   memory length: 42145   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 222   score: 0.0   memory length: 42268   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 223   score: 2.0   memory length: 42466   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 224   score: 3.0   memory length: 42712   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 225   score: 3.0   memory length: 42938   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 226   score: 1.0   memory length: 43107   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 227   score: 1.0   memory length: 43258   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 228   score: 0.0   memory length: 43380   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 229   score: 3.0   memory length: 43611   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 230   score: 2.0   memory length: 43809   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 231   score: 2.0   memory length: 44028   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 232   score: 0.0   memory length: 44151   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 233   score: 1.0   memory length: 44320   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 234   score: 3.0   memory length: 44564   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 235   score: 1.0   memory length: 44733   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 236   score: 1.0   memory length: 44904   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 237   score: 2.0   memory length: 45101   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 238   score: 2.0   memory length: 45318   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 239   score: 1.0   memory length: 45489   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 240   score: 3.0   memory length: 45715   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 241   score: 4.0   memory length: 45990   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 242   score: 1.0   memory length: 46159   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 243   score: 0.0   memory length: 46282   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 244   score: 0.0   memory length: 46404   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 245   score: 6.0   memory length: 46774   epsilon: 1.0    steps: 370    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 246   score: 0.0   memory length: 46896   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 247   score: 3.0   memory length: 47140   epsilon: 1.0    steps: 244    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 248   score: 1.0   memory length: 47310   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 249   score: 2.0   memory length: 47508   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 250   score: 1.0   memory length: 47678   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 251   score: 2.0   memory length: 47878   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 252   score: 1.0   memory length: 48049   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 253   score: 1.0   memory length: 48218   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 254   score: 3.0   memory length: 48465   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 255   score: 0.0   memory length: 48587   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 256   score: 0.0   memory length: 48709   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 257   score: 0.0   memory length: 48831   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 258   score: 2.0   memory length: 49028   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 259   score: 4.0   memory length: 49343   epsilon: 1.0    steps: 315    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 260   score: 5.0   memory length: 49671   epsilon: 1.0    steps: 328    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 261   score: 1.0   memory length: 49822   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 262   score: 2.0   memory length: 50002   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 263   score: 1.0   memory length: 50153   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 264   score: 0.0   memory length: 50276   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 265   score: 2.0   memory length: 50457   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 266   score: 1.0   memory length: 50627   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 267   score: 1.0   memory length: 50795   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 268   score: 1.0   memory length: 50967   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 269   score: 1.0   memory length: 51137   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 270   score: 2.0   memory length: 51335   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 271   score: 3.0   memory length: 51561   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 272   score: 2.0   memory length: 51779   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 273   score: 2.0   memory length: 51997   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 274   score: 2.0   memory length: 52213   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 275   score: 0.0   memory length: 52336   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 276   score: 2.0   memory length: 52554   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 277   score: 1.0   memory length: 52705   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 278   score: 2.0   memory length: 52923   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 279   score: 1.0   memory length: 53074   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 280   score: 2.0   memory length: 53272   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 281   score: 2.0   memory length: 53469   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 282   score: 0.0   memory length: 53592   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 283   score: 2.0   memory length: 53790   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 284   score: 2.0   memory length: 53989   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 285   score: 0.0   memory length: 54112   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 286   score: 2.0   memory length: 54309   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 287   score: 0.0   memory length: 54431   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 288   score: 3.0   memory length: 54659   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 289   score: 2.0   memory length: 54856   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 290   score: 1.0   memory length: 55025   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 291   score: 0.0   memory length: 55147   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 292   score: 1.0   memory length: 55316   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 293   score: 4.0   memory length: 55611   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 294   score: 2.0   memory length: 55829   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 295   score: 0.0   memory length: 55952   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 296   score: 3.0   memory length: 56198   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 297   score: 2.0   memory length: 56418   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 298   score: 3.0   memory length: 56666   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 299   score: 0.0   memory length: 56788   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 300   score: 1.0   memory length: 56957   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 301   score: 1.0   memory length: 57108   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 302   score: 0.0   memory length: 57231   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 303   score: 1.0   memory length: 57400   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 304   score: 1.0   memory length: 57568   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 305   score: 0.0   memory length: 57691   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 306   score: 5.0   memory length: 57982   epsilon: 1.0    steps: 291    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 307   score: 1.0   memory length: 58151   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 308   score: 2.0   memory length: 58352   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 309   score: 0.0   memory length: 58475   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 310   score: 3.0   memory length: 58724   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 311   score: 4.0   memory length: 59018   epsilon: 1.0    steps: 294    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 312   score: 1.0   memory length: 59186   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 313   score: 0.0   memory length: 59308   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 314   score: 1.0   memory length: 59459   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 315   score: 1.0   memory length: 59628   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 316   score: 2.0   memory length: 59845   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 317   score: 0.0   memory length: 59968   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 318   score: 1.0   memory length: 60136   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 319   score: 0.0   memory length: 60259   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 320   score: 2.0   memory length: 60457   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 321   score: 1.0   memory length: 60626   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 322   score: 1.0   memory length: 60777   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 323   score: 2.0   memory length: 60959   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 324   score: 3.0   memory length: 61208   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 325   score: 3.0   memory length: 61455   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 326   score: 2.0   memory length: 61671   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 327   score: 1.0   memory length: 61822   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 328   score: 0.0   memory length: 61944   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 329   score: 1.0   memory length: 62113   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 330   score: 2.0   memory length: 62311   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 331   score: 0.0   memory length: 62434   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 332   score: 2.0   memory length: 62632   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 333   score: 0.0   memory length: 62754   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 334   score: 3.0   memory length: 62997   epsilon: 1.0    steps: 243    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 335   score: 0.0   memory length: 63119   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 336   score: 2.0   memory length: 63316   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 337   score: 2.0   memory length: 63533   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 338   score: 2.0   memory length: 63731   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 339   score: 0.0   memory length: 63854   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 340   score: 1.0   memory length: 64006   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 341   score: 2.0   memory length: 64223   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 342   score: 1.0   memory length: 64392   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 343   score: 2.0   memory length: 64590   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 344   score: 2.0   memory length: 64805   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 345   score: 2.0   memory length: 65022   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 346   score: 0.0   memory length: 65145   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 347   score: 3.0   memory length: 65393   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 348   score: 1.0   memory length: 65565   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 349   score: 4.0   memory length: 65840   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 350   score: 1.0   memory length: 66009   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 351   score: 0.0   memory length: 66132   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 352   score: 2.0   memory length: 66350   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 353   score: 0.0   memory length: 66472   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 354   score: 1.0   memory length: 66642   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 355   score: 3.0   memory length: 66889   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 356   score: 2.0   memory length: 67087   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 357   score: 0.0   memory length: 67210   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 358   score: 0.0   memory length: 67332   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 359   score: 0.0   memory length: 67455   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 360   score: 0.0   memory length: 67578   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 361   score: 1.0   memory length: 67746   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 362   score: 2.0   memory length: 67965   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 363   score: 4.0   memory length: 68240   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 364   score: 1.0   memory length: 68409   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 365   score: 2.0   memory length: 68607   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 366   score: 1.0   memory length: 68775   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 367   score: 1.0   memory length: 68944   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 368   score: 1.0   memory length: 69113   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 369   score: 1.0   memory length: 69281   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 370   score: 0.0   memory length: 69404   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 371   score: 1.0   memory length: 69573   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 372   score: 4.0   memory length: 69870   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 373   score: 1.0   memory length: 70020   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 374   score: 2.0   memory length: 70241   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 375   score: 1.0   memory length: 70409   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 376   score: 3.0   memory length: 70635   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 377   score: 2.0   memory length: 70833   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 378   score: 2.0   memory length: 71032   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 379   score: 0.0   memory length: 71155   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 380   score: 0.0   memory length: 71278   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 381   score: 0.0   memory length: 71400   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 382   score: 0.0   memory length: 71522   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 383   score: 1.0   memory length: 71676   epsilon: 1.0    steps: 154    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 384   score: 0.0   memory length: 71799   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 385   score: 1.0   memory length: 71968   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 386   score: 2.0   memory length: 72166   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 387   score: 2.0   memory length: 72386   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 388   score: 1.0   memory length: 72537   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 389   score: 2.0   memory length: 72757   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 390   score: 1.0   memory length: 72927   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 391   score: 2.0   memory length: 73124   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 392   score: 1.0   memory length: 73294   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 393   score: 0.0   memory length: 73417   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 394   score: 3.0   memory length: 73650   epsilon: 1.0    steps: 233    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 395   score: 0.0   memory length: 73773   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 396   score: 2.0   memory length: 73990   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 397   score: 1.0   memory length: 74141   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 398   score: 0.0   memory length: 74264   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 399   score: 0.0   memory length: 74387   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 400   score: 2.0   memory length: 74566   epsilon: 1.0    steps: 179    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 401   score: 1.0   memory length: 74716   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 402   score: 1.0   memory length: 74885   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 403   score: 0.0   memory length: 75007   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 404   score: 1.0   memory length: 75158   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 405   score: 0.0   memory length: 75280   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 406   score: 3.0   memory length: 75546   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 407   score: 2.0   memory length: 75743   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 408   score: 1.0   memory length: 75912   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 409   score: 0.0   memory length: 76035   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 410   score: 1.0   memory length: 76187   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 411   score: 4.0   memory length: 76465   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 412   score: 1.0   memory length: 76619   epsilon: 1.0    steps: 154    lr: 0.0001     evaluation reward: 1.27\n",
      "episode: 413   score: 6.0   memory length: 76965   epsilon: 1.0    steps: 346    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 414   score: 2.0   memory length: 77164   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 415   score: 0.0   memory length: 77286   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 416   score: 3.0   memory length: 77533   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 417   score: 1.0   memory length: 77703   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 418   score: 0.0   memory length: 77826   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 419   score: 1.0   memory length: 77995   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 420   score: 1.0   memory length: 78164   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 421   score: 5.0   memory length: 78480   epsilon: 1.0    steps: 316    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 422   score: 0.0   memory length: 78602   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 423   score: 1.0   memory length: 78772   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 424   score: 3.0   memory length: 78998   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 425   score: 2.0   memory length: 79196   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 426   score: 2.0   memory length: 79414   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 427   score: 1.0   memory length: 79583   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 428   score: 1.0   memory length: 79734   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 429   score: 3.0   memory length: 80002   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 430   score: 1.0   memory length: 80174   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 431   score: 0.0   memory length: 80297   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 432   score: 2.0   memory length: 80513   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 433   score: 4.0   memory length: 80811   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 434   score: 2.0   memory length: 81008   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 435   score: 1.0   memory length: 81159   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 436   score: 0.0   memory length: 81282   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 437   score: 0.0   memory length: 81405   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 438   score: 0.0   memory length: 81528   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 439   score: 1.0   memory length: 81680   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 440   score: 1.0   memory length: 81850   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 441   score: 0.0   memory length: 81973   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 442   score: 2.0   memory length: 82192   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 443   score: 1.0   memory length: 82361   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 444   score: 1.0   memory length: 82531   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 445   score: 2.0   memory length: 82748   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 446   score: 2.0   memory length: 82966   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 447   score: 3.0   memory length: 83213   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 448   score: 0.0   memory length: 83335   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 449   score: 0.0   memory length: 83458   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 450   score: 0.0   memory length: 83580   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.29\n",
      "episode: 451   score: 1.0   memory length: 83731   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 452   score: 0.0   memory length: 83853   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.28\n",
      "episode: 453   score: 3.0   memory length: 84120   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 454   score: 2.0   memory length: 84318   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 455   score: 3.0   memory length: 84546   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 456   score: 1.0   memory length: 84715   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 457   score: 2.0   memory length: 84936   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 458   score: 5.0   memory length: 85301   epsilon: 1.0    steps: 365    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 459   score: 1.0   memory length: 85452   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 460   score: 0.0   memory length: 85575   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 461   score: 0.0   memory length: 85697   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 462   score: 2.0   memory length: 85894   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 463   score: 2.0   memory length: 86111   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 464   score: 1.0   memory length: 86280   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 465   score: 0.0   memory length: 86403   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 466   score: 0.0   memory length: 86525   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 467   score: 3.0   memory length: 86771   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 468   score: 3.0   memory length: 87018   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 469   score: 4.0   memory length: 87294   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 470   score: 0.0   memory length: 87416   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 471   score: 4.0   memory length: 87691   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 472   score: 2.0   memory length: 87873   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 473   score: 3.0   memory length: 88085   epsilon: 1.0    steps: 212    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 474   score: 0.0   memory length: 88207   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 475   score: 3.0   memory length: 88419   epsilon: 1.0    steps: 212    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 476   score: 2.0   memory length: 88634   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 477   score: 1.0   memory length: 88806   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 478   score: 4.0   memory length: 89081   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 479   score: 0.0   memory length: 89203   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 480   score: 2.0   memory length: 89401   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 481   score: 3.0   memory length: 89631   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 482   score: 4.0   memory length: 89905   epsilon: 1.0    steps: 274    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 483   score: 0.0   memory length: 90027   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 484   score: 0.0   memory length: 90149   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 485   score: 0.0   memory length: 90272   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 486   score: 1.0   memory length: 90441   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 487   score: 2.0   memory length: 90662   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 488   score: 1.0   memory length: 90831   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 489   score: 0.0   memory length: 90954   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 490   score: 2.0   memory length: 91155   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 491   score: 2.0   memory length: 91371   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 492   score: 2.0   memory length: 91591   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 493   score: 2.0   memory length: 91788   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 494   score: 2.0   memory length: 91986   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 495   score: 0.0   memory length: 92108   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 496   score: 3.0   memory length: 92376   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 497   score: 2.0   memory length: 92574   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 498   score: 0.0   memory length: 92697   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 499   score: 3.0   memory length: 92962   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 500   score: 1.0   memory length: 93112   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 501   score: 1.0   memory length: 93263   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 502   score: 0.0   memory length: 93386   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 503   score: 2.0   memory length: 93605   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 504   score: 2.0   memory length: 93803   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 505   score: 2.0   memory length: 93989   epsilon: 1.0    steps: 186    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 506   score: 1.0   memory length: 94157   epsilon: 1.0    steps: 168    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 507   score: 0.0   memory length: 94280   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 508   score: 4.0   memory length: 94547   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 509   score: 2.0   memory length: 94748   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 510   score: 0.0   memory length: 94871   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 511   score: 2.0   memory length: 95089   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 512   score: 0.0   memory length: 95212   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 513   score: 0.0   memory length: 95335   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 514   score: 2.0   memory length: 95535   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 515   score: 1.0   memory length: 95706   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 516   score: 2.0   memory length: 95925   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 517   score: 2.0   memory length: 96123   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 518   score: 2.0   memory length: 96339   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 519   score: 1.0   memory length: 96491   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 520   score: 0.0   memory length: 96614   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 521   score: 2.0   memory length: 96813   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 522   score: 0.0   memory length: 96936   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 523   score: 2.0   memory length: 97152   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 524   score: 2.0   memory length: 97349   epsilon: 1.0    steps: 197    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 525   score: 1.0   memory length: 97500   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 526   score: 0.0   memory length: 97622   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 527   score: 1.0   memory length: 97791   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 528   score: 0.0   memory length: 97913   epsilon: 1.0    steps: 122    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 529   score: 1.0   memory length: 98063   epsilon: 1.0    steps: 150    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 530   score: 0.0   memory length: 98186   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 531   score: 3.0   memory length: 98434   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 532   score: 1.0   memory length: 98585   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 533   score: 1.0   memory length: 98736   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 534   score: 1.0   memory length: 98905   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 535   score: 1.0   memory length: 99074   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 536   score: 0.0   memory length: 99197   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 537   score: 3.0   memory length: 99443   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 538   score: 5.0   memory length: 99724   epsilon: 1.0    steps: 281    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 539   score: 2.0   memory length: 99922   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/aalkhami/cs747/hw5/CS747_Assigment5/agent.py:58: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  mini_batch = np.array(mini_batch, dtype=object).transpose()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 540   score: 0.0   memory length: 100045   epsilon: 0.999908920000002    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 541   score: 2.0   memory length: 100243   epsilon: 0.9995168800000105    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 542   score: 0.0   memory length: 100366   epsilon: 0.9992733400000158    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 543   score: 3.0   memory length: 100615   epsilon: 0.9987803200000265    steps: 249    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 544   score: 1.0   memory length: 100783   epsilon: 0.9984476800000337    steps: 168    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 545   score: 1.0   memory length: 100934   epsilon: 0.9981487000000402    steps: 151    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 546   score: 1.0   memory length: 101105   epsilon: 0.9978101200000475    steps: 171    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 547   score: 3.0   memory length: 101351   epsilon: 0.9973230400000581    steps: 246    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 548   score: 0.0   memory length: 101474   epsilon: 0.9970795000000634    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 549   score: 5.0   memory length: 101838   epsilon: 0.996358780000079    steps: 364    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 550   score: 0.0   memory length: 101961   epsilon: 0.9961152400000843    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 551   score: 0.0   memory length: 102083   epsilon: 0.9958736800000896    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 552   score: 2.0   memory length: 102299   epsilon: 0.9954460000000989    steps: 216    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 553   score: 2.0   memory length: 102516   epsilon: 0.9950163400001082    steps: 217    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 554   score: 3.0   memory length: 102763   epsilon: 0.9945272800001188    steps: 247    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 555   score: 3.0   memory length: 103010   epsilon: 0.9940382200001294    steps: 247    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 556   score: 0.0   memory length: 103132   epsilon: 0.9937966600001347    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 557   score: 0.0   memory length: 103255   epsilon: 0.99355312000014    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 558   score: 0.0   memory length: 103377   epsilon: 0.9933115600001452    steps: 122    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 559   score: 2.0   memory length: 103598   epsilon: 0.9928739800001547    steps: 221    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 560   score: 0.0   memory length: 103721   epsilon: 0.99263044000016    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 561   score: 0.0   memory length: 103844   epsilon: 0.9923869000001653    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 562   score: 10.0   memory length: 104286   epsilon: 0.9915117400001843    steps: 442    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 563   score: 0.0   memory length: 104409   epsilon: 0.9912682000001896    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 564   score: 3.0   memory length: 104635   epsilon: 0.9908207200001993    steps: 226    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 565   score: 1.0   memory length: 104786   epsilon: 0.9905217400002058    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 566   score: 3.0   memory length: 105012   epsilon: 0.9900742600002155    steps: 226    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 567   score: 2.0   memory length: 105212   epsilon: 0.9896782600002241    steps: 200    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 568   score: 0.0   memory length: 105334   epsilon: 0.9894367000002293    steps: 122    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 569   score: 1.0   memory length: 105506   epsilon: 0.9890961400002367    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 570   score: 2.0   memory length: 105685   epsilon: 0.9887417200002444    steps: 179    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 571   score: 1.0   memory length: 105836   epsilon: 0.9884427400002509    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 572   score: 3.0   memory length: 106104   epsilon: 0.9879121000002624    steps: 268    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 573   score: 0.0   memory length: 106227   epsilon: 0.9876685600002677    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 574   score: 3.0   memory length: 106475   epsilon: 0.9871775200002784    steps: 248    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 575   score: 3.0   memory length: 106705   epsilon: 0.9867221200002882    steps: 230    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 576   score: 2.0   memory length: 106888   epsilon: 0.9863597800002961    steps: 183    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 577   score: 0.0   memory length: 107011   epsilon: 0.9861162400003014    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 578   score: 4.0   memory length: 107251   epsilon: 0.9856410400003117    steps: 240    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 579   score: 1.0   memory length: 107420   epsilon: 0.985306420000319    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 580   score: 0.0   memory length: 107543   epsilon: 0.9850628800003243    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 581   score: 2.0   memory length: 107759   epsilon: 0.9846352000003336    steps: 216    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 582   score: 2.0   memory length: 107978   epsilon: 0.984201580000343    steps: 219    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 583   score: 0.0   memory length: 108101   epsilon: 0.9839580400003483    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 584   score: 0.0   memory length: 108224   epsilon: 0.9837145000003535    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 585   score: 0.0   memory length: 108347   epsilon: 0.9834709600003588    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 586   score: 2.0   memory length: 108527   epsilon: 0.9831145600003666    steps: 180    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 587   score: 1.0   memory length: 108699   epsilon: 0.982774000000374    steps: 172    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 588   score: 3.0   memory length: 108946   epsilon: 0.9822849400003846    steps: 247    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 589   score: 1.0   memory length: 109115   epsilon: 0.9819503200003918    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 590   score: 3.0   memory length: 109361   epsilon: 0.9814632400004024    steps: 246    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 591   score: 0.0   memory length: 109483   epsilon: 0.9812216800004077    steps: 122    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 592   score: 1.0   memory length: 109652   epsilon: 0.9808870600004149    steps: 169    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 593   score: 3.0   memory length: 109898   epsilon: 0.9803999800004255    steps: 246    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 594   score: 1.0   memory length: 110068   epsilon: 0.9800633800004328    steps: 170    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 595   score: 0.0   memory length: 110190   epsilon: 0.979821820000438    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 596   score: 0.0   memory length: 110313   epsilon: 0.9795782800004433    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 597   score: 0.0   memory length: 110436   epsilon: 0.9793347400004486    steps: 123    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 598   score: 4.0   memory length: 110730   epsilon: 0.9787526200004613    steps: 294    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 599   score: 3.0   memory length: 110978   epsilon: 0.9782615800004719    steps: 248    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 600   score: 1.0   memory length: 111128   epsilon: 0.9779645800004784    steps: 150    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 601   score: 2.0   memory length: 111326   epsilon: 0.9775725400004869    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 602   score: 0.0   memory length: 111448   epsilon: 0.9773309800004921    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 603   score: 2.0   memory length: 111646   epsilon: 0.9769389400005006    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 604   score: 2.0   memory length: 111844   epsilon: 0.9765469000005091    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 605   score: 2.0   memory length: 112042   epsilon: 0.9761548600005177    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 606   score: 0.0   memory length: 112165   epsilon: 0.9759113200005229    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 607   score: 1.0   memory length: 112315   epsilon: 0.9756143200005294    steps: 150    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 608   score: 3.0   memory length: 112585   epsilon: 0.975079720000541    steps: 270    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 609   score: 0.0   memory length: 112708   epsilon: 0.9748361800005463    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 610   score: 2.0   memory length: 112925   epsilon: 0.9744065200005556    steps: 217    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 611   score: 2.0   memory length: 113126   epsilon: 0.9740085400005642    steps: 201    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 612   score: 0.0   memory length: 113248   epsilon: 0.9737669800005695    steps: 122    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 613   score: 0.0   memory length: 113371   epsilon: 0.9735234400005748    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 614   score: 3.0   memory length: 113596   epsilon: 0.9730779400005845    steps: 225    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 615   score: 2.0   memory length: 113812   epsilon: 0.9726502600005937    steps: 216    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 616   score: 3.0   memory length: 114078   epsilon: 0.9721235800006052    steps: 266    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 617   score: 1.0   memory length: 114247   epsilon: 0.9717889600006124    steps: 169    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 618   score: 1.0   memory length: 114416   epsilon: 0.9714543400006197    steps: 169    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 619   score: 5.0   memory length: 114783   epsilon: 0.9707276800006355    steps: 367    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 620   score: 3.0   memory length: 115008   epsilon: 0.9702821800006451    steps: 225    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 621   score: 1.0   memory length: 115159   epsilon: 0.9699832000006516    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 622   score: 2.0   memory length: 115357   epsilon: 0.9695911600006601    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 623   score: 0.0   memory length: 115480   epsilon: 0.9693476200006654    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 624   score: 0.0   memory length: 115602   epsilon: 0.9691060600006707    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 625   score: 0.0   memory length: 115725   epsilon: 0.968862520000676    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 626   score: 1.0   memory length: 115894   epsilon: 0.9685279000006832    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 627   score: 4.0   memory length: 116135   epsilon: 0.9680507200006936    steps: 241    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 628   score: 0.0   memory length: 116257   epsilon: 0.9678091600006988    steps: 122    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 629   score: 0.0   memory length: 116379   epsilon: 0.9675676000007041    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 630   score: 1.0   memory length: 116530   epsilon: 0.9672686200007106    steps: 151    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 631   score: 1.0   memory length: 116698   epsilon: 0.9669359800007178    steps: 168    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 632   score: 0.0   memory length: 116821   epsilon: 0.9666924400007231    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 633   score: 5.0   memory length: 117162   epsilon: 0.9660172600007377    steps: 341    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 634   score: 2.0   memory length: 117364   epsilon: 0.9656173000007464    steps: 202    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 635   score: 1.0   memory length: 117515   epsilon: 0.9653183200007529    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 636   score: 1.0   memory length: 117686   epsilon: 0.9649797400007603    steps: 171    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 637   score: 2.0   memory length: 117905   epsilon: 0.9645461200007697    steps: 219    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 638   score: 3.0   memory length: 118154   epsilon: 0.9640531000007804    steps: 249    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 639   score: 0.0   memory length: 118277   epsilon: 0.9638095600007857    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 640   score: 1.0   memory length: 118446   epsilon: 0.9634749400007929    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 641   score: 0.0   memory length: 118569   epsilon: 0.9632314000007982    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 642   score: 3.0   memory length: 118833   epsilon: 0.9627086800008096    steps: 264    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 643   score: 0.0   memory length: 118956   epsilon: 0.9624651400008148    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 644   score: 2.0   memory length: 119176   epsilon: 0.9620295400008243    steps: 220    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 645   score: 1.0   memory length: 119329   epsilon: 0.9617266000008309    steps: 153    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 646   score: 3.0   memory length: 119596   epsilon: 0.9611979400008424    steps: 267    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 647   score: 1.0   memory length: 119746   epsilon: 0.9609009400008488    steps: 150    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 648   score: 1.0   memory length: 119896   epsilon: 0.9606039400008552    steps: 150    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 649   score: 2.0   memory length: 120094   epsilon: 0.9602119000008638    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 650   score: 2.0   memory length: 120295   epsilon: 0.9598139200008724    steps: 201    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 651   score: 2.0   memory length: 120516   epsilon: 0.9593763400008819    steps: 221    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 652   score: 2.0   memory length: 120734   epsilon: 0.9589447000008913    steps: 218    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 653   score: 2.0   memory length: 120933   epsilon: 0.9585506800008998    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 654   score: 0.0   memory length: 121056   epsilon: 0.9583071400009051    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 655   score: 1.0   memory length: 121228   epsilon: 0.9579665800009125    steps: 172    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 656   score: 2.0   memory length: 121410   epsilon: 0.9576062200009203    steps: 182    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 657   score: 3.0   memory length: 121636   epsilon: 0.95715874000093    steps: 226    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 658   score: 2.0   memory length: 121854   epsilon: 0.9567271000009394    steps: 218    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 659   score: 0.0   memory length: 121976   epsilon: 0.9564855400009447    steps: 122    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 660   score: 3.0   memory length: 122220   epsilon: 0.9560024200009551    steps: 244    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 661   score: 3.0   memory length: 122485   epsilon: 0.9554777200009665    steps: 265    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 662   score: 1.0   memory length: 122636   epsilon: 0.955178740000973    steps: 151    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 663   score: 6.0   memory length: 123035   epsilon: 0.9543887200009902    steps: 399    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 664   score: 2.0   memory length: 123252   epsilon: 0.9539590600009995    steps: 217    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 665   score: 0.0   memory length: 123374   epsilon: 0.9537175000010047    steps: 122    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 666   score: 2.0   memory length: 123592   epsilon: 0.9532858600010141    steps: 218    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 667   score: 1.0   memory length: 123742   epsilon: 0.9529888600010206    steps: 150    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 668   score: 0.0   memory length: 123865   epsilon: 0.9527453200010259    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 669   score: 0.0   memory length: 123987   epsilon: 0.9525037600010311    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 670   score: 0.0   memory length: 124110   epsilon: 0.9522602200010364    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 671   score: 2.0   memory length: 124308   epsilon: 0.9518681800010449    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 672   score: 0.0   memory length: 124431   epsilon: 0.9516246400010502    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 673   score: 1.0   memory length: 124582   epsilon: 0.9513256600010567    steps: 151    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 674   score: 3.0   memory length: 124848   epsilon: 0.9507989800010681    steps: 266    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 675   score: 5.0   memory length: 125140   epsilon: 0.9502208200010807    steps: 292    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 676   score: 2.0   memory length: 125338   epsilon: 0.9498287800010892    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 677   score: 1.0   memory length: 125488   epsilon: 0.9495317800010956    steps: 150    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 678   score: 1.0   memory length: 125659   epsilon: 0.949193200001103    steps: 171    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 679   score: 2.0   memory length: 125880   epsilon: 0.9487556200011125    steps: 221    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 680   score: 0.0   memory length: 126002   epsilon: 0.9485140600011177    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 681   score: 1.0   memory length: 126170   epsilon: 0.9481814200011249    steps: 168    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 682   score: 3.0   memory length: 126396   epsilon: 0.9477339400011346    steps: 226    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 683   score: 1.0   memory length: 126564   epsilon: 0.9474013000011419    steps: 168    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 684   score: 1.0   memory length: 126715   epsilon: 0.9471023200011484    steps: 151    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 685   score: 1.0   memory length: 126887   epsilon: 0.9467617600011557    steps: 172    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 686   score: 0.0   memory length: 127009   epsilon: 0.946520200001161    steps: 122    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 687   score: 3.0   memory length: 127257   epsilon: 0.9460291600011717    steps: 248    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 688   score: 0.0   memory length: 127380   epsilon: 0.9457856200011769    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 689   score: 1.0   memory length: 127531   epsilon: 0.9454866400011834    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 690   score: 1.0   memory length: 127682   epsilon: 0.9451876600011899    steps: 151    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 691   score: 0.0   memory length: 127804   epsilon: 0.9449461000011952    steps: 122    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 692   score: 3.0   memory length: 128052   epsilon: 0.9444550600012058    steps: 248    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 693   score: 3.0   memory length: 128277   epsilon: 0.9440095600012155    steps: 225    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 694   score: 1.0   memory length: 128449   epsilon: 0.9436690000012229    steps: 172    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 695   score: 1.0   memory length: 128621   epsilon: 0.9433284400012303    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 696   score: 5.0   memory length: 128947   epsilon: 0.9426829600012443    steps: 326    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 697   score: 1.0   memory length: 129117   epsilon: 0.9423463600012516    steps: 170    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 698   score: 0.0   memory length: 129239   epsilon: 0.9421048000012568    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 699   score: 1.0   memory length: 129408   epsilon: 0.9417701800012641    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 700   score: 3.0   memory length: 129656   epsilon: 0.9412791400012748    steps: 248    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 701   score: 1.0   memory length: 129807   epsilon: 0.9409801600012813    steps: 151    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 702   score: 3.0   memory length: 130052   epsilon: 0.9404950600012918    steps: 245    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 703   score: 2.0   memory length: 130273   epsilon: 0.9400574800013013    steps: 221    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 704   score: 2.0   memory length: 130491   epsilon: 0.9396258400013107    steps: 218    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 705   score: 0.0   memory length: 130614   epsilon: 0.939382300001316    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 706   score: 2.0   memory length: 130812   epsilon: 0.9389902600013245    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 707   score: 0.0   memory length: 130935   epsilon: 0.9387467200013297    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 708   score: 3.0   memory length: 131163   epsilon: 0.9382952800013395    steps: 228    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 709   score: 1.0   memory length: 131334   epsilon: 0.9379567000013469    steps: 171    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 710   score: 0.0   memory length: 131456   epsilon: 0.9377151400013521    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 711   score: 2.0   memory length: 131671   epsilon: 0.9372894400013614    steps: 215    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 712   score: 2.0   memory length: 131850   epsilon: 0.9369350200013691    steps: 179    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 713   score: 0.0   memory length: 131973   epsilon: 0.9366914800013744    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 714   score: 0.0   memory length: 132096   epsilon: 0.9364479400013797    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 715   score: 2.0   memory length: 132294   epsilon: 0.9360559000013882    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 716   score: 1.0   memory length: 132445   epsilon: 0.9357569200013947    steps: 151    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 717   score: 1.0   memory length: 132613   epsilon: 0.9354242800014019    steps: 168    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 718   score: 0.0   memory length: 132736   epsilon: 0.9351807400014072    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 719   score: 2.0   memory length: 132953   epsilon: 0.9347510800014165    steps: 217    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 720   score: 1.0   memory length: 133122   epsilon: 0.9344164600014238    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 721   score: 4.0   memory length: 133381   epsilon: 0.9339036400014349    steps: 259    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 722   score: 1.0   memory length: 133550   epsilon: 0.9335690200014422    steps: 169    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 723   score: 3.0   memory length: 133776   epsilon: 0.9331215400014519    steps: 226    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 724   score: 2.0   memory length: 133996   epsilon: 0.9326859400014613    steps: 220    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 725   score: 1.0   memory length: 134164   epsilon: 0.9323533000014685    steps: 168    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 726   score: 0.0   memory length: 134287   epsilon: 0.9321097600014738    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 727   score: 2.0   memory length: 134485   epsilon: 0.9317177200014823    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 728   score: 0.0   memory length: 134608   epsilon: 0.9314741800014876    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 729   score: 4.0   memory length: 134867   epsilon: 0.9309613600014988    steps: 259    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 730   score: 2.0   memory length: 135084   epsilon: 0.9305317000015081    steps: 217    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 731   score: 0.0   memory length: 135207   epsilon: 0.9302881600015134    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 732   score: 0.0   memory length: 135330   epsilon: 0.9300446200015187    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 733   score: 1.0   memory length: 135499   epsilon: 0.9297100000015259    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 734   score: 0.0   memory length: 135622   epsilon: 0.9294664600015312    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 735   score: 2.0   memory length: 135821   epsilon: 0.9290724400015398    steps: 199    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 736   score: 2.0   memory length: 136019   epsilon: 0.9286804000015483    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 737   score: 1.0   memory length: 136170   epsilon: 0.9283814200015548    steps: 151    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 738   score: 0.0   memory length: 136293   epsilon: 0.9281378800015601    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 739   score: 3.0   memory length: 136559   epsilon: 0.9276112000015715    steps: 266    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 740   score: 3.0   memory length: 136788   epsilon: 0.9271577800015813    steps: 229    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 741   score: 0.0   memory length: 136911   epsilon: 0.9269142400015866    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 742   score: 0.0   memory length: 137034   epsilon: 0.9266707000015919    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 743   score: 0.0   memory length: 137156   epsilon: 0.9264291400015972    steps: 122    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 744   score: 2.0   memory length: 137354   epsilon: 0.9260371000016057    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 745   score: 2.0   memory length: 137571   epsilon: 0.925607440001615    steps: 217    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 746   score: 3.0   memory length: 137842   epsilon: 0.9250708600016266    steps: 271    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 747   score: 0.0   memory length: 137965   epsilon: 0.9248273200016319    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 748   score: 3.0   memory length: 138191   epsilon: 0.9243798400016416    steps: 226    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 749   score: 4.0   memory length: 138467   epsilon: 0.9238333600016535    steps: 276    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 750   score: 1.0   memory length: 138639   epsilon: 0.9234928000016609    steps: 172    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 751   score: 2.0   memory length: 138836   epsilon: 0.9231027400016694    steps: 197    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 752   score: 3.0   memory length: 139062   epsilon: 0.9226552600016791    steps: 226    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 753   score: 4.0   memory length: 139341   epsilon: 0.9221028400016911    steps: 279    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 754   score: 1.0   memory length: 139495   epsilon: 0.9217979200016977    steps: 154    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 755   score: 0.0   memory length: 139618   epsilon: 0.921554380001703    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 756   score: 2.0   memory length: 139815   epsilon: 0.9211643200017114    steps: 197    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 757   score: 2.0   memory length: 140033   epsilon: 0.9207326800017208    steps: 218    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 758   score: 0.0   memory length: 140155   epsilon: 0.9204911200017261    steps: 122    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 759   score: 2.0   memory length: 140353   epsilon: 0.9200990800017346    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 760   score: 2.0   memory length: 140568   epsilon: 0.9196733800017438    steps: 215    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 761   score: 1.0   memory length: 140737   epsilon: 0.9193387600017511    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 762   score: 3.0   memory length: 140970   epsilon: 0.9188774200017611    steps: 233    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 763   score: 1.0   memory length: 141141   epsilon: 0.9185388400017684    steps: 171    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 764   score: 5.0   memory length: 141482   epsilon: 0.9178636600017831    steps: 341    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 765   score: 2.0   memory length: 141683   epsilon: 0.9174656800017917    steps: 201    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 766   score: 2.0   memory length: 141903   epsilon: 0.9170300800018012    steps: 220    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 767   score: 2.0   memory length: 142122   epsilon: 0.9165964600018106    steps: 219    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 768   score: 0.0   memory length: 142245   epsilon: 0.9163529200018159    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 769   score: 2.0   memory length: 142426   epsilon: 0.9159945400018237    steps: 181    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 770   score: 2.0   memory length: 142646   epsilon: 0.9155589400018331    steps: 220    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 771   score: 2.0   memory length: 142865   epsilon: 0.9151253200018425    steps: 219    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 772   score: 1.0   memory length: 143016   epsilon: 0.914826340001849    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 773   score: 0.0   memory length: 143139   epsilon: 0.9145828000018543    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 774   score: 2.0   memory length: 143356   epsilon: 0.9141531400018637    steps: 217    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 775   score: 2.0   memory length: 143554   epsilon: 0.9137611000018722    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 776   score: 0.0   memory length: 143677   epsilon: 0.9135175600018774    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 777   score: 0.0   memory length: 143800   epsilon: 0.9132740200018827    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 778   score: 3.0   memory length: 144011   epsilon: 0.9128562400018918    steps: 211    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 779   score: 2.0   memory length: 144208   epsilon: 0.9124661800019003    steps: 197    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 780   score: 2.0   memory length: 144426   epsilon: 0.9120345400019096    steps: 218    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 781   score: 5.0   memory length: 144729   epsilon: 0.9114346000019227    steps: 303    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 782   score: 0.0   memory length: 144852   epsilon: 0.911191060001928    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 783   score: 1.0   memory length: 145022   epsilon: 0.9108544600019353    steps: 170    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 784   score: 3.0   memory length: 145248   epsilon: 0.910406980001945    steps: 226    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 785   score: 2.0   memory length: 145447   epsilon: 0.9100129600019535    steps: 199    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 786   score: 1.0   memory length: 145619   epsilon: 0.9096724000019609    steps: 172    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 787   score: 1.0   memory length: 145789   epsilon: 0.9093358000019682    steps: 170    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 788   score: 2.0   memory length: 146007   epsilon: 0.9089041600019776    steps: 218    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 789   score: 0.0   memory length: 146130   epsilon: 0.9086606200019829    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 790   score: 0.0   memory length: 146252   epsilon: 0.9084190600019881    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 791   score: 3.0   memory length: 146500   epsilon: 0.9079280200019988    steps: 248    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 792   score: 0.0   memory length: 146622   epsilon: 0.907686460002004    steps: 122    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 793   score: 2.0   memory length: 146840   epsilon: 0.9072548200020134    steps: 218    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 794   score: 0.0   memory length: 146963   epsilon: 0.9070112800020187    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 795   score: 2.0   memory length: 147161   epsilon: 0.9066192400020272    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 796   score: 2.0   memory length: 147379   epsilon: 0.9061876000020366    steps: 218    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 797   score: 2.0   memory length: 147600   epsilon: 0.9057500200020461    steps: 221    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 798   score: 0.0   memory length: 147723   epsilon: 0.9055064800020514    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 799   score: 0.0   memory length: 147845   epsilon: 0.9052649200020566    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 800   score: 3.0   memory length: 148113   epsilon: 0.9047342800020681    steps: 268    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 801   score: 1.0   memory length: 148283   epsilon: 0.9043976800020754    steps: 170    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 802   score: 3.0   memory length: 148534   epsilon: 0.9039007000020862    steps: 251    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 803   score: 2.0   memory length: 148714   epsilon: 0.903544300002094    steps: 180    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 804   score: 1.0   memory length: 148884   epsilon: 0.9032077000021013    steps: 170    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 805   score: 1.0   memory length: 149052   epsilon: 0.9028750600021085    steps: 168    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 806   score: 2.0   memory length: 149250   epsilon: 0.902483020002117    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 807   score: 0.0   memory length: 149373   epsilon: 0.9022394800021223    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 808   score: 1.0   memory length: 149545   epsilon: 0.9018989200021297    steps: 172    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 809   score: 3.0   memory length: 149792   epsilon: 0.9014098600021403    steps: 247    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 810   score: 1.0   memory length: 149960   epsilon: 0.9010772200021475    steps: 168    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 811   score: 3.0   memory length: 150225   epsilon: 0.9005525200021589    steps: 265    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 812   score: 0.0   memory length: 150348   epsilon: 0.9003089800021642    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 813   score: 2.0   memory length: 150548   epsilon: 0.8999129800021728    steps: 200    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 814   score: 0.0   memory length: 150671   epsilon: 0.8996694400021781    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 815   score: 1.0   memory length: 150821   epsilon: 0.8993724400021845    steps: 150    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 816   score: 1.0   memory length: 150990   epsilon: 0.8990378200021918    steps: 169    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 817   score: 3.0   memory length: 151235   epsilon: 0.8985527200022023    steps: 245    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 818   score: 0.0   memory length: 151358   epsilon: 0.8983091800022076    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 819   score: 2.0   memory length: 151537   epsilon: 0.8979547600022153    steps: 179    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 820   score: 1.0   memory length: 151707   epsilon: 0.8976181600022226    steps: 170    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 821   score: 0.0   memory length: 151830   epsilon: 0.8973746200022279    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 822   score: 3.0   memory length: 152058   epsilon: 0.8969231800022377    steps: 228    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 823   score: 3.0   memory length: 152305   epsilon: 0.8964341200022483    steps: 247    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 824   score: 0.0   memory length: 152428   epsilon: 0.8961905800022536    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 825   score: 3.0   memory length: 152654   epsilon: 0.8957431000022633    steps: 226    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 826   score: 1.0   memory length: 152804   epsilon: 0.8954461000022698    steps: 150    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 827   score: 2.0   memory length: 153001   epsilon: 0.8950560400022782    steps: 197    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 828   score: 2.0   memory length: 153199   epsilon: 0.8946640000022867    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 829   score: 1.0   memory length: 153350   epsilon: 0.8943650200022932    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 830   score: 1.0   memory length: 153500   epsilon: 0.8940680200022997    steps: 150    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 831   score: 2.0   memory length: 153698   epsilon: 0.8936759800023082    steps: 198    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 832   score: 3.0   memory length: 153947   epsilon: 0.8931829600023189    steps: 249    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 833   score: 1.0   memory length: 154097   epsilon: 0.8928859600023253    steps: 150    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 834   score: 0.0   memory length: 154220   epsilon: 0.8926424200023306    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 835   score: 1.0   memory length: 154390   epsilon: 0.8923058200023379    steps: 170    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 836   score: 1.0   memory length: 154541   epsilon: 0.8920068400023444    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 837   score: 1.0   memory length: 154713   epsilon: 0.8916662800023518    steps: 172    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 838   score: 2.0   memory length: 154911   epsilon: 0.8912742400023603    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 839   score: 2.0   memory length: 155109   epsilon: 0.8908822000023688    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 840   score: 0.0   memory length: 155231   epsilon: 0.8906406400023741    steps: 122    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 841   score: 2.0   memory length: 155430   epsilon: 0.8902466200023826    steps: 199    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 842   score: 2.0   memory length: 155631   epsilon: 0.8898486400023913    steps: 201    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 843   score: 0.0   memory length: 155754   epsilon: 0.8896051000023966    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 844   score: 3.0   memory length: 156000   epsilon: 0.8891180200024071    steps: 246    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 845   score: 1.0   memory length: 156168   epsilon: 0.8887853800024144    steps: 168    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 846   score: 2.0   memory length: 156386   epsilon: 0.8883537400024237    steps: 218    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 847   score: 3.0   memory length: 156632   epsilon: 0.8878666600024343    steps: 246    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 848   score: 5.0   memory length: 156964   epsilon: 0.8872093000024486    steps: 332    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 849   score: 2.0   memory length: 157165   epsilon: 0.8868113200024572    steps: 201    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 850   score: 2.0   memory length: 157384   epsilon: 0.8863777000024666    steps: 219    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 851   score: 1.0   memory length: 157535   epsilon: 0.8860787200024731    steps: 151    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 852   score: 0.0   memory length: 157658   epsilon: 0.8858351800024784    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 853   score: 2.0   memory length: 157855   epsilon: 0.8854451200024869    steps: 197    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 854   score: 1.0   memory length: 158026   epsilon: 0.8851065400024942    steps: 171    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 855   score: 0.0   memory length: 158149   epsilon: 0.8848630000024995    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 856   score: 2.0   memory length: 158369   epsilon: 0.884427400002509    steps: 220    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 857   score: 0.0   memory length: 158491   epsilon: 0.8841858400025142    steps: 122    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 858   score: 0.0   memory length: 158614   epsilon: 0.8839423000025195    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 859   score: 2.0   memory length: 158832   epsilon: 0.8835106600025289    steps: 218    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 860   score: 3.0   memory length: 159101   epsilon: 0.8829780400025404    steps: 269    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 861   score: 1.0   memory length: 159252   epsilon: 0.8826790600025469    steps: 151    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 862   score: 5.0   memory length: 159594   epsilon: 0.8820019000025616    steps: 342    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 863   score: 1.0   memory length: 159745   epsilon: 0.8817029200025681    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 864   score: 1.0   memory length: 159896   epsilon: 0.8814039400025746    steps: 151    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 865   score: 0.0   memory length: 160019   epsilon: 0.8811604000025799    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 866   score: 2.0   memory length: 160235   epsilon: 0.8807327200025892    steps: 216    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 867   score: 2.0   memory length: 160450   epsilon: 0.8803070200025984    steps: 215    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 868   score: 1.0   memory length: 160600   epsilon: 0.8800100200026049    steps: 150    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 869   score: 1.0   memory length: 160769   epsilon: 0.8796754000026121    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 870   score: 1.0   memory length: 160940   epsilon: 0.8793368200026195    steps: 171    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 871   score: 1.0   memory length: 161109   epsilon: 0.8790022000026267    steps: 169    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 872   score: 2.0   memory length: 161306   epsilon: 0.8786121400026352    steps: 197    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 873   score: 1.0   memory length: 161474   epsilon: 0.8782795000026424    steps: 168    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 874   score: 0.0   memory length: 161597   epsilon: 0.8780359600026477    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 875   score: 2.0   memory length: 161817   epsilon: 0.8776003600026572    steps: 220    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 876   score: 0.0   memory length: 161940   epsilon: 0.8773568200026625    steps: 123    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 877   score: 2.0   memory length: 162138   epsilon: 0.876964780002671    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 878   score: 3.0   memory length: 162385   epsilon: 0.8764757200026816    steps: 247    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 879   score: 1.0   memory length: 162554   epsilon: 0.8761411000026889    steps: 169    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 880   score: 0.0   memory length: 162677   epsilon: 0.8758975600026941    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 881   score: 3.0   memory length: 162926   epsilon: 0.8754045400027048    steps: 249    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 882   score: 1.0   memory length: 163094   epsilon: 0.8750719000027121    steps: 168    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 883   score: 1.0   memory length: 163263   epsilon: 0.8747372800027193    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 884   score: 2.0   memory length: 163464   epsilon: 0.874339300002728    steps: 201    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 885   score: 0.0   memory length: 163586   epsilon: 0.8740977400027332    steps: 122    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 886   score: 1.0   memory length: 163756   epsilon: 0.8737611400027405    steps: 170    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 887   score: 0.0   memory length: 163879   epsilon: 0.8735176000027458    steps: 123    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 888   score: 2.0   memory length: 164077   epsilon: 0.8731255600027543    steps: 198    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 889   score: 4.0   memory length: 164372   epsilon: 0.872541460002767    steps: 295    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 890   score: 1.0   memory length: 164523   epsilon: 0.8722424800027735    steps: 151    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 891   score: 2.0   memory length: 164721   epsilon: 0.871850440002782    steps: 198    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 892   score: 2.0   memory length: 164939   epsilon: 0.8714188000027914    steps: 218    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 893   score: 2.0   memory length: 165137   epsilon: 0.8710267600027999    steps: 198    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 894   score: 2.0   memory length: 165335   epsilon: 0.8706347200028084    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 895   score: 1.0   memory length: 165486   epsilon: 0.8703357400028149    steps: 151    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 896   score: 4.0   memory length: 165781   epsilon: 0.8697516400028276    steps: 295    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 897   score: 1.0   memory length: 165931   epsilon: 0.869454640002834    steps: 150    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 898   score: 0.0   memory length: 166054   epsilon: 0.8692111000028393    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 899   score: 5.0   memory length: 166380   epsilon: 0.8685656200028533    steps: 326    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 900   score: 2.0   memory length: 166579   epsilon: 0.8681716000028619    steps: 199    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 901   score: 0.0   memory length: 166702   epsilon: 0.8679280600028672    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 902   score: 0.0   memory length: 166825   epsilon: 0.8676845200028724    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 903   score: 1.0   memory length: 166993   epsilon: 0.8673518800028797    steps: 168    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 904   score: 2.0   memory length: 167210   epsilon: 0.866922220002889    steps: 217    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 905   score: 1.0   memory length: 167380   epsilon: 0.8665856200028963    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 906   score: 1.0   memory length: 167549   epsilon: 0.8662510000029036    steps: 169    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 907   score: 0.0   memory length: 167672   epsilon: 0.8660074600029088    steps: 123    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 908   score: 3.0   memory length: 167920   epsilon: 0.8655164200029195    steps: 248    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 909   score: 3.0   memory length: 168169   epsilon: 0.8650234000029302    steps: 249    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 910   score: 1.0   memory length: 168341   epsilon: 0.8646828400029376    steps: 172    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 911   score: 2.0   memory length: 168538   epsilon: 0.8642927800029461    steps: 197    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 912   score: 2.0   memory length: 168735   epsilon: 0.8639027200029545    steps: 197    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 913   score: 1.0   memory length: 168907   epsilon: 0.8635621600029619    steps: 172    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 914   score: 1.0   memory length: 169076   epsilon: 0.8632275400029692    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 915   score: 4.0   memory length: 169370   epsilon: 0.8626454200029818    steps: 294    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 916   score: 0.0   memory length: 169493   epsilon: 0.8624018800029871    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 917   score: 3.0   memory length: 169719   epsilon: 0.8619544000029968    steps: 226    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 918   score: 0.0   memory length: 169842   epsilon: 0.8617108600030021    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 919   score: 2.0   memory length: 170023   epsilon: 0.8613524800030099    steps: 181    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 920   score: 4.0   memory length: 170300   epsilon: 0.8608040200030218    steps: 277    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 921   score: 2.0   memory length: 170516   epsilon: 0.8603763400030311    steps: 216    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 922   score: 4.0   memory length: 170791   epsilon: 0.8598318400030429    steps: 275    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 923   score: 0.0   memory length: 170914   epsilon: 0.8595883000030482    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 924   score: 5.0   memory length: 171266   epsilon: 0.8588913400030633    steps: 352    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 925   score: 2.0   memory length: 171481   epsilon: 0.8584656400030726    steps: 215    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 926   score: 2.0   memory length: 171661   epsilon: 0.8581092400030803    steps: 180    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 927   score: 3.0   memory length: 171907   epsilon: 0.8576221600030909    steps: 246    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 928   score: 2.0   memory length: 172124   epsilon: 0.8571925000031002    steps: 217    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 929   score: 0.0   memory length: 172246   epsilon: 0.8569509400031055    steps: 122    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 930   score: 2.0   memory length: 172464   epsilon: 0.8565193000031148    steps: 218    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 931   score: 0.0   memory length: 172586   epsilon: 0.8562777400031201    steps: 122    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 932   score: 0.0   memory length: 172708   epsilon: 0.8560361800031253    steps: 122    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 933   score: 4.0   memory length: 172966   epsilon: 0.8555253400031364    steps: 258    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 934   score: 2.0   memory length: 173185   epsilon: 0.8550917200031458    steps: 219    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 935   score: 2.0   memory length: 173402   epsilon: 0.8546620600031551    steps: 217    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 936   score: 0.0   memory length: 173524   epsilon: 0.8544205000031604    steps: 122    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 937   score: 0.0   memory length: 173647   epsilon: 0.8541769600031657    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 938   score: 2.0   memory length: 173848   epsilon: 0.8537789800031743    steps: 201    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 939   score: 0.0   memory length: 173971   epsilon: 0.8535354400031796    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 940   score: 0.0   memory length: 174093   epsilon: 0.8532938800031848    steps: 122    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 941   score: 0.0   memory length: 174216   epsilon: 0.8530503400031901    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 942   score: 3.0   memory length: 174464   epsilon: 0.8525593000032008    steps: 248    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 943   score: 0.0   memory length: 174587   epsilon: 0.8523157600032061    steps: 123    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 944   score: 4.0   memory length: 174906   epsilon: 0.8516841400032198    steps: 319    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 945   score: 3.0   memory length: 175135   epsilon: 0.8512307200032296    steps: 229    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 946   score: 2.0   memory length: 175333   epsilon: 0.8508386800032381    steps: 198    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 947   score: 1.0   memory length: 175483   epsilon: 0.8505416800032446    steps: 150    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 948   score: 0.0   memory length: 175606   epsilon: 0.8502981400032499    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 949   score: 1.0   memory length: 175756   epsilon: 0.8500011400032563    steps: 150    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 950   score: 2.0   memory length: 175938   epsilon: 0.8496407800032642    steps: 182    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 951   score: 3.0   memory length: 176181   epsilon: 0.8491596400032746    steps: 243    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 952   score: 2.0   memory length: 176379   epsilon: 0.8487676000032831    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 953   score: 1.0   memory length: 176530   epsilon: 0.8484686200032896    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 954   score: 0.0   memory length: 176653   epsilon: 0.8482250800032949    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 955   score: 10.0   memory length: 177165   epsilon: 0.8472113200033169    steps: 512    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 956   score: 1.0   memory length: 177334   epsilon: 0.8468767000033242    steps: 169    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 957   score: 1.0   memory length: 177504   epsilon: 0.8465401000033315    steps: 170    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 958   score: 1.0   memory length: 177673   epsilon: 0.8462054800033387    steps: 169    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 959   score: 0.0   memory length: 177795   epsilon: 0.845963920003344    steps: 122    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 960   score: 1.0   memory length: 177946   epsilon: 0.8456649400033505    steps: 151    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 961   score: 4.0   memory length: 178222   epsilon: 0.8451184600033623    steps: 276    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 962   score: 2.0   memory length: 178440   epsilon: 0.8446868200033717    steps: 218    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 963   score: 1.0   memory length: 178611   epsilon: 0.844348240003379    steps: 171    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 964   score: 2.0   memory length: 178808   epsilon: 0.8439581800033875    steps: 197    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 965   score: 2.0   memory length: 179008   epsilon: 0.8435621800033961    steps: 200    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 966   score: 2.0   memory length: 179210   epsilon: 0.8431622200034048    steps: 202    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 967   score: 0.0   memory length: 179332   epsilon: 0.84292066000341    steps: 122    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 968   score: 3.0   memory length: 179558   epsilon: 0.8424731800034198    steps: 226    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 969   score: 4.0   memory length: 179833   epsilon: 0.8419286800034316    steps: 275    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 970   score: 0.0   memory length: 179956   epsilon: 0.8416851400034369    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 971   score: 2.0   memory length: 180174   epsilon: 0.8412535000034462    steps: 218    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 972   score: 2.0   memory length: 180372   epsilon: 0.8408614600034547    steps: 198    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 973   score: 0.0   memory length: 180495   epsilon: 0.84061792000346    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 974   score: 0.0   memory length: 180618   epsilon: 0.8403743800034653    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 975   score: 2.0   memory length: 180834   epsilon: 0.8399467000034746    steps: 216    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 976   score: 2.0   memory length: 181013   epsilon: 0.8395922800034823    steps: 179    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 977   score: 3.0   memory length: 181259   epsilon: 0.8391052000034929    steps: 246    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 978   score: 0.0   memory length: 181381   epsilon: 0.8388636400034981    steps: 122    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 979   score: 2.0   memory length: 181578   epsilon: 0.8384735800035066    steps: 197    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 980   score: 7.0   memory length: 181899   epsilon: 0.8378380000035204    steps: 321    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 981   score: 3.0   memory length: 182151   epsilon: 0.8373390400035312    steps: 252    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 982   score: 2.0   memory length: 182368   epsilon: 0.8369093800035405    steps: 217    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 983   score: 0.0   memory length: 182491   epsilon: 0.8366658400035458    steps: 123    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 984   score: 4.0   memory length: 182767   epsilon: 0.8361193600035577    steps: 276    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 985   score: 3.0   memory length: 182995   epsilon: 0.8356679200035675    steps: 228    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 986   score: 2.0   memory length: 183193   epsilon: 0.835275880003576    steps: 198    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 987   score: 2.0   memory length: 183391   epsilon: 0.8348838400035845    steps: 198    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 988   score: 1.0   memory length: 183560   epsilon: 0.8345492200035918    steps: 169    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 989   score: 1.0   memory length: 183731   epsilon: 0.8342106400035991    steps: 171    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 990   score: 3.0   memory length: 183957   epsilon: 0.8337631600036088    steps: 226    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 991   score: 2.0   memory length: 184155   epsilon: 0.8333711200036173    steps: 198    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 992   score: 0.0   memory length: 184278   epsilon: 0.8331275800036226    steps: 123    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 993   score: 2.0   memory length: 184476   epsilon: 0.8327355400036311    steps: 198    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 994   score: 1.0   memory length: 184644   epsilon: 0.8324029000036384    steps: 168    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 995   score: 2.0   memory length: 184862   epsilon: 0.8319712600036477    steps: 218    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 996   score: 1.0   memory length: 185031   epsilon: 0.831636640003655    steps: 169    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 997   score: 4.0   memory length: 185314   epsilon: 0.8310763000036672    steps: 283    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 998   score: 5.0   memory length: 185638   epsilon: 0.8304347800036811    steps: 324    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 999   score: 2.0   memory length: 185855   epsilon: 0.8300051200036904    steps: 217    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 1000   score: 0.0   memory length: 185977   epsilon: 0.8297635600036957    steps: 122    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 1001   score: 1.0   memory length: 186128   epsilon: 0.8294645800037022    steps: 151    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 1002   score: 1.0   memory length: 186296   epsilon: 0.8291319400037094    steps: 168    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 1003   score: 0.0   memory length: 186419   epsilon: 0.8288884000037147    steps: 123    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 1004   score: 0.0   memory length: 186541   epsilon: 0.8286468400037199    steps: 122    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 1005   score: 2.0   memory length: 186739   epsilon: 0.8282548000037284    steps: 198    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 1006   score: 2.0   memory length: 186937   epsilon: 0.8278627600037369    steps: 198    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 1007   score: 2.0   memory length: 187134   epsilon: 0.8274727000037454    steps: 197    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 1008   score: 2.0   memory length: 187352   epsilon: 0.8270410600037548    steps: 218    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 1009   score: 0.0   memory length: 187475   epsilon: 0.8267975200037601    steps: 123    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 1010   score: 2.0   memory length: 187672   epsilon: 0.8264074600037685    steps: 197    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 1011   score: 0.0   memory length: 187795   epsilon: 0.8261639200037738    steps: 123    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1012   score: 1.0   memory length: 187964   epsilon: 0.8258293000037811    steps: 169    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 1013   score: 3.0   memory length: 188213   epsilon: 0.8253362800037918    steps: 249    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 1014   score: 1.0   memory length: 188363   epsilon: 0.8250392800037982    steps: 150    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 1015   score: 3.0   memory length: 188632   epsilon: 0.8245066600038098    steps: 269    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1016   score: 3.0   memory length: 188901   epsilon: 0.8239740400038214    steps: 269    lr: 0.0001     evaluation reward: 1.8\n",
      "episode: 1017   score: 1.0   memory length: 189069   epsilon: 0.8236414000038286    steps: 168    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 1018   score: 0.0   memory length: 189192   epsilon: 0.8233978600038339    steps: 123    lr: 0.0001     evaluation reward: 1.78\n",
      "episode: 1019   score: 3.0   memory length: 189462   epsilon: 0.8228632600038455    steps: 270    lr: 0.0001     evaluation reward: 1.79\n",
      "episode: 1020   score: 1.0   memory length: 189613   epsilon: 0.822564280003852    steps: 151    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 1021   score: 3.0   memory length: 189877   epsilon: 0.8220415600038633    steps: 264    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1022   score: 1.0   memory length: 190046   epsilon: 0.8217069400038706    steps: 169    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 1023   score: 1.0   memory length: 190196   epsilon: 0.821409940003877    steps: 150    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 1024   score: 2.0   memory length: 190412   epsilon: 0.8209822600038863    steps: 216    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 1025   score: 2.0   memory length: 190610   epsilon: 0.8205902200038948    steps: 198    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 1026   score: 1.0   memory length: 190779   epsilon: 0.8202556000039021    steps: 169    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 1027   score: 1.0   memory length: 190951   epsilon: 0.8199150400039095    steps: 172    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 1028   score: 6.0   memory length: 191330   epsilon: 0.8191646200039258    steps: 379    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 1029   score: 1.0   memory length: 191481   epsilon: 0.8188656400039322    steps: 151    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 1030   score: 4.0   memory length: 191756   epsilon: 0.8183211400039441    steps: 275    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 1031   score: 1.0   memory length: 191928   epsilon: 0.8179805800039515    steps: 172    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1032   score: 0.0   memory length: 192050   epsilon: 0.8177390200039567    steps: 122    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1033   score: 2.0   memory length: 192248   epsilon: 0.8173469800039652    steps: 198    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 1034   score: 2.0   memory length: 192446   epsilon: 0.8169549400039737    steps: 198    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 1035   score: 0.0   memory length: 192569   epsilon: 0.816711400003979    steps: 123    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 1036   score: 2.0   memory length: 192767   epsilon: 0.8163193600039875    steps: 198    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 1037   score: 1.0   memory length: 192936   epsilon: 0.8159847400039948    steps: 169    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 1038   score: 3.0   memory length: 193203   epsilon: 0.8154560800040063    steps: 267    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 1039   score: 4.0   memory length: 193500   epsilon: 0.814868020004019    steps: 297    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 1040   score: 4.0   memory length: 193776   epsilon: 0.8143215400040309    steps: 276    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 1041   score: 0.0   memory length: 193899   epsilon: 0.8140780000040362    steps: 123    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 1042   score: 2.0   memory length: 194117   epsilon: 0.8136463600040456    steps: 218    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 1043   score: 0.0   memory length: 194240   epsilon: 0.8134028200040508    steps: 123    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 1044   score: 3.0   memory length: 194486   epsilon: 0.8129157400040614    steps: 246    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 1045   score: 1.0   memory length: 194655   epsilon: 0.8125811200040687    steps: 169    lr: 0.0001     evaluation reward: 1.81\n",
      "episode: 1046   score: 3.0   memory length: 194900   epsilon: 0.8120960200040792    steps: 245    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 1047   score: 1.0   memory length: 195054   epsilon: 0.8117911000040858    steps: 154    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 1048   score: 3.0   memory length: 195303   epsilon: 0.8112980800040965    steps: 249    lr: 0.0001     evaluation reward: 1.85\n",
      "episode: 1049   score: 0.0   memory length: 195426   epsilon: 0.8110545400041018    steps: 123    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 1050   score: 2.0   memory length: 195624   epsilon: 0.8106625000041103    steps: 198    lr: 0.0001     evaluation reward: 1.84\n",
      "episode: 1051   score: 2.0   memory length: 195822   epsilon: 0.8102704600041188    steps: 198    lr: 0.0001     evaluation reward: 1.83\n",
      "episode: 1052   score: 1.0   memory length: 195993   epsilon: 0.8099318800041262    steps: 171    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 1053   score: 1.0   memory length: 196162   epsilon: 0.8095972600041335    steps: 169    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 1054   score: 0.0   memory length: 196285   epsilon: 0.8093537200041387    steps: 123    lr: 0.0001     evaluation reward: 1.82\n",
      "episode: 1055   score: 1.0   memory length: 196454   epsilon: 0.809019100004146    steps: 169    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 1056   score: 1.0   memory length: 196606   epsilon: 0.8087181400041525    steps: 152    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 1057   score: 1.0   memory length: 196777   epsilon: 0.8083795600041599    steps: 171    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 1058   score: 3.0   memory length: 197025   epsilon: 0.8078885200041706    steps: 248    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 1059   score: 0.0   memory length: 197148   epsilon: 0.8076449800041758    steps: 123    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 1060   score: 0.0   memory length: 197270   epsilon: 0.8074034200041811    steps: 122    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 1061   score: 0.0   memory length: 197393   epsilon: 0.8071598800041864    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 1062   score: 2.0   memory length: 197591   epsilon: 0.8067678400041949    steps: 198    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 1063   score: 0.0   memory length: 197714   epsilon: 0.8065243000042002    steps: 123    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 1064   score: 0.0   memory length: 197836   epsilon: 0.8062827400042054    steps: 122    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1065   score: 2.0   memory length: 198053   epsilon: 0.8058530800042147    steps: 217    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1066   score: 2.0   memory length: 198270   epsilon: 0.8054234200042241    steps: 217    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1067   score: 2.0   memory length: 198488   epsilon: 0.8049917800042334    steps: 218    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 1068   score: 0.0   memory length: 198610   epsilon: 0.8047502200042387    steps: 122    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1069   score: 2.0   memory length: 198828   epsilon: 0.804318580004248    steps: 218    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 1070   score: 0.0   memory length: 198951   epsilon: 0.8040750400042533    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 1071   score: 1.0   memory length: 199101   epsilon: 0.8037780400042598    steps: 150    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 1072   score: 1.0   memory length: 199270   epsilon: 0.803443420004267    steps: 169    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 1073   score: 0.0   memory length: 199393   epsilon: 0.8031998800042723    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 1074   score: 1.0   memory length: 199544   epsilon: 0.8029009000042788    steps: 151    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 1075   score: 2.0   memory length: 199742   epsilon: 0.8025088600042873    steps: 198    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 1076   score: 3.0   memory length: 199991   epsilon: 0.802015840004298    steps: 249    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 1077   score: 2.0   memory length: 200211   epsilon: 0.8015802400043075    steps: 220    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 1078   score: 0.0   memory length: 200334   epsilon: 0.8013367000043128    steps: 123    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 1079   score: 3.0   memory length: 200602   epsilon: 0.8008060600043243    steps: 268    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 1080   score: 2.0   memory length: 200799   epsilon: 0.8004160000043328    steps: 197    lr: 4e-05     evaluation reward: 1.59\n",
      "episode: 1081   score: 2.0   memory length: 200997   epsilon: 0.8000239600043413    steps: 198    lr: 4e-05     evaluation reward: 1.58\n",
      "episode: 1082   score: 1.0   memory length: 201148   epsilon: 0.7997249800043478    steps: 151    lr: 4e-05     evaluation reward: 1.57\n",
      "episode: 1083   score: 2.0   memory length: 201345   epsilon: 0.7993349200043562    steps: 197    lr: 4e-05     evaluation reward: 1.59\n",
      "episode: 1084   score: 1.0   memory length: 201514   epsilon: 0.7990003000043635    steps: 169    lr: 4e-05     evaluation reward: 1.56\n",
      "episode: 1085   score: 3.0   memory length: 201762   epsilon: 0.7985092600043742    steps: 248    lr: 4e-05     evaluation reward: 1.56\n",
      "episode: 1086   score: 2.0   memory length: 201980   epsilon: 0.7980776200043835    steps: 218    lr: 4e-05     evaluation reward: 1.56\n",
      "episode: 1087   score: 4.0   memory length: 202298   epsilon: 0.7974479800043972    steps: 318    lr: 4e-05     evaluation reward: 1.58\n",
      "episode: 1088   score: 2.0   memory length: 202496   epsilon: 0.7970559400044057    steps: 198    lr: 4e-05     evaluation reward: 1.59\n",
      "episode: 1089   score: 3.0   memory length: 202745   epsilon: 0.7965629200044164    steps: 249    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 1090   score: 4.0   memory length: 203062   epsilon: 0.79593526000443    steps: 317    lr: 4e-05     evaluation reward: 1.62\n",
      "episode: 1091   score: 1.0   memory length: 203213   epsilon: 0.7956362800044365    steps: 151    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 1092   score: 2.0   memory length: 203411   epsilon: 0.795244240004445    steps: 198    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 1093   score: 4.0   memory length: 203707   epsilon: 0.7946581600044578    steps: 296    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 1094   score: 3.0   memory length: 203953   epsilon: 0.7941710800044683    steps: 246    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 1095   score: 2.0   memory length: 204151   epsilon: 0.7937790400044769    steps: 198    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 1096   score: 1.0   memory length: 204301   epsilon: 0.7934820400044833    steps: 150    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 1097   score: 2.0   memory length: 204518   epsilon: 0.7930523800044926    steps: 217    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 1098   score: 3.0   memory length: 204746   epsilon: 0.7926009400045024    steps: 228    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 1099   score: 0.0   memory length: 204869   epsilon: 0.7923574000045077    steps: 123    lr: 4e-05     evaluation reward: 1.61\n",
      "episode: 1100   score: 3.0   memory length: 205116   epsilon: 0.7918683400045183    steps: 247    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 1101   score: 2.0   memory length: 205313   epsilon: 0.7914782800045268    steps: 197    lr: 4e-05     evaluation reward: 1.65\n",
      "episode: 1102   score: 2.0   memory length: 205510   epsilon: 0.7910882200045353    steps: 197    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 1103   score: 1.0   memory length: 205661   epsilon: 0.7907892400045418    steps: 151    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 1104   score: 0.0   memory length: 205783   epsilon: 0.790547680004547    steps: 122    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 1105   score: 3.0   memory length: 206028   epsilon: 0.7900625800045575    steps: 245    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 1106   score: 1.0   memory length: 206179   epsilon: 0.789763600004564    steps: 151    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 1107   score: 3.0   memory length: 206449   epsilon: 0.7892290000045756    steps: 270    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 1108   score: 1.0   memory length: 206618   epsilon: 0.7888943800045829    steps: 169    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 1109   score: 1.0   memory length: 206786   epsilon: 0.7885617400045901    steps: 168    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 1110   score: 4.0   memory length: 207085   epsilon: 0.787969720004603    steps: 299    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 1111   score: 1.0   memory length: 207236   epsilon: 0.7876707400046095    steps: 151    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 1112   score: 1.0   memory length: 207407   epsilon: 0.7873321600046168    steps: 171    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 1113   score: 2.0   memory length: 207625   epsilon: 0.7869005200046262    steps: 218    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 1114   score: 3.0   memory length: 207872   epsilon: 0.7864114600046368    steps: 247    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1115   score: 1.0   memory length: 208023   epsilon: 0.7861124800046433    steps: 151    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 1116   score: 2.0   memory length: 208221   epsilon: 0.7857204400046518    steps: 198    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 1117   score: 1.0   memory length: 208389   epsilon: 0.785387800004659    steps: 168    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 1118   score: 2.0   memory length: 208586   epsilon: 0.7849977400046675    steps: 197    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 1119   score: 0.0   memory length: 208709   epsilon: 0.7847542000046728    steps: 123    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 1120   score: 1.0   memory length: 208860   epsilon: 0.7844552200046793    steps: 151    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 1121   score: 3.0   memory length: 209106   epsilon: 0.7839681400046898    steps: 246    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 1122   score: 2.0   memory length: 209304   epsilon: 0.7835761000046984    steps: 198    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 1123   score: 2.0   memory length: 209502   epsilon: 0.7831840600047069    steps: 198    lr: 4e-05     evaluation reward: 1.7\n",
      "episode: 1124   score: 0.0   memory length: 209625   epsilon: 0.7829405200047121    steps: 123    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 1125   score: 0.0   memory length: 209748   epsilon: 0.7826969800047174    steps: 123    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 1126   score: 2.0   memory length: 209968   epsilon: 0.7822613800047269    steps: 220    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 1127   score: 2.0   memory length: 210186   epsilon: 0.7818297400047363    steps: 218    lr: 4e-05     evaluation reward: 1.68\n",
      "episode: 1128   score: 1.0   memory length: 210355   epsilon: 0.7814951200047435    steps: 169    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 1129   score: 4.0   memory length: 210613   epsilon: 0.7809842800047546    steps: 258    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 1130   score: 1.0   memory length: 210784   epsilon: 0.780645700004762    steps: 171    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 1131   score: 1.0   memory length: 210935   epsilon: 0.7803467200047685    steps: 151    lr: 4e-05     evaluation reward: 1.63\n",
      "episode: 1132   score: 1.0   memory length: 211106   epsilon: 0.7800081400047758    steps: 171    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 1133   score: 2.0   memory length: 211304   epsilon: 0.7796161000047843    steps: 198    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 1134   score: 2.0   memory length: 211520   epsilon: 0.7791884200047936    steps: 216    lr: 4e-05     evaluation reward: 1.64\n",
      "episode: 1135   score: 3.0   memory length: 211766   epsilon: 0.7787013400048042    steps: 246    lr: 4e-05     evaluation reward: 1.67\n",
      "episode: 1136   score: 1.0   memory length: 211917   epsilon: 0.7784023600048107    steps: 151    lr: 4e-05     evaluation reward: 1.66\n",
      "episode: 1137   score: 4.0   memory length: 212196   epsilon: 0.7778499400048227    steps: 279    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 1138   score: 8.0   memory length: 212655   epsilon: 0.7769411200048424    steps: 459    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1139   score: 1.0   memory length: 212824   epsilon: 0.7766065000048497    steps: 169    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 1140   score: 2.0   memory length: 213041   epsilon: 0.776176840004859    steps: 217    lr: 4e-05     evaluation reward: 1.69\n",
      "episode: 1141   score: 3.0   memory length: 213266   epsilon: 0.7757313400048687    steps: 225    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1142   score: 3.0   memory length: 213513   epsilon: 0.7752422800048793    steps: 247    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 1143   score: 1.0   memory length: 213663   epsilon: 0.7749452800048857    steps: 150    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1144   score: 2.0   memory length: 213860   epsilon: 0.7745552200048942    steps: 197    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 1145   score: 4.0   memory length: 214133   epsilon: 0.7740146800049059    steps: 273    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1146   score: 1.0   memory length: 214302   epsilon: 0.7736800600049132    steps: 169    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1147   score: 2.0   memory length: 214520   epsilon: 0.7732484200049226    steps: 218    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1148   score: 2.0   memory length: 214739   epsilon: 0.772814800004932    steps: 219    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1149   score: 3.0   memory length: 214983   epsilon: 0.7723316800049425    steps: 244    lr: 4e-05     evaluation reward: 1.77\n",
      "episode: 1150   score: 5.0   memory length: 215328   epsilon: 0.7716485800049573    steps: 345    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1151   score: 2.0   memory length: 215526   epsilon: 0.7712565400049658    steps: 198    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1152   score: 1.0   memory length: 215697   epsilon: 0.7709179600049731    steps: 171    lr: 4e-05     evaluation reward: 1.8\n",
      "episode: 1153   score: 2.0   memory length: 215895   epsilon: 0.7705259200049817    steps: 198    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1154   score: 2.0   memory length: 216113   epsilon: 0.770094280004991    steps: 218    lr: 4e-05     evaluation reward: 1.83\n",
      "episode: 1155   score: 4.0   memory length: 216374   epsilon: 0.7695775000050022    steps: 261    lr: 4e-05     evaluation reward: 1.86\n",
      "episode: 1156   score: 2.0   memory length: 216556   epsilon: 0.7692171400050101    steps: 182    lr: 4e-05     evaluation reward: 1.87\n",
      "episode: 1157   score: 2.0   memory length: 216754   epsilon: 0.7688251000050186    steps: 198    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 1158   score: 3.0   memory length: 216980   epsilon: 0.7683776200050283    steps: 226    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 1159   score: 2.0   memory length: 217178   epsilon: 0.7679855800050368    steps: 198    lr: 4e-05     evaluation reward: 1.9\n",
      "episode: 1160   score: 5.0   memory length: 217527   epsilon: 0.7672945600050518    steps: 349    lr: 4e-05     evaluation reward: 1.95\n",
      "episode: 1161   score: 10.0   memory length: 217964   epsilon: 0.7664293000050706    steps: 437    lr: 4e-05     evaluation reward: 2.05\n",
      "episode: 1162   score: 2.0   memory length: 218182   epsilon: 0.76599766000508    steps: 218    lr: 4e-05     evaluation reward: 2.05\n",
      "episode: 1163   score: 2.0   memory length: 218380   epsilon: 0.7656056200050885    steps: 198    lr: 4e-05     evaluation reward: 2.07\n",
      "episode: 1164   score: 3.0   memory length: 218645   epsilon: 0.7650809200050999    steps: 265    lr: 4e-05     evaluation reward: 2.1\n",
      "episode: 1165   score: 3.0   memory length: 218892   epsilon: 0.7645918600051105    steps: 247    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1166   score: 2.0   memory length: 219090   epsilon: 0.764199820005119    steps: 198    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1167   score: 4.0   memory length: 219366   epsilon: 0.7636533400051309    steps: 276    lr: 4e-05     evaluation reward: 2.13\n",
      "episode: 1168   score: 2.0   memory length: 219564   epsilon: 0.7632613000051394    steps: 198    lr: 4e-05     evaluation reward: 2.15\n",
      "episode: 1169   score: 3.0   memory length: 219809   epsilon: 0.7627762000051499    steps: 245    lr: 4e-05     evaluation reward: 2.16\n",
      "episode: 1170   score: 2.0   memory length: 220007   epsilon: 0.7623841600051584    steps: 198    lr: 4e-05     evaluation reward: 2.18\n",
      "episode: 1171   score: 3.0   memory length: 220236   epsilon: 0.7619307400051682    steps: 229    lr: 4e-05     evaluation reward: 2.2\n",
      "episode: 1172   score: 2.0   memory length: 220434   epsilon: 0.7615387000051768    steps: 198    lr: 4e-05     evaluation reward: 2.21\n",
      "episode: 1173   score: 1.0   memory length: 220603   epsilon: 0.761204080005184    steps: 169    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1174   score: 4.0   memory length: 220859   epsilon: 0.760697200005195    steps: 256    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1175   score: 4.0   memory length: 221156   epsilon: 0.7601091400052078    steps: 297    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1176   score: 0.0   memory length: 221278   epsilon: 0.759867580005213    steps: 122    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1177   score: 0.0   memory length: 221401   epsilon: 0.7596240400052183    steps: 123    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1178   score: 0.0   memory length: 221524   epsilon: 0.7593805000052236    steps: 123    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1179   score: 2.0   memory length: 221744   epsilon: 0.7589449000052331    steps: 220    lr: 4e-05     evaluation reward: 2.21\n",
      "episode: 1180   score: 2.0   memory length: 221926   epsilon: 0.7585845400052409    steps: 182    lr: 4e-05     evaluation reward: 2.21\n",
      "episode: 1181   score: 1.0   memory length: 222077   epsilon: 0.7582855600052474    steps: 151    lr: 4e-05     evaluation reward: 2.2\n",
      "episode: 1182   score: 3.0   memory length: 222322   epsilon: 0.7578004600052579    steps: 245    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1183   score: 2.0   memory length: 222520   epsilon: 0.7574084200052664    steps: 198    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1184   score: 2.0   memory length: 222737   epsilon: 0.7569787600052758    steps: 217    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 1185   score: 2.0   memory length: 222935   epsilon: 0.7565867200052843    steps: 198    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1186   score: 3.0   memory length: 223188   epsilon: 0.7560857800052951    steps: 253    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 1187   score: 5.0   memory length: 223534   epsilon: 0.75540070000531    steps: 346    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1188   score: 6.0   memory length: 223875   epsilon: 0.7547255200053247    steps: 341    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1189   score: 2.0   memory length: 224073   epsilon: 0.7543334800053332    steps: 198    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1190   score: 2.0   memory length: 224271   epsilon: 0.7539414400053417    steps: 198    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1191   score: 2.0   memory length: 224490   epsilon: 0.7535078200053511    steps: 219    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1192   score: 0.0   memory length: 224613   epsilon: 0.7532642800053564    steps: 123    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1193   score: 1.0   memory length: 224767   epsilon: 0.752959360005363    steps: 154    lr: 4e-05     evaluation reward: 2.21\n",
      "episode: 1194   score: 3.0   memory length: 225022   epsilon: 0.752454460005374    steps: 255    lr: 4e-05     evaluation reward: 2.21\n",
      "episode: 1195   score: 4.0   memory length: 225336   epsilon: 0.7518327400053875    steps: 314    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 1196   score: 3.0   memory length: 225607   epsilon: 0.7512961600053991    steps: 271    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1197   score: 0.0   memory length: 225730   epsilon: 0.7510526200054044    steps: 123    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 1198   score: 5.0   memory length: 226055   epsilon: 0.7504091200054184    steps: 325    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1199   score: 7.0   memory length: 226376   epsilon: 0.7497735400054322    steps: 321    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1200   score: 2.0   memory length: 226573   epsilon: 0.7493834800054406    steps: 197    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1201   score: 2.0   memory length: 226775   epsilon: 0.7489835200054493    steps: 202    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1202   score: 2.0   memory length: 226973   epsilon: 0.7485914800054578    steps: 198    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1203   score: 3.0   memory length: 227218   epsilon: 0.7481063800054684    steps: 245    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1204   score: 1.0   memory length: 227388   epsilon: 0.7477697800054757    steps: 170    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1205   score: 2.0   memory length: 227608   epsilon: 0.7473341800054851    steps: 220    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1206   score: 2.0   memory length: 227806   epsilon: 0.7469421400054936    steps: 198    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1207   score: 1.0   memory length: 227976   epsilon: 0.746605540005501    steps: 170    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1208   score: 2.0   memory length: 228192   epsilon: 0.7461778600055102    steps: 216    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1209   score: 3.0   memory length: 228439   epsilon: 0.7456888000055208    steps: 247    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 1210   score: 3.0   memory length: 228665   epsilon: 0.7452413200055306    steps: 226    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1211   score: 3.0   memory length: 228893   epsilon: 0.7447898800055404    steps: 228    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1212   score: 3.0   memory length: 229119   epsilon: 0.7443424000055501    steps: 226    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1213   score: 2.0   memory length: 229300   epsilon: 0.7439840200055579    steps: 181    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1214   score: 2.0   memory length: 229481   epsilon: 0.7436256400055656    steps: 181    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1215   score: 2.0   memory length: 229682   epsilon: 0.7432276600055743    steps: 201    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1216   score: 2.0   memory length: 229881   epsilon: 0.7428336400055828    steps: 199    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1217   score: 1.0   memory length: 230032   epsilon: 0.7425346600055893    steps: 151    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1218   score: 2.0   memory length: 230230   epsilon: 0.7421426200055978    steps: 198    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1219   score: 2.0   memory length: 230447   epsilon: 0.7417129600056072    steps: 217    lr: 4e-05     evaluation reward: 2.4\n",
      "episode: 1220   score: 1.0   memory length: 230598   epsilon: 0.7414139800056136    steps: 151    lr: 4e-05     evaluation reward: 2.4\n",
      "episode: 1221   score: 2.0   memory length: 230796   epsilon: 0.7410219400056222    steps: 198    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1222   score: 2.0   memory length: 230994   epsilon: 0.7406299000056307    steps: 198    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1223   score: 2.0   memory length: 231191   epsilon: 0.7402398400056391    steps: 197    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1224   score: 3.0   memory length: 231438   epsilon: 0.7397507800056498    steps: 247    lr: 4e-05     evaluation reward: 2.42\n",
      "episode: 1225   score: 2.0   memory length: 231636   epsilon: 0.7393587400056583    steps: 198    lr: 4e-05     evaluation reward: 2.44\n",
      "episode: 1226   score: 3.0   memory length: 231862   epsilon: 0.738911260005668    steps: 226    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1227   score: 1.0   memory length: 232013   epsilon: 0.7386122800056745    steps: 151    lr: 4e-05     evaluation reward: 2.44\n",
      "episode: 1228   score: 3.0   memory length: 232282   epsilon: 0.738079660005686    steps: 269    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1229   score: 2.0   memory length: 232480   epsilon: 0.7376876200056945    steps: 198    lr: 4e-05     evaluation reward: 2.44\n",
      "episode: 1230   score: 1.0   memory length: 232651   epsilon: 0.7373490400057019    steps: 171    lr: 4e-05     evaluation reward: 2.44\n",
      "episode: 1231   score: 2.0   memory length: 232849   epsilon: 0.7369570000057104    steps: 198    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1232   score: 4.0   memory length: 233145   epsilon: 0.7363709200057231    steps: 296    lr: 4e-05     evaluation reward: 2.48\n",
      "episode: 1233   score: 0.0   memory length: 233267   epsilon: 0.7361293600057284    steps: 122    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1234   score: 2.0   memory length: 233465   epsilon: 0.7357373200057369    steps: 198    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1235   score: 3.0   memory length: 233711   epsilon: 0.7352502400057475    steps: 246    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1236   score: 0.0   memory length: 233834   epsilon: 0.7350067000057527    steps: 123    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1237   score: 2.0   memory length: 234049   epsilon: 0.734581000005762    steps: 215    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1238   score: 3.0   memory length: 234275   epsilon: 0.7341335200057717    steps: 226    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1239   score: 2.0   memory length: 234473   epsilon: 0.7337414800057802    steps: 198    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1240   score: 2.0   memory length: 234672   epsilon: 0.7333474600057888    steps: 199    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1241   score: 2.0   memory length: 234870   epsilon: 0.7329554200057973    steps: 198    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1242   score: 2.0   memory length: 235068   epsilon: 0.7325633800058058    steps: 198    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1243   score: 3.0   memory length: 235297   epsilon: 0.7321099600058156    steps: 229    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1244   score: 2.0   memory length: 235514   epsilon: 0.731680300005825    steps: 217    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1245   score: 3.0   memory length: 235761   epsilon: 0.7311912400058356    steps: 247    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1246   score: 0.0   memory length: 235884   epsilon: 0.7309477000058409    steps: 123    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1247   score: 3.0   memory length: 236112   epsilon: 0.7304962600058507    steps: 228    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1248   score: 3.0   memory length: 236357   epsilon: 0.7300111600058612    steps: 245    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1249   score: 1.0   memory length: 236526   epsilon: 0.7296765400058685    steps: 169    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1250   score: 2.0   memory length: 236724   epsilon: 0.729284500005877    steps: 198    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1251   score: 4.0   memory length: 237020   epsilon: 0.7286984200058897    steps: 296    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1252   score: 0.0   memory length: 237143   epsilon: 0.728454880005895    steps: 123    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 1253   score: 7.0   memory length: 237543   epsilon: 0.7276628800059122    steps: 400    lr: 4e-05     evaluation reward: 2.4\n",
      "episode: 1254   score: 3.0   memory length: 237788   epsilon: 0.7271777800059227    steps: 245    lr: 4e-05     evaluation reward: 2.41\n",
      "episode: 1255   score: 2.0   memory length: 237985   epsilon: 0.7267877200059312    steps: 197    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1256   score: 6.0   memory length: 238321   epsilon: 0.7261224400059456    steps: 336    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1257   score: 0.0   memory length: 238443   epsilon: 0.7258808800059509    steps: 122    lr: 4e-05     evaluation reward: 2.41\n",
      "episode: 1258   score: 2.0   memory length: 238641   epsilon: 0.7254888400059594    steps: 198    lr: 4e-05     evaluation reward: 2.4\n",
      "episode: 1259   score: 0.0   memory length: 238764   epsilon: 0.7252453000059647    steps: 123    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1260   score: 4.0   memory length: 239052   epsilon: 0.724675060005977    steps: 288    lr: 4e-05     evaluation reward: 2.37\n",
      "episode: 1261   score: 3.0   memory length: 239297   epsilon: 0.7241899600059876    steps: 245    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1262   score: 1.0   memory length: 239448   epsilon: 0.7238909800059941    steps: 151    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1263   score: 1.0   memory length: 239600   epsilon: 0.7235900200060006    steps: 152    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1264   score: 2.0   memory length: 239818   epsilon: 0.72315838000601    steps: 218    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1265   score: 3.0   memory length: 240066   epsilon: 0.7226673400060206    steps: 248    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1266   score: 6.0   memory length: 240433   epsilon: 0.7219406800060364    steps: 367    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1267   score: 2.0   memory length: 240613   epsilon: 0.7215842800060441    steps: 180    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1268   score: 2.0   memory length: 240811   epsilon: 0.7211922400060526    steps: 198    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1269   score: 3.0   memory length: 241057   epsilon: 0.7207051600060632    steps: 246    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1270   score: 0.0   memory length: 241179   epsilon: 0.7204636000060685    steps: 122    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1271   score: 3.0   memory length: 241425   epsilon: 0.719976520006079    steps: 246    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1272   score: 1.0   memory length: 241576   epsilon: 0.7196775400060855    steps: 151    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1273   score: 2.0   memory length: 241774   epsilon: 0.719285500006094    steps: 198    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1274   score: 3.0   memory length: 242000   epsilon: 0.7188380200061038    steps: 226    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1275   score: 2.0   memory length: 242218   epsilon: 0.7184063800061131    steps: 218    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1276   score: 2.0   memory length: 242415   epsilon: 0.7180163200061216    steps: 197    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1277   score: 3.0   memory length: 242641   epsilon: 0.7175688400061313    steps: 226    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1278   score: 1.0   memory length: 242792   epsilon: 0.7172698600061378    steps: 151    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1279   score: 1.0   memory length: 242944   epsilon: 0.7169689000061443    steps: 152    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1280   score: 4.0   memory length: 243240   epsilon: 0.716382820006157    steps: 296    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1281   score: 3.0   memory length: 243487   epsilon: 0.7158937600061677    steps: 247    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1282   score: 4.0   memory length: 243760   epsilon: 0.7153532200061794    steps: 273    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1283   score: 3.0   memory length: 243971   epsilon: 0.7149354400061885    steps: 211    lr: 4e-05     evaluation reward: 2.35\n",
      "episode: 1284   score: 1.0   memory length: 244141   epsilon: 0.7145988400061958    steps: 170    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1285   score: 2.0   memory length: 244360   epsilon: 0.7141652200062052    steps: 219    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1286   score: 3.0   memory length: 244586   epsilon: 0.7137177400062149    steps: 226    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1287   score: 3.0   memory length: 244852   epsilon: 0.7131910600062263    steps: 266    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1288   score: 3.0   memory length: 245080   epsilon: 0.7127396200062361    steps: 228    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1289   score: 1.0   memory length: 245231   epsilon: 0.7124406400062426    steps: 151    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1290   score: 2.0   memory length: 245452   epsilon: 0.7120030600062521    steps: 221    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1291   score: 3.0   memory length: 245719   epsilon: 0.7114744000062636    steps: 267    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1292   score: 2.0   memory length: 245916   epsilon: 0.7110843400062721    steps: 197    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1293   score: 2.0   memory length: 246114   epsilon: 0.7106923000062806    steps: 198    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1294   score: 2.0   memory length: 246312   epsilon: 0.7103002600062891    steps: 198    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1295   score: 0.0   memory length: 246434   epsilon: 0.7100587000062943    steps: 122    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1296   score: 2.0   memory length: 246649   epsilon: 0.7096330000063036    steps: 215    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1297   score: 2.0   memory length: 246846   epsilon: 0.709242940006312    steps: 197    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1298   score: 6.0   memory length: 247240   epsilon: 0.708462820006329    steps: 394    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1299   score: 0.0   memory length: 247363   epsilon: 0.7082192800063343    steps: 123    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1300   score: 2.0   memory length: 247561   epsilon: 0.7078272400063428    steps: 198    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1301   score: 2.0   memory length: 247758   epsilon: 0.7074371800063513    steps: 197    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1302   score: 4.0   memory length: 248054   epsilon: 0.706851100006364    steps: 296    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1303   score: 2.0   memory length: 248251   epsilon: 0.7064610400063724    steps: 197    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 1304   score: 3.0   memory length: 248498   epsilon: 0.7059719800063831    steps: 247    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1305   score: 2.0   memory length: 248696   epsilon: 0.7055799400063916    steps: 198    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1306   score: 4.0   memory length: 248990   epsilon: 0.7049978200064042    steps: 294    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1307   score: 2.0   memory length: 249190   epsilon: 0.7046018200064128    steps: 200    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1308   score: 3.0   memory length: 249416   epsilon: 0.7041543400064225    steps: 226    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1309   score: 5.0   memory length: 249709   epsilon: 0.7035742000064351    steps: 293    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1310   score: 3.0   memory length: 249975   epsilon: 0.7030475200064465    steps: 266    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1311   score: 3.0   memory length: 250204   epsilon: 0.7025941000064564    steps: 229    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1312   score: 3.0   memory length: 250430   epsilon: 0.7021466200064661    steps: 226    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1313   score: 0.0   memory length: 250552   epsilon: 0.7019050600064713    steps: 122    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1314   score: 5.0   memory length: 250889   epsilon: 0.7012378000064858    steps: 337    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1315   score: 2.0   memory length: 251087   epsilon: 0.7008457600064943    steps: 198    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1316   score: 0.0   memory length: 251210   epsilon: 0.7006022200064996    steps: 123    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1317   score: 0.0   memory length: 251332   epsilon: 0.7003606600065049    steps: 122    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1318   score: 6.0   memory length: 251675   epsilon: 0.6996815200065196    steps: 343    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1319   score: 1.0   memory length: 251847   epsilon: 0.699340960006527    steps: 172    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1320   score: 2.0   memory length: 252045   epsilon: 0.6989489200065355    steps: 198    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1321   score: 2.0   memory length: 252245   epsilon: 0.6985529200065441    steps: 200    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1322   score: 2.0   memory length: 252443   epsilon: 0.6981608800065526    steps: 198    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1323   score: 0.0   memory length: 252566   epsilon: 0.6979173400065579    steps: 123    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1324   score: 3.0   memory length: 252799   epsilon: 0.6974560000065679    steps: 233    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1325   score: 3.0   memory length: 253046   epsilon: 0.6969669400065786    steps: 247    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1326   score: 0.0   memory length: 253169   epsilon: 0.6967234000065838    steps: 123    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1327   score: 3.0   memory length: 253415   epsilon: 0.6962363200065944    steps: 246    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1328   score: 0.0   memory length: 253537   epsilon: 0.6959947600065997    steps: 122    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1329   score: 3.0   memory length: 253763   epsilon: 0.6955472800066094    steps: 226    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1330   score: 3.0   memory length: 254031   epsilon: 0.6950166400066209    steps: 268    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1331   score: 0.0   memory length: 254154   epsilon: 0.6947731000066262    steps: 123    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1332   score: 3.0   memory length: 254399   epsilon: 0.6942880000066367    steps: 245    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1333   score: 2.0   memory length: 254596   epsilon: 0.6938979400066452    steps: 197    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1334   score: 5.0   memory length: 254920   epsilon: 0.6932564200066591    steps: 324    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1335   score: 2.0   memory length: 255118   epsilon: 0.6928643800066676    steps: 198    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1336   score: 2.0   memory length: 255315   epsilon: 0.6924743200066761    steps: 197    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1337   score: 0.0   memory length: 255438   epsilon: 0.6922307800066814    steps: 123    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1338   score: 5.0   memory length: 255744   epsilon: 0.6916249000066945    steps: 306    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1339   score: 2.0   memory length: 255942   epsilon: 0.691232860006703    steps: 198    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1340   score: 4.0   memory length: 256237   epsilon: 0.6906487600067157    steps: 295    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1341   score: 5.0   memory length: 256561   epsilon: 0.6900072400067296    steps: 324    lr: 4e-05     evaluation reward: 2.39\n",
      "episode: 1342   score: 3.0   memory length: 256808   epsilon: 0.6895181800067403    steps: 247    lr: 4e-05     evaluation reward: 2.4\n",
      "episode: 1343   score: 3.0   memory length: 257034   epsilon: 0.68907070000675    steps: 226    lr: 4e-05     evaluation reward: 2.4\n",
      "episode: 1344   score: 4.0   memory length: 257291   epsilon: 0.688561840006761    steps: 257    lr: 4e-05     evaluation reward: 2.42\n",
      "episode: 1345   score: 2.0   memory length: 257488   epsilon: 0.6881717800067695    steps: 197    lr: 4e-05     evaluation reward: 2.41\n",
      "episode: 1346   score: 4.0   memory length: 257765   epsilon: 0.6876233200067814    steps: 277    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1347   score: 3.0   memory length: 258011   epsilon: 0.687136240006792    steps: 246    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1348   score: 3.0   memory length: 258258   epsilon: 0.6866471800068026    steps: 247    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1349   score: 2.0   memory length: 258456   epsilon: 0.6862551400068111    steps: 198    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1350   score: 2.0   memory length: 258654   epsilon: 0.6858631000068196    steps: 198    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1351   score: 3.0   memory length: 258923   epsilon: 0.6853304800068312    steps: 269    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1352   score: 0.0   memory length: 259046   epsilon: 0.6850869400068365    steps: 123    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1353   score: 4.0   memory length: 259325   epsilon: 0.6845345200068484    steps: 279    lr: 4e-05     evaluation reward: 2.42\n",
      "episode: 1354   score: 3.0   memory length: 259551   epsilon: 0.6840870400068582    steps: 226    lr: 4e-05     evaluation reward: 2.42\n",
      "episode: 1355   score: 3.0   memory length: 259777   epsilon: 0.6836395600068679    steps: 226    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1356   score: 1.0   memory length: 259947   epsilon: 0.6833029600068752    steps: 170    lr: 4e-05     evaluation reward: 2.38\n",
      "episode: 1357   score: 2.0   memory length: 260168   epsilon: 0.6828653800068847    steps: 221    lr: 4e-05     evaluation reward: 2.4\n",
      "episode: 1358   score: 2.0   memory length: 260365   epsilon: 0.6824753200068931    steps: 197    lr: 4e-05     evaluation reward: 2.4\n",
      "episode: 1359   score: 4.0   memory length: 260660   epsilon: 0.6818912200069058    steps: 295    lr: 4e-05     evaluation reward: 2.44\n",
      "episode: 1360   score: 3.0   memory length: 260907   epsilon: 0.6814021600069164    steps: 247    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1361   score: 6.0   memory length: 261217   epsilon: 0.6807883600069298    steps: 310    lr: 4e-05     evaluation reward: 2.46\n",
      "episode: 1362   score: 5.0   memory length: 261564   epsilon: 0.6801013000069447    steps: 347    lr: 4e-05     evaluation reward: 2.5\n",
      "episode: 1363   score: 3.0   memory length: 261797   epsilon: 0.6796399600069547    steps: 233    lr: 4e-05     evaluation reward: 2.52\n",
      "episode: 1364   score: 1.0   memory length: 261965   epsilon: 0.6793073200069619    steps: 168    lr: 4e-05     evaluation reward: 2.51\n",
      "episode: 1365   score: 2.0   memory length: 262162   epsilon: 0.6789172600069704    steps: 197    lr: 4e-05     evaluation reward: 2.5\n",
      "episode: 1366   score: 9.0   memory length: 262671   epsilon: 0.6779094400069923    steps: 509    lr: 4e-05     evaluation reward: 2.53\n",
      "episode: 1367   score: 3.0   memory length: 262939   epsilon: 0.6773788000070038    steps: 268    lr: 4e-05     evaluation reward: 2.54\n",
      "episode: 1368   score: 3.0   memory length: 263208   epsilon: 0.6768461800070154    steps: 269    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1369   score: 3.0   memory length: 263434   epsilon: 0.6763987000070251    steps: 226    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1370   score: 2.0   memory length: 263632   epsilon: 0.6760066600070336    steps: 198    lr: 4e-05     evaluation reward: 2.57\n",
      "episode: 1371   score: 2.0   memory length: 263830   epsilon: 0.6756146200070421    steps: 198    lr: 4e-05     evaluation reward: 2.56\n",
      "episode: 1372   score: 6.0   memory length: 264156   epsilon: 0.6749691400070561    steps: 326    lr: 4e-05     evaluation reward: 2.61\n",
      "episode: 1373   score: 1.0   memory length: 264307   epsilon: 0.6746701600070626    steps: 151    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1374   score: 2.0   memory length: 264487   epsilon: 0.6743137600070703    steps: 180    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1375   score: 4.0   memory length: 264764   epsilon: 0.6737653000070822    steps: 277    lr: 4e-05     evaluation reward: 2.61\n",
      "episode: 1376   score: 1.0   memory length: 264934   epsilon: 0.6734287000070895    steps: 170    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1377   score: 1.0   memory length: 265084   epsilon: 0.673131700007096    steps: 150    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1378   score: 5.0   memory length: 265409   epsilon: 0.67248820000711    steps: 325    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1379   score: 3.0   memory length: 265620   epsilon: 0.672070420007119    steps: 211    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1380   score: 0.0   memory length: 265742   epsilon: 0.6718288600071243    steps: 122    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1381   score: 3.0   memory length: 265991   epsilon: 0.671335840007135    steps: 249    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1382   score: 2.0   memory length: 266190   epsilon: 0.6709418200071435    steps: 199    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1383   score: 0.0   memory length: 266313   epsilon: 0.6706982800071488    steps: 123    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1384   score: 3.0   memory length: 266559   epsilon: 0.6702112000071594    steps: 246    lr: 4e-05     evaluation reward: 2.57\n",
      "episode: 1385   score: 4.0   memory length: 266851   epsilon: 0.6696330400071719    steps: 292    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1386   score: 3.0   memory length: 267120   epsilon: 0.6691004200071835    steps: 269    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1387   score: 7.0   memory length: 267515   epsilon: 0.6683183200072005    steps: 395    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1388   score: 3.0   memory length: 267762   epsilon: 0.6678292600072111    steps: 247    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1389   score: 3.0   memory length: 268009   epsilon: 0.6673402000072217    steps: 247    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1390   score: 3.0   memory length: 268238   epsilon: 0.6668867800072316    steps: 229    lr: 4e-05     evaluation reward: 2.66\n",
      "episode: 1391   score: 1.0   memory length: 268407   epsilon: 0.6665521600072388    steps: 169    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1392   score: 2.0   memory length: 268627   epsilon: 0.6661165600072483    steps: 220    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1393   score: 3.0   memory length: 268853   epsilon: 0.665669080007258    steps: 226    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1394   score: 5.0   memory length: 269160   epsilon: 0.6650612200072712    steps: 307    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1395   score: 4.0   memory length: 269459   epsilon: 0.664469200007284    steps: 299    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1396   score: 2.0   memory length: 269657   epsilon: 0.6640771600072926    steps: 198    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1397   score: 2.0   memory length: 269856   epsilon: 0.6636831400073011    steps: 199    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1398   score: 2.0   memory length: 270053   epsilon: 0.6632930800073096    steps: 197    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1399   score: 6.0   memory length: 270428   epsilon: 0.6625505800073257    steps: 375    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1400   score: 3.0   memory length: 270675   epsilon: 0.6620615200073363    steps: 247    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1401   score: 5.0   memory length: 270965   epsilon: 0.6614873200073488    steps: 290    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1402   score: 5.0   memory length: 271315   epsilon: 0.6607943200073638    steps: 350    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1403   score: 4.0   memory length: 271614   epsilon: 0.6602023000073767    steps: 299    lr: 4e-05     evaluation reward: 2.81\n",
      "episode: 1404   score: 2.0   memory length: 271811   epsilon: 0.6598122400073851    steps: 197    lr: 4e-05     evaluation reward: 2.8\n",
      "episode: 1405   score: 3.0   memory length: 272022   epsilon: 0.6593944600073942    steps: 211    lr: 4e-05     evaluation reward: 2.81\n",
      "episode: 1406   score: 2.0   memory length: 272241   epsilon: 0.6589608400074036    steps: 219    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1407   score: 4.0   memory length: 272509   epsilon: 0.6584302000074151    steps: 268    lr: 4e-05     evaluation reward: 2.81\n",
      "episode: 1408   score: 0.0   memory length: 272632   epsilon: 0.6581866600074204    steps: 123    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1409   score: 3.0   memory length: 272901   epsilon: 0.657654040007432    steps: 269    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1410   score: 4.0   memory length: 273175   epsilon: 0.6571115200074438    steps: 274    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1411   score: 3.0   memory length: 273421   epsilon: 0.6566244400074543    steps: 246    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1412   score: 1.0   memory length: 273593   epsilon: 0.6562838800074617    steps: 172    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1413   score: 3.0   memory length: 273819   epsilon: 0.6558364000074715    steps: 226    lr: 4e-05     evaluation reward: 2.78\n",
      "episode: 1414   score: 3.0   memory length: 274045   epsilon: 0.6553889200074812    steps: 226    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1415   score: 2.0   memory length: 274263   epsilon: 0.6549572800074905    steps: 218    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1416   score: 3.0   memory length: 274510   epsilon: 0.6544682200075012    steps: 247    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1417   score: 4.0   memory length: 274826   epsilon: 0.6538425400075147    steps: 316    lr: 4e-05     evaluation reward: 2.83\n",
      "episode: 1418   score: 5.0   memory length: 275129   epsilon: 0.6532426000075278    steps: 303    lr: 4e-05     evaluation reward: 2.82\n",
      "episode: 1419   score: 2.0   memory length: 275327   epsilon: 0.6528505600075363    steps: 198    lr: 4e-05     evaluation reward: 2.83\n",
      "episode: 1420   score: 3.0   memory length: 275571   epsilon: 0.6523674400075468    steps: 244    lr: 4e-05     evaluation reward: 2.84\n",
      "episode: 1421   score: 4.0   memory length: 275887   epsilon: 0.6517417600075603    steps: 316    lr: 4e-05     evaluation reward: 2.86\n",
      "episode: 1422   score: 3.0   memory length: 276131   epsilon: 0.6512586400075708    steps: 244    lr: 4e-05     evaluation reward: 2.87\n",
      "episode: 1423   score: 3.0   memory length: 276379   epsilon: 0.6507676000075815    steps: 248    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1424   score: 2.0   memory length: 276579   epsilon: 0.6503716000075901    steps: 200    lr: 4e-05     evaluation reward: 2.89\n",
      "episode: 1425   score: 2.0   memory length: 276803   epsilon: 0.6499280800075997    steps: 224    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1426   score: 3.0   memory length: 277072   epsilon: 0.6493954600076113    steps: 269    lr: 4e-05     evaluation reward: 2.91\n",
      "episode: 1427   score: 4.0   memory length: 277368   epsilon: 0.648809380007624    steps: 296    lr: 4e-05     evaluation reward: 2.92\n",
      "episode: 1428   score: 4.0   memory length: 277644   epsilon: 0.6482629000076359    steps: 276    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1429   score: 2.0   memory length: 277842   epsilon: 0.6478708600076444    steps: 198    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1430   score: 2.0   memory length: 278042   epsilon: 0.647474860007653    steps: 200    lr: 4e-05     evaluation reward: 2.94\n",
      "episode: 1431   score: 4.0   memory length: 278338   epsilon: 0.6468887800076657    steps: 296    lr: 4e-05     evaluation reward: 2.98\n",
      "episode: 1432   score: 1.0   memory length: 278490   epsilon: 0.6465878200076722    steps: 152    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1433   score: 3.0   memory length: 278737   epsilon: 0.6460987600076828    steps: 247    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1434   score: 0.0   memory length: 278860   epsilon: 0.6458552200076881    steps: 123    lr: 4e-05     evaluation reward: 2.92\n",
      "episode: 1435   score: 3.0   memory length: 279086   epsilon: 0.6454077400076978    steps: 226    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1436   score: 2.0   memory length: 279268   epsilon: 0.6450473800077057    steps: 182    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1437   score: 4.0   memory length: 279545   epsilon: 0.6444989200077176    steps: 277    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1438   score: 4.0   memory length: 279805   epsilon: 0.6439841200077288    steps: 260    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1439   score: 3.0   memory length: 280036   epsilon: 0.6435267400077387    steps: 231    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1440   score: 2.0   memory length: 280233   epsilon: 0.6431366800077472    steps: 197    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1441   score: 5.0   memory length: 280524   epsilon: 0.6425605000077597    steps: 291    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1442   score: 4.0   memory length: 280799   epsilon: 0.6420160000077715    steps: 275    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1443   score: 6.0   memory length: 281173   epsilon: 0.6412754800077876    steps: 374    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1444   score: 5.0   memory length: 281523   epsilon: 0.6405824800078026    steps: 350    lr: 4e-05     evaluation reward: 3.0\n",
      "episode: 1445   score: 4.0   memory length: 281819   epsilon: 0.6399964000078153    steps: 296    lr: 4e-05     evaluation reward: 3.02\n",
      "episode: 1446   score: 4.0   memory length: 282097   epsilon: 0.6394459600078273    steps: 278    lr: 4e-05     evaluation reward: 3.02\n",
      "episode: 1447   score: 1.0   memory length: 282250   epsilon: 0.6391430200078339    steps: 153    lr: 4e-05     evaluation reward: 3.0\n",
      "episode: 1448   score: 3.0   memory length: 282476   epsilon: 0.6386955400078436    steps: 226    lr: 4e-05     evaluation reward: 3.0\n",
      "episode: 1449   score: 1.0   memory length: 282627   epsilon: 0.6383965600078501    steps: 151    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1450   score: 0.0   memory length: 282749   epsilon: 0.6381550000078553    steps: 122    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1451   score: 6.0   memory length: 283088   epsilon: 0.6374837800078699    steps: 339    lr: 4e-05     evaluation reward: 3.0\n",
      "episode: 1452   score: 4.0   memory length: 283338   epsilon: 0.6369887800078806    steps: 250    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1453   score: 3.0   memory length: 283563   epsilon: 0.6365432800078903    steps: 225    lr: 4e-05     evaluation reward: 3.03\n",
      "episode: 1454   score: 4.0   memory length: 283821   epsilon: 0.6360324400079014    steps: 258    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1455   score: 5.0   memory length: 284119   epsilon: 0.6354424000079142    steps: 298    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1456   score: 3.0   memory length: 284345   epsilon: 0.6349949200079239    steps: 226    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1457   score: 3.0   memory length: 284557   epsilon: 0.634575160007933    steps: 212    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1458   score: 3.0   memory length: 284790   epsilon: 0.634113820007943    steps: 233    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1459   score: 0.0   memory length: 284913   epsilon: 0.6338702800079483    steps: 123    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1460   score: 5.0   memory length: 285210   epsilon: 0.6332822200079611    steps: 297    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1461   score: 4.0   memory length: 285485   epsilon: 0.6327377200079729    steps: 275    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1462   score: 2.0   memory length: 285683   epsilon: 0.6323456800079814    steps: 198    lr: 4e-05     evaluation reward: 3.03\n",
      "episode: 1463   score: 5.0   memory length: 286007   epsilon: 0.6317041600079953    steps: 324    lr: 4e-05     evaluation reward: 3.05\n",
      "episode: 1464   score: 8.0   memory length: 286473   epsilon: 0.6307814800080154    steps: 466    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1465   score: 3.0   memory length: 286722   epsilon: 0.6302884600080261    steps: 249    lr: 4e-05     evaluation reward: 3.13\n",
      "episode: 1466   score: 4.0   memory length: 286984   epsilon: 0.6297697000080373    steps: 262    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1467   score: 3.0   memory length: 287195   epsilon: 0.6293519200080464    steps: 211    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1468   score: 3.0   memory length: 287421   epsilon: 0.6289044400080561    steps: 226    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1469   score: 2.0   memory length: 287618   epsilon: 0.6285143800080646    steps: 197    lr: 4e-05     evaluation reward: 3.07\n",
      "episode: 1470   score: 2.0   memory length: 287816   epsilon: 0.6281223400080731    steps: 198    lr: 4e-05     evaluation reward: 3.07\n",
      "episode: 1471   score: 3.0   memory length: 288042   epsilon: 0.6276748600080828    steps: 226    lr: 4e-05     evaluation reward: 3.08\n",
      "episode: 1472   score: 2.0   memory length: 288239   epsilon: 0.6272848000080913    steps: 197    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1473   score: 4.0   memory length: 288514   epsilon: 0.6267403000081031    steps: 275    lr: 4e-05     evaluation reward: 3.07\n",
      "episode: 1474   score: 4.0   memory length: 288790   epsilon: 0.626193820008115    steps: 276    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1475   score: 5.0   memory length: 289116   epsilon: 0.625548340008129    steps: 326    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1476   score: 7.0   memory length: 289534   epsilon: 0.624720700008147    steps: 418    lr: 4e-05     evaluation reward: 3.16\n",
      "episode: 1477   score: 4.0   memory length: 289809   epsilon: 0.6241762000081588    steps: 275    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1478   score: 4.0   memory length: 290066   epsilon: 0.6236673400081698    steps: 257    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1479   score: 4.0   memory length: 290348   epsilon: 0.6231089800081819    steps: 282    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1480   score: 4.0   memory length: 290623   epsilon: 0.6225644800081938    steps: 275    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1481   score: 3.0   memory length: 290849   epsilon: 0.6221170000082035    steps: 226    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1482   score: 2.0   memory length: 291028   epsilon: 0.6217625800082112    steps: 179    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1483   score: 2.0   memory length: 291209   epsilon: 0.6214042000082189    steps: 181    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1484   score: 2.0   memory length: 291409   epsilon: 0.6210082000082275    steps: 200    lr: 4e-05     evaluation reward: 3.24\n",
      "episode: 1485   score: 5.0   memory length: 291713   epsilon: 0.6204062800082406    steps: 304    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1486   score: 3.0   memory length: 291942   epsilon: 0.6199528600082505    steps: 229    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1487   score: 4.0   memory length: 292220   epsilon: 0.6194024200082624    steps: 278    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1488   score: 4.0   memory length: 292496   epsilon: 0.6188559400082743    steps: 276    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1489   score: 3.0   memory length: 292712   epsilon: 0.6184282600082835    steps: 216    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1490   score: 3.0   memory length: 292956   epsilon: 0.617945140008294    steps: 244    lr: 4e-05     evaluation reward: 3.23\n",
      "episode: 1491   score: 4.0   memory length: 293231   epsilon: 0.6174006400083059    steps: 275    lr: 4e-05     evaluation reward: 3.26\n",
      "episode: 1492   score: 2.0   memory length: 293429   epsilon: 0.6170086000083144    steps: 198    lr: 4e-05     evaluation reward: 3.26\n",
      "episode: 1493   score: 4.0   memory length: 293703   epsilon: 0.6164660800083261    steps: 274    lr: 4e-05     evaluation reward: 3.27\n",
      "episode: 1494   score: 3.0   memory length: 293949   epsilon: 0.6159790000083367    steps: 246    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1495   score: 4.0   memory length: 294248   epsilon: 0.6153869800083496    steps: 299    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1496   score: 4.0   memory length: 294503   epsilon: 0.6148820800083605    steps: 255    lr: 4e-05     evaluation reward: 3.27\n",
      "episode: 1497   score: 2.0   memory length: 294702   epsilon: 0.6144880600083691    steps: 199    lr: 4e-05     evaluation reward: 3.27\n",
      "episode: 1498   score: 4.0   memory length: 294977   epsilon: 0.6139435600083809    steps: 275    lr: 4e-05     evaluation reward: 3.29\n",
      "episode: 1499   score: 4.0   memory length: 295272   epsilon: 0.6133594600083936    steps: 295    lr: 4e-05     evaluation reward: 3.27\n",
      "episode: 1500   score: 1.0   memory length: 295423   epsilon: 0.6130604800084001    steps: 151    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1501   score: 0.0   memory length: 295546   epsilon: 0.6128169400084054    steps: 123    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1502   score: 2.0   memory length: 295744   epsilon: 0.6124249000084139    steps: 198    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1503   score: 5.0   memory length: 296076   epsilon: 0.6117675400084281    steps: 332    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1504   score: 2.0   memory length: 296294   epsilon: 0.6113359000084375    steps: 218    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1505   score: 2.0   memory length: 296492   epsilon: 0.610943860008446    steps: 198    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1506   score: 4.0   memory length: 296785   epsilon: 0.6103637200084586    steps: 293    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1507   score: 3.0   memory length: 296998   epsilon: 0.6099419800084678    steps: 213    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1508   score: 2.0   memory length: 297178   epsilon: 0.6095855800084755    steps: 180    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1509   score: 4.0   memory length: 297476   epsilon: 0.6089955400084883    steps: 298    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1510   score: 3.0   memory length: 297701   epsilon: 0.608550040008498    steps: 225    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1511   score: 3.0   memory length: 297947   epsilon: 0.6080629600085086    steps: 246    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1512   score: 3.0   memory length: 298175   epsilon: 0.6076115200085184    steps: 228    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1513   score: 1.0   memory length: 298326   epsilon: 0.6073125400085249    steps: 151    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1514   score: 2.0   memory length: 298524   epsilon: 0.6069205000085334    steps: 198    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1515   score: 5.0   memory length: 298853   epsilon: 0.6062690800085475    steps: 329    lr: 4e-05     evaluation reward: 3.22\n",
      "episode: 1516   score: 6.0   memory length: 299250   epsilon: 0.6054830200085646    steps: 397    lr: 4e-05     evaluation reward: 3.25\n",
      "episode: 1517   score: 3.0   memory length: 299498   epsilon: 0.6049919800085752    steps: 248    lr: 4e-05     evaluation reward: 3.24\n",
      "episode: 1518   score: 2.0   memory length: 299680   epsilon: 0.6046316200085831    steps: 182    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1519   score: 6.0   memory length: 300023   epsilon: 0.6039524800085978    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 3.25\n",
      "episode: 1520   score: 5.0   memory length: 300346   epsilon: 0.6033129400086117    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n",
      "episode: 1521   score: 1.0   memory length: 300515   epsilon: 0.602978320008619    steps: 169    lr: 1.6000000000000003e-05     evaluation reward: 3.24\n",
      "episode: 1522   score: 1.0   memory length: 300685   epsilon: 0.6026417200086263    steps: 170    lr: 1.6000000000000003e-05     evaluation reward: 3.22\n",
      "episode: 1523   score: 4.0   memory length: 300944   epsilon: 0.6021289000086374    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n",
      "episode: 1524   score: 3.0   memory length: 301170   epsilon: 0.6016814200086471    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.24\n",
      "episode: 1525   score: 6.0   memory length: 301494   epsilon: 0.601039900008661    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 3.28\n",
      "episode: 1526   score: 4.0   memory length: 301790   epsilon: 0.6004538200086738    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.29\n",
      "episode: 1527   score: 2.0   memory length: 301970   epsilon: 0.6000974200086815    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n",
      "episode: 1528   score: 3.0   memory length: 302199   epsilon: 0.5996440000086913    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.26\n",
      "episode: 1529   score: 6.0   memory length: 302556   epsilon: 0.5989371400087067    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n",
      "episode: 1530   score: 6.0   memory length: 302880   epsilon: 0.5982956200087206    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1531   score: 7.0   memory length: 303266   epsilon: 0.5975313400087372    steps: 386    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1532   score: 3.0   memory length: 303492   epsilon: 0.5970838600087469    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1533   score: 4.0   memory length: 303753   epsilon: 0.5965670800087581    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1534   score: 3.0   memory length: 303978   epsilon: 0.5961215800087678    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1535   score: 4.0   memory length: 304253   epsilon: 0.5955770800087796    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1536   score: 6.0   memory length: 304626   epsilon: 0.5948385400087957    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 3.48\n",
      "episode: 1537   score: 1.0   memory length: 304777   epsilon: 0.5945395600088021    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n",
      "episode: 1538   score: 4.0   memory length: 305054   epsilon: 0.593991100008814    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n",
      "episode: 1539   score: 3.0   memory length: 305280   epsilon: 0.5935436200088238    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n",
      "episode: 1540   score: 3.0   memory length: 305505   epsilon: 0.5930981200088334    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 3.46\n",
      "episode: 1541   score: 2.0   memory length: 305687   epsilon: 0.5927377600088413    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1542   score: 3.0   memory length: 305933   epsilon: 0.5922506800088518    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n",
      "episode: 1543   score: 3.0   memory length: 306159   epsilon: 0.5918032000088616    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1544   score: 2.0   memory length: 306340   epsilon: 0.5914448200088693    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1545   score: 2.0   memory length: 306522   epsilon: 0.5910844600088772    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1546   score: 4.0   memory length: 306796   epsilon: 0.5905419400088889    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1547   score: 3.0   memory length: 307022   epsilon: 0.5900944600088986    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1548   score: 1.0   memory length: 307173   epsilon: 0.5897954800089051    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1549   score: 2.0   memory length: 307371   epsilon: 0.5894034400089136    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1550   score: 4.0   memory length: 307625   epsilon: 0.5889005200089246    steps: 254    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1551   score: 2.0   memory length: 307825   epsilon: 0.5885045200089332    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1552   score: 3.0   memory length: 308099   epsilon: 0.5879620000089449    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1553   score: 3.0   memory length: 308345   epsilon: 0.5874749200089555    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1554   score: 4.0   memory length: 308607   epsilon: 0.5869561600089668    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 3.34\n",
      "episode: 1555   score: 6.0   memory length: 309000   epsilon: 0.5861780200089837    steps: 393    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1556   score: 1.0   memory length: 309151   epsilon: 0.5858790400089902    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.33\n",
      "episode: 1557   score: 3.0   memory length: 309377   epsilon: 0.5854315600089999    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.33\n",
      "episode: 1558   score: 2.0   memory length: 309576   epsilon: 0.5850375400090084    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1559   score: 3.0   memory length: 309808   epsilon: 0.5845781800090184    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1560   score: 0.0   memory length: 309931   epsilon: 0.5843346400090237    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n",
      "episode: 1561   score: 5.0   memory length: 310226   epsilon: 0.5837505400090364    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1562   score: 3.0   memory length: 310472   epsilon: 0.5832634600090469    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1563   score: 4.0   memory length: 310727   epsilon: 0.5827585600090579    steps: 255    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1564   score: 1.0   memory length: 310878   epsilon: 0.5824595800090644    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.24\n",
      "episode: 1565   score: 1.0   memory length: 311030   epsilon: 0.5821586200090709    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.22\n",
      "episode: 1566   score: 2.0   memory length: 311212   epsilon: 0.5817982600090787    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n",
      "episode: 1567   score: 3.0   memory length: 311478   epsilon: 0.5812715800090902    steps: 266    lr: 1.6000000000000003e-05     evaluation reward: 3.2\n",
      "episode: 1568   score: 2.0   memory length: 311676   epsilon: 0.5808795400090987    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.19\n",
      "episode: 1569   score: 4.0   memory length: 311952   epsilon: 0.5803330600091106    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n",
      "episode: 1570   score: 3.0   memory length: 312182   epsilon: 0.5798776600091204    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.22\n",
      "episode: 1571   score: 4.0   memory length: 312427   epsilon: 0.579392560009131    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n",
      "episode: 1572   score: 6.0   memory length: 312783   epsilon: 0.5786876800091463    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n",
      "episode: 1573   score: 2.0   memory length: 312982   epsilon: 0.5782936600091548    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.25\n",
      "episode: 1574   score: 4.0   memory length: 313277   epsilon: 0.5777095600091675    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.25\n",
      "episode: 1575   score: 7.0   memory length: 313655   epsilon: 0.5769611200091838    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 3.27\n",
      "episode: 1576   score: 1.0   memory length: 313805   epsilon: 0.5766641200091902    steps: 150    lr: 1.6000000000000003e-05     evaluation reward: 3.21\n",
      "episode: 1577   score: 6.0   memory length: 314170   epsilon: 0.5759414200092059    steps: 365    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n",
      "episode: 1578   score: 4.0   memory length: 314446   epsilon: 0.5753949400092178    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n",
      "episode: 1579   score: 4.0   memory length: 314708   epsilon: 0.574876180009229    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 3.23\n",
      "episode: 1580   score: 7.0   memory length: 315066   epsilon: 0.5741673400092444    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 3.26\n",
      "episode: 1581   score: 7.0   memory length: 315452   epsilon: 0.573403060009261    steps: 386    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n",
      "episode: 1582   score: 3.0   memory length: 315699   epsilon: 0.5729140000092716    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1583   score: 6.0   memory length: 316070   epsilon: 0.5721794200092876    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1584   score: 4.0   memory length: 316345   epsilon: 0.5716349200092994    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1585   score: 4.0   memory length: 316620   epsilon: 0.5710904200093112    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1586   score: 4.0   memory length: 316900   epsilon: 0.5705360200093232    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1587   score: 3.0   memory length: 317131   epsilon: 0.5700786400093332    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1588   score: 5.0   memory length: 317454   epsilon: 0.569439100009347    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1589   score: 3.0   memory length: 317664   epsilon: 0.5690233000093561    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1590   score: 6.0   memory length: 318001   epsilon: 0.5683560400093706    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1591   score: 4.0   memory length: 318260   epsilon: 0.5678432200093817    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1592   score: 4.0   memory length: 318534   epsilon: 0.5673007000093935    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n",
      "episode: 1593   score: 3.0   memory length: 318766   epsilon: 0.5668413400094034    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n",
      "episode: 1594   score: 4.0   memory length: 319043   epsilon: 0.5662928800094154    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.42\n",
      "episode: 1595   score: 2.0   memory length: 319261   epsilon: 0.5658612400094247    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1596   score: 1.0   memory length: 319412   epsilon: 0.5655622600094312    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1597   score: 2.0   memory length: 319611   epsilon: 0.5651682400094398    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1598   score: 4.0   memory length: 319890   epsilon: 0.5646158200094518    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1599   score: 3.0   memory length: 320103   epsilon: 0.5641940800094609    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1600   score: 3.0   memory length: 320350   epsilon: 0.5637050200094715    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1601   score: 1.0   memory length: 320501   epsilon: 0.563406040009478    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1602   score: 3.0   memory length: 320729   epsilon: 0.5629546000094878    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1603   score: 4.0   memory length: 321006   epsilon: 0.5624061400094997    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1604   score: 2.0   memory length: 321206   epsilon: 0.5620101400095083    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1605   score: 3.0   memory length: 321431   epsilon: 0.561564640009518    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1606   score: 3.0   memory length: 321678   epsilon: 0.5610755800095286    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.39\n",
      "episode: 1607   score: 4.0   memory length: 321954   epsilon: 0.5605291000095405    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1608   score: 5.0   memory length: 322298   epsilon: 0.5598479800095553    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1609   score: 5.0   memory length: 322624   epsilon: 0.5592025000095693    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1610   score: 4.0   memory length: 322890   epsilon: 0.5586758200095807    steps: 266    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n",
      "episode: 1611   score: 2.0   memory length: 323070   epsilon: 0.5583194200095885    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1612   score: 6.0   memory length: 323413   epsilon: 0.5576402800096032    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 3.47\n",
      "episode: 1613   score: 4.0   memory length: 323688   epsilon: 0.557095780009615    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.5\n",
      "episode: 1614   score: 5.0   memory length: 323975   epsilon: 0.5565275200096274    steps: 287    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n",
      "episode: 1615   score: 4.0   memory length: 324216   epsilon: 0.5560503400096377    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n",
      "episode: 1616   score: 5.0   memory length: 324505   epsilon: 0.5554781200096501    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 3.51\n",
      "episode: 1617   score: 3.0   memory length: 324731   epsilon: 0.5550306400096598    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.51\n",
      "episode: 1618   score: 4.0   memory length: 325028   epsilon: 0.5544425800096726    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n",
      "episode: 1619   score: 2.0   memory length: 325209   epsilon: 0.5540842000096804    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.49\n",
      "episode: 1620   score: 6.0   memory length: 325538   epsilon: 0.5534327800096945    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 3.5\n",
      "episode: 1621   score: 3.0   memory length: 325764   epsilon: 0.5529853000097043    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n",
      "episode: 1622   score: 3.0   memory length: 325990   epsilon: 0.552537820009714    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.54\n",
      "episode: 1623   score: 6.0   memory length: 326355   epsilon: 0.5518151200097297    steps: 365    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1624   score: 4.0   memory length: 326631   epsilon: 0.5512686400097415    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1625   score: 7.0   memory length: 327051   epsilon: 0.5504370400097596    steps: 420    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1626   score: 10.0   memory length: 327460   epsilon: 0.5496272200097772    steps: 409    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1627   score: 6.0   memory length: 327816   epsilon: 0.5489223400097925    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1628   score: 6.0   memory length: 328139   epsilon: 0.5482828000098063    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1629   score: 2.0   memory length: 328338   epsilon: 0.5478887800098149    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1630   score: 3.0   memory length: 328566   epsilon: 0.5474373400098247    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1631   score: 5.0   memory length: 328890   epsilon: 0.5467958200098386    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1632   score: 8.0   memory length: 329310   epsilon: 0.5459642200098567    steps: 420    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1633   score: 0.0   memory length: 329433   epsilon: 0.545720680009862    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1634   score: 7.0   memory length: 329825   epsilon: 0.5449445200098788    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1635   score: 2.0   memory length: 330025   epsilon: 0.5445485200098874    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1636   score: 5.0   memory length: 330373   epsilon: 0.5438594800099024    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1637   score: 4.0   memory length: 330668   epsilon: 0.543275380009915    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1638   score: 5.0   memory length: 330991   epsilon: 0.5426358400099289    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1639   score: 7.0   memory length: 331349   epsilon: 0.5419270000099443    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1640   score: 4.0   memory length: 331645   epsilon: 0.541340920009957    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1641   score: 1.0   memory length: 331796   epsilon: 0.5410419400099635    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1642   score: 2.0   memory length: 331996   epsilon: 0.5406459400099721    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1643   score: 2.0   memory length: 332176   epsilon: 0.5402895400099799    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1644   score: 2.0   memory length: 332358   epsilon: 0.5399291800099877    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1645   score: 3.0   memory length: 332570   epsilon: 0.5395094200099968    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1646   score: 1.0   memory length: 332721   epsilon: 0.5392104400100033    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1647   score: 3.0   memory length: 332968   epsilon: 0.5387213800100139    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1648   score: 8.0   memory length: 333389   epsilon: 0.537887800010032    steps: 421    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n",
      "episode: 1649   score: 5.0   memory length: 333714   epsilon: 0.537244300010046    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n",
      "episode: 1650   score: 2.0   memory length: 333914   epsilon: 0.5368483000100546    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n",
      "episode: 1651   score: 7.0   memory length: 334258   epsilon: 0.5361671800100694    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n",
      "episode: 1652   score: 3.0   memory length: 334484   epsilon: 0.5357197000100791    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n",
      "episode: 1653   score: 3.0   memory length: 334696   epsilon: 0.5352999400100882    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n",
      "episode: 1654   score: 4.0   memory length: 334974   epsilon: 0.5347495000101001    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n",
      "episode: 1655   score: 3.0   memory length: 335223   epsilon: 0.5342564800101108    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n",
      "episode: 1656   score: 6.0   memory length: 335566   epsilon: 0.5335773400101256    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n",
      "episode: 1657   score: 5.0   memory length: 335910   epsilon: 0.5328962200101404    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n",
      "episode: 1658   score: 6.0   memory length: 336247   epsilon: 0.5322289600101549    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n",
      "episode: 1659   score: 3.0   memory length: 336477   epsilon: 0.5317735600101647    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n",
      "episode: 1660   score: 2.0   memory length: 336676   epsilon: 0.5313795400101733    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.91\n",
      "episode: 1661   score: 4.0   memory length: 336918   epsilon: 0.5309003800101837    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1662   score: 8.0   memory length: 337370   epsilon: 0.5300054200102031    steps: 452    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1663   score: 4.0   memory length: 337648   epsilon: 0.5294549800102151    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1664   score: 0.0   memory length: 337771   epsilon: 0.5292114400102204    steps: 123    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n",
      "episode: 1665   score: 6.0   memory length: 338098   epsilon: 0.5285639800102344    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1666   score: 4.0   memory length: 338358   epsilon: 0.5280491800102456    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.01\n",
      "episode: 1667   score: 6.0   memory length: 338711   epsilon: 0.5273502400102608    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1668   score: 8.0   memory length: 339122   epsilon: 0.5265364600102784    steps: 411    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1669   score: 4.0   memory length: 339396   epsilon: 0.5259939400102902    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1670   score: 4.0   memory length: 339656   epsilon: 0.5254791400103014    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1671   score: 3.0   memory length: 339908   epsilon: 0.5249801800103122    steps: 252    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1672   score: 4.0   memory length: 340186   epsilon: 0.5244297400103242    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1673   score: 4.0   memory length: 340481   epsilon: 0.5238456400103368    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1674   score: 6.0   memory length: 340838   epsilon: 0.5231387800103522    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1675   score: 2.0   memory length: 341059   epsilon: 0.5227012000103617    steps: 221    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1676   score: 6.0   memory length: 341399   epsilon: 0.5220280000103763    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1677   score: 2.0   memory length: 341598   epsilon: 0.5216339800103849    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1678   score: 4.0   memory length: 341893   epsilon: 0.5210498800103975    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1679   score: 8.0   memory length: 342322   epsilon: 0.520200460010416    steps: 429    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1680   score: 3.0   memory length: 342548   epsilon: 0.5197529800104257    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1681   score: 5.0   memory length: 342873   epsilon: 0.5191094800104397    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1682   score: 4.0   memory length: 343130   epsilon: 0.5186006200104507    steps: 257    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1683   score: 3.0   memory length: 343360   epsilon: 0.5181452200104606    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1684   score: 4.0   memory length: 343638   epsilon: 0.5175947800104725    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1685   score: 2.0   memory length: 343836   epsilon: 0.517202740010481    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1686   score: 3.0   memory length: 344062   epsilon: 0.5167552600104908    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.01\n",
      "episode: 1687   score: 2.0   memory length: 344260   epsilon: 0.5163632200104993    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n",
      "episode: 1688   score: 2.0   memory length: 344458   epsilon: 0.5159711800105078    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1689   score: 4.0   memory length: 344775   epsilon: 0.5153435200105214    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n",
      "episode: 1690   score: 5.0   memory length: 345119   epsilon: 0.5146624000105362    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1691   score: 4.0   memory length: 345394   epsilon: 0.514117900010548    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1692   score: 4.0   memory length: 345653   epsilon: 0.5136050800105592    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.97\n",
      "episode: 1693   score: 6.0   memory length: 346046   epsilon: 0.512826940010576    steps: 393    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n",
      "episode: 1694   score: 10.0   memory length: 346507   epsilon: 0.5119141600105959    steps: 461    lr: 1.6000000000000003e-05     evaluation reward: 4.06\n",
      "episode: 1695   score: 5.0   memory length: 346809   epsilon: 0.5113162000106088    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1696   score: 3.0   memory length: 347060   epsilon: 0.5108192200106196    steps: 251    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1697   score: 7.0   memory length: 347446   epsilon: 0.5100549400106362    steps: 386    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1698   score: 2.0   memory length: 347626   epsilon: 0.509698540010644    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1699   score: 3.0   memory length: 347836   epsilon: 0.509282740010653    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1700   score: 2.0   memory length: 348036   epsilon: 0.5088867400106616    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1701   score: 10.0   memory length: 348512   epsilon: 0.507944260010682    steps: 476    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1702   score: 4.0   memory length: 348807   epsilon: 0.5073601600106947    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1703   score: 6.0   memory length: 349173   epsilon: 0.5066354800107105    steps: 366    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1704   score: 5.0   memory length: 349494   epsilon: 0.5059999000107243    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1705   score: 3.0   memory length: 349723   epsilon: 0.5055464800107341    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1706   score: 1.0   memory length: 349874   epsilon: 0.5052475000107406    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1707   score: 8.0   memory length: 350203   epsilon: 0.5045960800107547    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1708   score: 8.0   memory length: 350650   epsilon: 0.503711020010774    steps: 447    lr: 1.6000000000000003e-05     evaluation reward: 4.33\n",
      "episode: 1709   score: 3.0   memory length: 350895   epsilon: 0.5032259200107845    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1710   score: 3.0   memory length: 351108   epsilon: 0.5028041800107936    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1711   score: 4.0   memory length: 351382   epsilon: 0.5022616600108054    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1712   score: 3.0   memory length: 351609   epsilon: 0.5018122000108152    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1713   score: 3.0   memory length: 351835   epsilon: 0.5013647200108249    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1714   score: 6.0   memory length: 352208   epsilon: 0.5006261800108409    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1715   score: 4.0   memory length: 352483   epsilon: 0.5000816800108527    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1716   score: 4.0   memory length: 352758   epsilon: 0.49953718001085157    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1717   score: 5.0   memory length: 353064   epsilon: 0.49893130001084773    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1718   score: 4.0   memory length: 353327   epsilon: 0.49841056001084444    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1719   score: 3.0   memory length: 353539   epsilon: 0.4979908000108418    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1720   score: 3.0   memory length: 353767   epsilon: 0.4975393600108389    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1721   score: 10.0   memory length: 354230   epsilon: 0.4966226200108331    steps: 463    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1722   score: 2.0   memory length: 354448   epsilon: 0.4961909800108304    steps: 218    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n",
      "episode: 1723   score: 4.0   memory length: 354723   epsilon: 0.49564648001082695    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1724   score: 4.0   memory length: 355018   epsilon: 0.49506238001082326    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1725   score: 3.0   memory length: 355229   epsilon: 0.4946446000108206    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1726   score: 3.0   memory length: 355460   epsilon: 0.4941872200108177    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1727   score: 3.0   memory length: 355686   epsilon: 0.4937397400108149    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1728   score: 4.0   memory length: 355964   epsilon: 0.4931893000108114    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1729   score: 4.0   memory length: 356259   epsilon: 0.4926052000108077    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1730   score: 6.0   memory length: 356599   epsilon: 0.49193200001080345    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1731   score: 5.0   memory length: 356925   epsilon: 0.49128652001079937    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1732   score: 5.0   memory length: 357232   epsilon: 0.4906786600107955    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1733   score: 4.0   memory length: 357507   epsilon: 0.4901341600107921    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1734   score: 4.0   memory length: 357781   epsilon: 0.48959164001078864    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1735   score: 3.0   memory length: 357994   epsilon: 0.489169900010786    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1736   score: 3.0   memory length: 358242   epsilon: 0.48867886001078287    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1737   score: 3.0   memory length: 358473   epsilon: 0.48822148001078    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1738   score: 14.0   memory length: 358847   epsilon: 0.4874809600107753    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1739   score: 1.0   memory length: 359015   epsilon: 0.4871483200107732    steps: 168    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1740   score: 7.0   memory length: 359438   epsilon: 0.4863107800107679    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1741   score: 2.0   memory length: 359617   epsilon: 0.48595636001076564    steps: 179    lr: 1.6000000000000003e-05     evaluation reward: 4.24\n",
      "episode: 1742   score: 4.0   memory length: 359914   epsilon: 0.4853683000107619    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1743   score: 3.0   memory length: 360125   epsilon: 0.4849505200107593    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1744   score: 4.0   memory length: 360386   epsilon: 0.484433740010756    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1745   score: 6.0   memory length: 360784   epsilon: 0.483645700010751    steps: 398    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1746   score: 4.0   memory length: 361061   epsilon: 0.48309724001074755    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1747   score: 4.0   memory length: 361335   epsilon: 0.4825547200107441    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.36\n",
      "episode: 1748   score: 2.0   memory length: 361535   epsilon: 0.4821587200107416    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1749   score: 5.0   memory length: 361860   epsilon: 0.48151522001073754    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1750   score: 3.0   memory length: 362130   epsilon: 0.48098062001073416    steps: 270    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1751   score: 5.0   memory length: 362438   epsilon: 0.4803707800107303    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1752   score: 1.0   memory length: 362589   epsilon: 0.4800718000107284    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1753   score: 3.0   memory length: 362802   epsilon: 0.47965006001072574    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1754   score: 4.0   memory length: 363056   epsilon: 0.47914714001072256    steps: 254    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1755   score: 5.0   memory length: 363380   epsilon: 0.4785056200107185    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1756   score: 7.0   memory length: 363748   epsilon: 0.4777769800107139    steps: 368    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1757   score: 2.0   memory length: 363946   epsilon: 0.4773849400107114    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1758   score: 4.0   memory length: 364204   epsilon: 0.4768741000107082    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1759   score: 4.0   memory length: 364481   epsilon: 0.4763256400107047    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1760   score: 5.0   memory length: 364789   epsilon: 0.47571580001070085    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1761   score: 3.0   memory length: 365036   epsilon: 0.47522674001069776    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1762   score: 2.0   memory length: 365234   epsilon: 0.4748347000106953    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1763   score: 3.0   memory length: 365446   epsilon: 0.4744149400106926    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1764   score: 4.0   memory length: 365722   epsilon: 0.47386846001068916    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1765   score: 4.0   memory length: 365997   epsilon: 0.4733239600106857    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1766   score: 8.0   memory length: 366388   epsilon: 0.4725497800106808    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1767   score: 2.0   memory length: 366569   epsilon: 0.47219140001067855    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1768   score: 4.0   memory length: 366812   epsilon: 0.4717102600106755    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1769   score: 3.0   memory length: 367038   epsilon: 0.4712627800106727    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1770   score: 7.0   memory length: 367384   epsilon: 0.47057770001066834    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1771   score: 3.0   memory length: 367615   epsilon: 0.47012032001066545    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1772   score: 4.0   memory length: 367890   epsilon: 0.469575820010662    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1773   score: 2.0   memory length: 368072   epsilon: 0.4692154600106597    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1774   score: 4.0   memory length: 368351   epsilon: 0.46866304001065623    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1775   score: 5.0   memory length: 368667   epsilon: 0.46803736001065227    steps: 316    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1776   score: 4.0   memory length: 368946   epsilon: 0.4674849400106488    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1777   score: 6.0   memory length: 369318   epsilon: 0.4667483800106441    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1778   score: 3.0   memory length: 369529   epsilon: 0.46633060001064147    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1779   score: 2.0   memory length: 369711   epsilon: 0.4659702400106392    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1780   score: 3.0   memory length: 369920   epsilon: 0.4655564200106366    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1781   score: 9.0   memory length: 370388   epsilon: 0.4646297800106307    steps: 468    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1782   score: 2.0   memory length: 370586   epsilon: 0.46423774001062823    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1783   score: 3.0   memory length: 370814   epsilon: 0.4637863000106254    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1784   score: 7.0   memory length: 371219   epsilon: 0.4629844000106203    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1785   score: 4.0   memory length: 371474   epsilon: 0.4624795000106171    steps: 255    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1786   score: 6.0   memory length: 371809   epsilon: 0.4618162000106129    steps: 335    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1787   score: 4.0   memory length: 372104   epsilon: 0.4612321000106092    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1788   score: 3.0   memory length: 372368   epsilon: 0.4607093800106059    steps: 264    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1789   score: 4.0   memory length: 372663   epsilon: 0.4601252800106022    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1790   score: 6.0   memory length: 372997   epsilon: 0.459463960010598    steps: 334    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1791   score: 4.0   memory length: 373257   epsilon: 0.45894916001059477    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1792   score: 5.0   memory length: 373572   epsilon: 0.4583254600105908    steps: 315    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1793   score: 4.0   memory length: 373867   epsilon: 0.45774136001058713    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1794   score: 12.0   memory length: 374336   epsilon: 0.45681274001058125    steps: 469    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1795   score: 3.0   memory length: 374564   epsilon: 0.4563613000105784    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1796   score: 5.0   memory length: 374889   epsilon: 0.4557178000105743    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1797   score: 3.0   memory length: 375099   epsilon: 0.4553020000105717    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1798   score: 3.0   memory length: 375345   epsilon: 0.4548149200105686    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1799   score: 3.0   memory length: 375591   epsilon: 0.45432784001056553    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1800   score: 7.0   memory length: 375999   epsilon: 0.4535200000105604    steps: 408    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1801   score: 4.0   memory length: 376278   epsilon: 0.4529675800105569    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1802   score: 3.0   memory length: 376504   epsilon: 0.4525201000105541    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1803   score: 3.0   memory length: 376732   epsilon: 0.45206866001055124    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1804   score: 11.0   memory length: 377145   epsilon: 0.45125092001054606    steps: 413    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1805   score: 6.0   memory length: 377495   epsilon: 0.4505579200105417    steps: 350    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1806   score: 6.0   memory length: 377848   epsilon: 0.44985898001053726    steps: 353    lr: 1.6000000000000003e-05     evaluation reward: 4.36\n",
      "episode: 1807   score: 3.0   memory length: 378074   epsilon: 0.4494115000105344    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1808   score: 2.0   memory length: 378272   epsilon: 0.44901946001053195    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1809   score: 6.0   memory length: 378629   epsilon: 0.4483126000105275    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1810   score: 6.0   memory length: 378987   epsilon: 0.447603760010523    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1811   score: 4.0   memory length: 379264   epsilon: 0.4470553000105195    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1812   score: 7.0   memory length: 379639   epsilon: 0.4463128000105148    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1813   score: 3.0   memory length: 379851   epsilon: 0.44589304001051216    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1814   score: 4.0   memory length: 380127   epsilon: 0.4453465600105087    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.33\n",
      "episode: 1815   score: 3.0   memory length: 380355   epsilon: 0.44489512001050585    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1816   score: 2.0   memory length: 380537   epsilon: 0.44453476001050357    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1817   score: 6.0   memory length: 380895   epsilon: 0.4438259200104991    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1818   score: 4.0   memory length: 381172   epsilon: 0.4432774600104956    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1819   score: 3.0   memory length: 381398   epsilon: 0.4428299800104928    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1820   score: 8.0   memory length: 381820   epsilon: 0.4419944200104875    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 4.36\n",
      "episode: 1821   score: 4.0   memory length: 382098   epsilon: 0.441443980010484    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1822   score: 2.0   memory length: 382297   epsilon: 0.4410499600104815    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1823   score: 3.0   memory length: 382523   epsilon: 0.4406024800104787    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1824   score: 4.0   memory length: 382819   epsilon: 0.440016400010475    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1825   score: 4.0   memory length: 383095   epsilon: 0.4394699200104715    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1826   score: 5.0   memory length: 383425   epsilon: 0.4388165200104674    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1827   score: 9.0   memory length: 383966   epsilon: 0.4377453400104606    steps: 541    lr: 1.6000000000000003e-05     evaluation reward: 4.38\n",
      "episode: 1828   score: 5.0   memory length: 384290   epsilon: 0.43710382001045656    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1829   score: 2.0   memory length: 384488   epsilon: 0.4367117800104541    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.37\n",
      "episode: 1830   score: 6.0   memory length: 384818   epsilon: 0.43605838001044994    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 4.37\n",
      "episode: 1831   score: 5.0   memory length: 385145   epsilon: 0.43541092001044585    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.37\n",
      "episode: 1832   score: 8.0   memory length: 385603   epsilon: 0.4345040800104401    steps: 458    lr: 1.6000000000000003e-05     evaluation reward: 4.4\n",
      "episode: 1833   score: 3.0   memory length: 385812   epsilon: 0.4340902600104375    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1834   score: 3.0   memory length: 386040   epsilon: 0.43363882001043463    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.38\n",
      "episode: 1835   score: 7.0   memory length: 386412   epsilon: 0.43290226001043    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 4.42\n",
      "episode: 1836   score: 4.0   memory length: 386656   epsilon: 0.4324191400104269    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1837   score: 5.0   memory length: 386964   epsilon: 0.43180930001042306    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1838   score: 2.0   memory length: 387162   epsilon: 0.4314172600104206    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 4.33\n",
      "episode: 1839   score: 3.0   memory length: 387393   epsilon: 0.4309598800104177    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1840   score: 2.0   memory length: 387573   epsilon: 0.43060348001041543    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1841   score: 6.0   memory length: 387910   epsilon: 0.4299362200104112    steps: 337    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n",
      "episode: 1842   score: 1.0   memory length: 388081   epsilon: 0.42959764001040907    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1843   score: 8.0   memory length: 388483   epsilon: 0.42880168001040403    steps: 402    lr: 1.6000000000000003e-05     evaluation reward: 4.36\n",
      "episode: 1844   score: 3.0   memory length: 388712   epsilon: 0.42834826001040116    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1845   score: 3.0   memory length: 388957   epsilon: 0.4278631600103981    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1846   score: 3.0   memory length: 389183   epsilon: 0.42741568001039526    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1847   score: 8.0   memory length: 389606   epsilon: 0.42657814001038996    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1848   score: 5.0   memory length: 389904   epsilon: 0.42598810001038623    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 4.38\n",
      "episode: 1849   score: 4.0   memory length: 390181   epsilon: 0.42543964001038276    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.37\n",
      "episode: 1850   score: 2.0   memory length: 390363   epsilon: 0.4250792800103805    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.36\n",
      "episode: 1851   score: 7.0   memory length: 390747   epsilon: 0.42431896001037567    steps: 384    lr: 1.6000000000000003e-05     evaluation reward: 4.38\n",
      "episode: 1852   score: 4.0   memory length: 391013   epsilon: 0.42379228001037234    steps: 266    lr: 1.6000000000000003e-05     evaluation reward: 4.41\n",
      "episode: 1853   score: 9.0   memory length: 391507   epsilon: 0.42281416001036615    steps: 494    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n",
      "episode: 1854   score: 7.0   memory length: 391897   epsilon: 0.42204196001036126    steps: 390    lr: 1.6000000000000003e-05     evaluation reward: 4.5\n",
      "episode: 1855   score: 6.0   memory length: 392241   epsilon: 0.42136084001035695    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.51\n",
      "episode: 1856   score: 6.0   memory length: 392570   epsilon: 0.42070942001035283    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.5\n",
      "episode: 1857   score: 2.0   memory length: 392750   epsilon: 0.4203530200103506    steps: 180    lr: 1.6000000000000003e-05     evaluation reward: 4.5\n",
      "episode: 1858   score: 4.0   memory length: 392993   epsilon: 0.41987188001034753    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 4.5\n",
      "episode: 1859   score: 5.0   memory length: 393317   epsilon: 0.4192303600103435    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.51\n",
      "episode: 1860   score: 5.0   memory length: 393621   epsilon: 0.41862844001033966    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 4.51\n",
      "episode: 1861   score: 3.0   memory length: 393846   epsilon: 0.41818294001033685    steps: 225    lr: 1.6000000000000003e-05     evaluation reward: 4.51\n",
      "episode: 1862   score: 10.0   memory length: 394331   epsilon: 0.41722264001033077    steps: 485    lr: 1.6000000000000003e-05     evaluation reward: 4.59\n",
      "episode: 1863   score: 3.0   memory length: 394557   epsilon: 0.41677516001032794    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.59\n",
      "episode: 1864   score: 3.0   memory length: 394785   epsilon: 0.4163237200103251    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.58\n",
      "episode: 1865   score: 4.0   memory length: 395061   epsilon: 0.4157772400103216    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.58\n",
      "episode: 1866   score: 3.0   memory length: 395287   epsilon: 0.4153297600103188    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.53\n",
      "episode: 1867   score: 3.0   memory length: 395513   epsilon: 0.41488228001031596    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.54\n",
      "episode: 1868   score: 7.0   memory length: 395936   epsilon: 0.41404474001031066    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.57\n",
      "episode: 1869   score: 7.0   memory length: 396295   epsilon: 0.41333392001030617    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 4.61\n",
      "episode: 1870   score: 3.0   memory length: 396525   epsilon: 0.4128785200103033    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.57\n",
      "episode: 1871   score: 7.0   memory length: 396886   epsilon: 0.41216374001029876    steps: 361    lr: 1.6000000000000003e-05     evaluation reward: 4.61\n",
      "episode: 1872   score: 6.0   memory length: 397242   epsilon: 0.4114588600102943    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.63\n",
      "episode: 1873   score: 3.0   memory length: 397456   epsilon: 0.4110351400102916    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 4.64\n",
      "episode: 1874   score: 7.0   memory length: 397819   epsilon: 0.4103164000102871    steps: 363    lr: 1.6000000000000003e-05     evaluation reward: 4.67\n",
      "episode: 1875   score: 6.0   memory length: 398189   epsilon: 0.40958380001028244    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 4.68\n",
      "episode: 1876   score: 8.0   memory length: 398593   epsilon: 0.4087838800102774    steps: 404    lr: 1.6000000000000003e-05     evaluation reward: 4.72\n",
      "episode: 1877   score: 8.0   memory length: 399015   epsilon: 0.4079483200102721    steps: 422    lr: 1.6000000000000003e-05     evaluation reward: 4.74\n",
      "episode: 1878   score: 1.0   memory length: 399166   epsilon: 0.4076493400102702    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 4.72\n",
      "episode: 1879   score: 3.0   memory length: 399412   epsilon: 0.4071622600102671    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 4.73\n",
      "episode: 1880   score: 3.0   memory length: 399625   epsilon: 0.40674052001026445    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.73\n",
      "episode: 1881   score: 3.0   memory length: 399851   epsilon: 0.4062930400102616    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 4.67\n",
      "episode: 1882   score: 5.0   memory length: 400174   epsilon: 0.4056535000102576    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 4.7\n",
      "episode: 1883   score: 4.0   memory length: 400433   epsilon: 0.40514068001025433    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 4.71\n",
      "episode: 1884   score: 5.0   memory length: 400757   epsilon: 0.40449916001025027    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 4.69\n",
      "episode: 1885   score: 3.0   memory length: 400985   epsilon: 0.4040477200102474    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 4.68\n",
      "episode: 1886   score: 8.0   memory length: 401416   epsilon: 0.403194340010242    steps: 431    lr: 6.400000000000001e-06     evaluation reward: 4.7\n",
      "episode: 1887   score: 6.0   memory length: 401761   epsilon: 0.4025112400102377    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 4.72\n",
      "episode: 1888   score: 7.0   memory length: 402155   epsilon: 0.40173112001023276    steps: 394    lr: 6.400000000000001e-06     evaluation reward: 4.76\n",
      "episode: 1889   score: 7.0   memory length: 402562   epsilon: 0.40092526001022766    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 4.79\n",
      "episode: 1890   score: 8.0   memory length: 402992   epsilon: 0.40007386001022227    steps: 430    lr: 6.400000000000001e-06     evaluation reward: 4.81\n",
      "episode: 1891   score: 9.0   memory length: 403434   epsilon: 0.39919870001021673    steps: 442    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1892   score: 8.0   memory length: 403839   epsilon: 0.39839680001021166    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 1893   score: 8.0   memory length: 404281   epsilon: 0.3975216400102061    steps: 442    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 1894   score: 5.0   memory length: 404608   epsilon: 0.396874180010202    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1895   score: 8.0   memory length: 405048   epsilon: 0.3960029800101965    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 1896   score: 7.0   memory length: 405435   epsilon: 0.39523672001019167    steps: 387    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 1897   score: 2.0   memory length: 405634   epsilon: 0.3948427000101892    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1898   score: 6.0   memory length: 405989   epsilon: 0.3941398000101847    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 4.95\n",
      "episode: 1899   score: 4.0   memory length: 406284   epsilon: 0.39355570001018103    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 4.96\n",
      "episode: 1900   score: 5.0   memory length: 406582   epsilon: 0.3929656600101773    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 1901   score: 7.0   memory length: 406986   epsilon: 0.39216574001017224    steps: 404    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1902   score: 10.0   memory length: 407528   epsilon: 0.39109258001016545    steps: 542    lr: 6.400000000000001e-06     evaluation reward: 5.04\n",
      "episode: 1903   score: 10.0   memory length: 408026   epsilon: 0.3901065400101592    steps: 498    lr: 6.400000000000001e-06     evaluation reward: 5.11\n",
      "episode: 1904   score: 11.0   memory length: 408578   epsilon: 0.3890135800101523    steps: 552    lr: 6.400000000000001e-06     evaluation reward: 5.11\n",
      "episode: 1905   score: 2.0   memory length: 408776   epsilon: 0.3886215400101498    steps: 198    lr: 6.400000000000001e-06     evaluation reward: 5.07\n",
      "episode: 1906   score: 9.0   memory length: 409244   epsilon: 0.38769490001014395    steps: 468    lr: 6.400000000000001e-06     evaluation reward: 5.1\n",
      "episode: 1907   score: 9.0   memory length: 409709   epsilon: 0.3867742000101381    steps: 465    lr: 6.400000000000001e-06     evaluation reward: 5.16\n",
      "episode: 1908   score: 4.0   memory length: 409951   epsilon: 0.3862950400101351    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 5.18\n",
      "episode: 1909   score: 8.0   memory length: 410403   epsilon: 0.38540008001012943    steps: 452    lr: 6.400000000000001e-06     evaluation reward: 5.2\n",
      "episode: 1910   score: 7.0   memory length: 410775   epsilon: 0.38466352001012477    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 5.21\n",
      "episode: 1911   score: 4.0   memory length: 411052   epsilon: 0.3841150600101213    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 5.21\n",
      "episode: 1912   score: 3.0   memory length: 411300   epsilon: 0.3836240200101182    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 5.17\n",
      "episode: 1913   score: 6.0   memory length: 411667   epsilon: 0.3828973600101136    steps: 367    lr: 6.400000000000001e-06     evaluation reward: 5.2\n",
      "episode: 1914   score: 4.0   memory length: 411929   epsilon: 0.3823786000101103    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 5.2\n",
      "episode: 1915   score: 8.0   memory length: 412355   epsilon: 0.381535120010105    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 5.25\n",
      "episode: 1916   score: 6.0   memory length: 412692   epsilon: 0.38086786001010076    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 5.29\n",
      "episode: 1917   score: 7.0   memory length: 413094   epsilon: 0.3800719000100957    steps: 402    lr: 6.400000000000001e-06     evaluation reward: 5.3\n",
      "episode: 1918   score: 6.0   memory length: 413432   epsilon: 0.3794026600100915    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 5.32\n",
      "episode: 1919   score: 6.0   memory length: 413769   epsilon: 0.37873540001008726    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 5.35\n",
      "episode: 1920   score: 9.0   memory length: 414230   epsilon: 0.3778226200100815    steps: 461    lr: 6.400000000000001e-06     evaluation reward: 5.36\n",
      "episode: 1921   score: 6.0   memory length: 414606   epsilon: 0.3770781400100768    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 5.38\n",
      "episode: 1922   score: 4.0   memory length: 414846   epsilon: 0.3766029400100738    steps: 240    lr: 6.400000000000001e-06     evaluation reward: 5.4\n",
      "episode: 1923   score: 11.0   memory length: 415328   epsilon: 0.37564858001006773    steps: 482    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1924   score: 6.0   memory length: 415679   epsilon: 0.37495360001006334    steps: 351    lr: 6.400000000000001e-06     evaluation reward: 5.5\n",
      "episode: 1925   score: 5.0   memory length: 415951   epsilon: 0.37441504001005993    steps: 272    lr: 6.400000000000001e-06     evaluation reward: 5.51\n",
      "episode: 1926   score: 2.0   memory length: 416150   epsilon: 0.37402102001005744    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1927   score: 7.0   memory length: 416538   epsilon: 0.3732527800100526    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 5.46\n",
      "episode: 1928   score: 4.0   memory length: 416795   epsilon: 0.37274392001004936    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1929   score: 3.0   memory length: 417023   epsilon: 0.3722924800100465    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 5.46\n",
      "episode: 1930   score: 10.0   memory length: 417520   epsilon: 0.3713084200100403    steps: 497    lr: 6.400000000000001e-06     evaluation reward: 5.5\n",
      "episode: 1931   score: 6.0   memory length: 417887   epsilon: 0.3705817600100357    steps: 367    lr: 6.400000000000001e-06     evaluation reward: 5.51\n",
      "episode: 1932   score: 4.0   memory length: 418162   epsilon: 0.37003726001003223    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1933   score: 9.0   memory length: 418659   epsilon: 0.369053200010026    steps: 497    lr: 6.400000000000001e-06     evaluation reward: 5.53\n",
      "episode: 1934   score: 4.0   memory length: 418903   epsilon: 0.36857008001002295    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 5.54\n",
      "episode: 1935   score: 4.0   memory length: 419163   epsilon: 0.3680552800100197    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 5.51\n",
      "episode: 1936   score: 2.0   memory length: 419344   epsilon: 0.3676969000100174    steps: 181    lr: 6.400000000000001e-06     evaluation reward: 5.49\n",
      "episode: 1937   score: 6.0   memory length: 419678   epsilon: 0.36703558001001324    steps: 334    lr: 6.400000000000001e-06     evaluation reward: 5.5\n",
      "episode: 1938   score: 8.0   memory length: 420125   epsilon: 0.36615052001000764    steps: 447    lr: 6.400000000000001e-06     evaluation reward: 5.56\n",
      "episode: 1939   score: 7.0   memory length: 420491   epsilon: 0.36542584001000306    steps: 366    lr: 6.400000000000001e-06     evaluation reward: 5.6\n",
      "episode: 1940   score: 4.0   memory length: 420751   epsilon: 0.3649110400099998    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 5.62\n",
      "episode: 1941   score: 10.0   memory length: 421293   epsilon: 0.363837880009993    steps: 542    lr: 6.400000000000001e-06     evaluation reward: 5.66\n",
      "episode: 1942   score: 7.0   memory length: 421665   epsilon: 0.36310132000998835    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 5.72\n",
      "episode: 1943   score: 10.0   memory length: 422148   epsilon: 0.3621449800099823    steps: 483    lr: 6.400000000000001e-06     evaluation reward: 5.74\n",
      "episode: 1944   score: 2.0   memory length: 422346   epsilon: 0.3617529400099798    steps: 198    lr: 6.400000000000001e-06     evaluation reward: 5.73\n",
      "episode: 1945   score: 4.0   memory length: 422585   epsilon: 0.3612797200099768    steps: 239    lr: 6.400000000000001e-06     evaluation reward: 5.74\n",
      "episode: 1946   score: 8.0   memory length: 422984   epsilon: 0.3604897000099718    steps: 399    lr: 6.400000000000001e-06     evaluation reward: 5.79\n",
      "episode: 1947   score: 9.0   memory length: 423467   epsilon: 0.3595333600099658    steps: 483    lr: 6.400000000000001e-06     evaluation reward: 5.8\n",
      "episode: 1948   score: 8.0   memory length: 423920   epsilon: 0.3586364200099601    steps: 453    lr: 6.400000000000001e-06     evaluation reward: 5.83\n",
      "episode: 1949   score: 10.0   memory length: 424464   epsilon: 0.3575593000099533    steps: 544    lr: 6.400000000000001e-06     evaluation reward: 5.89\n",
      "episode: 1950   score: 9.0   memory length: 424950   epsilon: 0.3565970200099472    steps: 486    lr: 6.400000000000001e-06     evaluation reward: 5.96\n",
      "episode: 1951   score: 8.0   memory length: 425382   epsilon: 0.3557416600099418    steps: 432    lr: 6.400000000000001e-06     evaluation reward: 5.97\n",
      "episode: 1952   score: 8.0   memory length: 425805   epsilon: 0.3549041200099365    steps: 423    lr: 6.400000000000001e-06     evaluation reward: 6.01\n",
      "episode: 1953   score: 12.0   memory length: 426232   epsilon: 0.35405866000993114    steps: 427    lr: 6.400000000000001e-06     evaluation reward: 6.04\n",
      "episode: 1954   score: 3.0   memory length: 426443   epsilon: 0.3536408800099285    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 6.0\n",
      "episode: 1955   score: 8.0   memory length: 426855   epsilon: 0.35282512000992333    steps: 412    lr: 6.400000000000001e-06     evaluation reward: 6.02\n",
      "episode: 1956   score: 9.0   memory length: 427350   epsilon: 0.35184502000991713    steps: 495    lr: 6.400000000000001e-06     evaluation reward: 6.05\n",
      "episode: 1957   score: 6.0   memory length: 427724   epsilon: 0.35110450000991245    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 6.09\n",
      "episode: 1958   score: 4.0   memory length: 428000   epsilon: 0.350558020009909    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 6.09\n",
      "episode: 1959   score: 6.0   memory length: 428308   epsilon: 0.34994818000990513    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 6.1\n",
      "episode: 1960   score: 9.0   memory length: 428827   epsilon: 0.34892056000989863    steps: 519    lr: 6.400000000000001e-06     evaluation reward: 6.14\n",
      "episode: 1961   score: 4.0   memory length: 429108   epsilon: 0.3483641800098951    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 6.15\n",
      "episode: 1962   score: 5.0   memory length: 429418   epsilon: 0.3477503800098912    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 6.1\n",
      "episode: 1963   score: 4.0   memory length: 429678   epsilon: 0.34723558000988797    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 6.11\n",
      "episode: 1964   score: 6.0   memory length: 430032   epsilon: 0.34653466000988353    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 6.14\n",
      "episode: 1965   score: 9.0   memory length: 430392   epsilon: 0.345821860009879    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 6.19\n",
      "episode: 1966   score: 5.0   memory length: 430719   epsilon: 0.3451744000098749    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 6.21\n",
      "episode: 1967   score: 9.0   memory length: 431209   epsilon: 0.3442042000098688    steps: 490    lr: 6.400000000000001e-06     evaluation reward: 6.27\n",
      "episode: 1968   score: 9.0   memory length: 431699   epsilon: 0.34323400000986265    steps: 490    lr: 6.400000000000001e-06     evaluation reward: 6.29\n",
      "episode: 1969   score: 7.0   memory length: 432126   epsilon: 0.3423885400098573    steps: 427    lr: 6.400000000000001e-06     evaluation reward: 6.29\n",
      "episode: 1970   score: 3.0   memory length: 432356   epsilon: 0.3419331400098544    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 6.29\n",
      "episode: 1971   score: 13.0   memory length: 432875   epsilon: 0.3409055200098479    steps: 519    lr: 6.400000000000001e-06     evaluation reward: 6.35\n",
      "episode: 1972   score: 6.0   memory length: 433231   epsilon: 0.34020064000984346    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 6.35\n",
      "episode: 1973   score: 3.0   memory length: 433460   epsilon: 0.3397472200098406    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 6.35\n",
      "episode: 1974   score: 7.0   memory length: 433853   epsilon: 0.33896908000983567    steps: 393    lr: 6.400000000000001e-06     evaluation reward: 6.35\n",
      "episode: 1975   score: 10.0   memory length: 434213   epsilon: 0.33825628000983116    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 6.39\n",
      "episode: 1976   score: 4.0   memory length: 434490   epsilon: 0.3377078200098277    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 6.35\n",
      "episode: 1977   score: 3.0   memory length: 434700   epsilon: 0.33729202000982506    steps: 210    lr: 6.400000000000001e-06     evaluation reward: 6.3\n",
      "episode: 1978   score: 6.0   memory length: 435055   epsilon: 0.3365891200098206    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 6.35\n",
      "episode: 1979   score: 6.0   memory length: 435374   epsilon: 0.3359575000098166    steps: 319    lr: 6.400000000000001e-06     evaluation reward: 6.38\n",
      "episode: 1980   score: 2.0   memory length: 435572   epsilon: 0.33556546000981413    steps: 198    lr: 6.400000000000001e-06     evaluation reward: 6.37\n",
      "episode: 1981   score: 6.0   memory length: 435930   epsilon: 0.33485662000980965    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 6.4\n",
      "episode: 1982   score: 9.0   memory length: 436394   epsilon: 0.33393790000980383    steps: 464    lr: 6.400000000000001e-06     evaluation reward: 6.44\n",
      "episode: 1983   score: 6.0   memory length: 436810   epsilon: 0.3331142200097986    steps: 416    lr: 6.400000000000001e-06     evaluation reward: 6.46\n",
      "episode: 1984   score: 5.0   memory length: 437136   epsilon: 0.33246874000979454    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 6.46\n",
      "episode: 1985   score: 8.0   memory length: 437589   epsilon: 0.33157180000978886    steps: 453    lr: 6.400000000000001e-06     evaluation reward: 6.51\n",
      "episode: 1986   score: 3.0   memory length: 437838   epsilon: 0.33107878000978574    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 6.46\n",
      "episode: 1987   score: 7.0   memory length: 438208   epsilon: 0.3303461800097811    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 6.47\n",
      "episode: 1988   score: 6.0   memory length: 438550   epsilon: 0.3296690200097768    steps: 342    lr: 6.400000000000001e-06     evaluation reward: 6.46\n",
      "episode: 1989   score: 4.0   memory length: 438794   epsilon: 0.32918590000977377    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 6.43\n",
      "episode: 1990   score: 6.0   memory length: 439140   epsilon: 0.32850082000976943    steps: 346    lr: 6.400000000000001e-06     evaluation reward: 6.41\n",
      "episode: 1991   score: 2.0   memory length: 439340   epsilon: 0.32810482000976693    steps: 200    lr: 6.400000000000001e-06     evaluation reward: 6.34\n",
      "episode: 1992   score: 4.0   memory length: 439616   epsilon: 0.32755834000976347    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 6.3\n",
      "episode: 1993   score: 5.0   memory length: 439937   epsilon: 0.32692276000975945    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 6.27\n",
      "episode: 1994   score: 9.0   memory length: 440264   epsilon: 0.32627530000975535    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 6.31\n",
      "episode: 1995   score: 3.0   memory length: 440509   epsilon: 0.3257902000097523    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 6.26\n",
      "episode: 1996   score: 4.0   memory length: 440785   epsilon: 0.3252437200097488    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 6.23\n",
      "episode: 1997   score: 6.0   memory length: 441097   epsilon: 0.3246259600097449    steps: 312    lr: 6.400000000000001e-06     evaluation reward: 6.27\n",
      "episode: 1998   score: 3.0   memory length: 441323   epsilon: 0.3241784800097421    steps: 226    lr: 6.400000000000001e-06     evaluation reward: 6.24\n",
      "episode: 1999   score: 4.0   memory length: 441599   epsilon: 0.32363200000973863    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 6.24\n",
      "episode: 2000   score: 7.0   memory length: 441990   epsilon: 0.32285782000973373    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 6.26\n",
      "episode: 2001   score: 8.0   memory length: 442435   epsilon: 0.32197672000972816    steps: 445    lr: 6.400000000000001e-06     evaluation reward: 6.27\n",
      "episode: 2002   score: 6.0   memory length: 442787   epsilon: 0.32127976000972375    steps: 352    lr: 6.400000000000001e-06     evaluation reward: 6.23\n",
      "episode: 2003   score: 7.0   memory length: 443187   epsilon: 0.32048776000971874    steps: 400    lr: 6.400000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2004   score: 6.0   memory length: 443508   epsilon: 0.3198521800097147    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2005   score: 7.0   memory length: 443879   epsilon: 0.31911760000971007    steps: 371    lr: 6.400000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2006   score: 4.0   memory length: 444154   epsilon: 0.3185731000097066    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2007   score: 2.0   memory length: 444334   epsilon: 0.31821670000970437    steps: 180    lr: 6.400000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2008   score: 7.0   memory length: 444725   epsilon: 0.31744252000969947    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2009   score: 4.0   memory length: 444965   epsilon: 0.31696732000969646    steps: 240    lr: 6.400000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2010   score: 5.0   memory length: 445257   epsilon: 0.3163891600096928    steps: 292    lr: 6.400000000000001e-06     evaluation reward: 6.05\n",
      "episode: 2011   score: 9.0   memory length: 445743   epsilon: 0.3154268800096867    steps: 486    lr: 6.400000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2012   score: 6.0   memory length: 446100   epsilon: 0.31472002000968224    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2013   score: 8.0   memory length: 446521   epsilon: 0.31388644000967697    steps: 421    lr: 6.400000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2014   score: 4.0   memory length: 446762   epsilon: 0.31340926000967395    steps: 241    lr: 6.400000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2015   score: 9.0   memory length: 447254   epsilon: 0.3124351000096678    steps: 492    lr: 6.400000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2016   score: 6.0   memory length: 447606   epsilon: 0.3117381400096634    steps: 352    lr: 6.400000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2017   score: 4.0   memory length: 447852   epsilon: 0.3112510600096603    steps: 246    lr: 6.400000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2018   score: 9.0   memory length: 448365   epsilon: 0.31023532000965387    steps: 513    lr: 6.400000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2019   score: 7.0   memory length: 448760   epsilon: 0.3094532200096489    steps: 395    lr: 6.400000000000001e-06     evaluation reward: 6.17\n",
      "episode: 2020   score: 12.0   memory length: 449218   epsilon: 0.3085463800096432    steps: 458    lr: 6.400000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2021   score: 8.0   memory length: 449676   epsilon: 0.30763954000963745    steps: 458    lr: 6.400000000000001e-06     evaluation reward: 6.22\n",
      "episode: 2022   score: 8.0   memory length: 450096   epsilon: 0.3068079400096322    steps: 420    lr: 6.400000000000001e-06     evaluation reward: 6.26\n",
      "episode: 2023   score: 17.0   memory length: 450660   epsilon: 0.3056912200096251    steps: 564    lr: 6.400000000000001e-06     evaluation reward: 6.32\n",
      "episode: 2024   score: 5.0   memory length: 450968   epsilon: 0.30508138000962126    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 6.31\n",
      "episode: 2025   score: 6.0   memory length: 451313   epsilon: 0.30439828000961694    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 6.32\n",
      "episode: 2026   score: 7.0   memory length: 451706   epsilon: 0.303620140009612    steps: 393    lr: 6.400000000000001e-06     evaluation reward: 6.37\n",
      "episode: 2027   score: 13.0   memory length: 452325   epsilon: 0.30239452000960426    steps: 619    lr: 6.400000000000001e-06     evaluation reward: 6.43\n",
      "episode: 2028   score: 3.0   memory length: 452550   epsilon: 0.30194902000960144    steps: 225    lr: 6.400000000000001e-06     evaluation reward: 6.42\n",
      "episode: 2029   score: 6.0   memory length: 452889   epsilon: 0.3012778000095972    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 6.45\n",
      "episode: 2030   score: 4.0   memory length: 453145   epsilon: 0.300770920009594    steps: 256    lr: 6.400000000000001e-06     evaluation reward: 6.39\n",
      "episode: 2031   score: 6.0   memory length: 453500   epsilon: 0.30006802000958954    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 6.39\n",
      "episode: 2032   score: 2.0   memory length: 453698   epsilon: 0.29967598000958706    steps: 198    lr: 6.400000000000001e-06     evaluation reward: 6.37\n",
      "episode: 2033   score: 6.0   memory length: 454056   epsilon: 0.2989671400095826    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 6.34\n",
      "episode: 2034   score: 9.0   memory length: 454539   epsilon: 0.2980108000095765    steps: 483    lr: 6.400000000000001e-06     evaluation reward: 6.39\n",
      "episode: 2035   score: 8.0   memory length: 454963   epsilon: 0.2971712800095712    steps: 424    lr: 6.400000000000001e-06     evaluation reward: 6.43\n",
      "episode: 2036   score: 7.0   memory length: 455357   epsilon: 0.2963911600095663    steps: 394    lr: 6.400000000000001e-06     evaluation reward: 6.48\n",
      "episode: 2037   score: 6.0   memory length: 455701   epsilon: 0.29571004000956197    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 6.48\n",
      "episode: 2038   score: 9.0   memory length: 456141   epsilon: 0.29483884000955646    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 6.49\n",
      "episode: 2039   score: 8.0   memory length: 456534   epsilon: 0.29406070000955153    steps: 393    lr: 6.400000000000001e-06     evaluation reward: 6.5\n",
      "episode: 2040   score: 6.0   memory length: 456878   epsilon: 0.2933795800095472    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 6.52\n",
      "episode: 2041   score: 4.0   memory length: 457151   epsilon: 0.2928390400095438    steps: 273    lr: 6.400000000000001e-06     evaluation reward: 6.46\n",
      "episode: 2042   score: 4.0   memory length: 457395   epsilon: 0.29235592000954075    steps: 244    lr: 6.400000000000001e-06     evaluation reward: 6.43\n",
      "episode: 2043   score: 8.0   memory length: 457810   epsilon: 0.29153422000953555    steps: 415    lr: 6.400000000000001e-06     evaluation reward: 6.41\n",
      "episode: 2044   score: 10.0   memory length: 458319   epsilon: 0.2905264000095292    steps: 509    lr: 6.400000000000001e-06     evaluation reward: 6.49\n",
      "episode: 2045   score: 10.0   memory length: 458693   epsilon: 0.2897858800095245    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 6.55\n",
      "episode: 2046   score: 12.0   memory length: 459353   epsilon: 0.2884790800095162    steps: 660    lr: 6.400000000000001e-06     evaluation reward: 6.59\n",
      "episode: 2047   score: 11.0   memory length: 459869   epsilon: 0.28745740000950976    steps: 516    lr: 6.400000000000001e-06     evaluation reward: 6.61\n",
      "episode: 2048   score: 8.0   memory length: 460295   epsilon: 0.2866139200095044    steps: 426    lr: 6.400000000000001e-06     evaluation reward: 6.61\n",
      "episode: 2049   score: 4.0   memory length: 460573   epsilon: 0.28606348000950094    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 6.55\n",
      "episode: 2050   score: 4.0   memory length: 460851   epsilon: 0.28551304000949745    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 6.5\n",
      "episode: 2051   score: 7.0   memory length: 461242   epsilon: 0.28473886000949256    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 6.49\n",
      "episode: 2052   score: 8.0   memory length: 461654   epsilon: 0.2839231000094874    steps: 412    lr: 6.400000000000001e-06     evaluation reward: 6.49\n",
      "episode: 2053   score: 9.0   memory length: 462127   epsilon: 0.28298656000948147    steps: 473    lr: 6.400000000000001e-06     evaluation reward: 6.46\n",
      "episode: 2054   score: 11.0   memory length: 462643   epsilon: 0.281964880009475    steps: 516    lr: 6.400000000000001e-06     evaluation reward: 6.54\n",
      "episode: 2055   score: 7.0   memory length: 463024   epsilon: 0.28121050000947023    steps: 381    lr: 6.400000000000001e-06     evaluation reward: 6.53\n",
      "episode: 2056   score: 5.0   memory length: 463312   epsilon: 0.2806402600094666    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 6.49\n",
      "episode: 2057   score: 8.0   memory length: 463728   epsilon: 0.2798165800094614    steps: 416    lr: 6.400000000000001e-06     evaluation reward: 6.51\n",
      "episode: 2058   score: 3.0   memory length: 463957   epsilon: 0.27936316000945854    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 6.5\n",
      "episode: 2059   score: 5.0   memory length: 464253   epsilon: 0.27877708000945484    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 6.49\n",
      "episode: 2060   score: 10.0   memory length: 464763   epsilon: 0.27776728000944845    steps: 510    lr: 6.400000000000001e-06     evaluation reward: 6.5\n",
      "episode: 2061   score: 2.0   memory length: 464961   epsilon: 0.27737524000944597    steps: 198    lr: 6.400000000000001e-06     evaluation reward: 6.48\n",
      "episode: 2062   score: 6.0   memory length: 465317   epsilon: 0.2766703600094415    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 6.49\n",
      "episode: 2063   score: 9.0   memory length: 465822   epsilon: 0.2756704600094352    steps: 505    lr: 6.400000000000001e-06     evaluation reward: 6.54\n",
      "episode: 2064   score: 3.0   memory length: 466049   epsilon: 0.27522100000943234    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 6.51\n",
      "episode: 2065   score: 7.0   memory length: 466438   epsilon: 0.27445078000942746    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 6.49\n",
      "episode: 2066   score: 8.0   memory length: 466857   epsilon: 0.2736211600094222    steps: 419    lr: 6.400000000000001e-06     evaluation reward: 6.52\n",
      "episode: 2067   score: 9.0   memory length: 467328   epsilon: 0.2726885800094163    steps: 471    lr: 6.400000000000001e-06     evaluation reward: 6.52\n",
      "episode: 2068   score: 5.0   memory length: 467616   epsilon: 0.2721183400094127    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 6.48\n",
      "episode: 2069   score: 6.0   memory length: 467953   epsilon: 0.2714510800094085    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 6.47\n",
      "episode: 2070   score: 4.0   memory length: 468196   epsilon: 0.27096994000940544    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 6.48\n",
      "episode: 2071   score: 3.0   memory length: 468425   epsilon: 0.2705165200094026    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 6.38\n",
      "episode: 2072   score: 5.0   memory length: 468731   epsilon: 0.26991064000939874    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 6.37\n",
      "episode: 2073   score: 5.0   memory length: 469037   epsilon: 0.2693047600093949    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 6.39\n",
      "episode: 2074   score: 5.0   memory length: 469364   epsilon: 0.2686573000093908    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 6.37\n",
      "episode: 2075   score: 10.0   memory length: 469850   epsilon: 0.2676950200093847    steps: 486    lr: 6.400000000000001e-06     evaluation reward: 6.37\n",
      "episode: 2076   score: 9.0   memory length: 470321   epsilon: 0.2667624400093788    steps: 471    lr: 6.400000000000001e-06     evaluation reward: 6.42\n",
      "episode: 2077   score: 8.0   memory length: 470761   epsilon: 0.2658912400093733    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 6.47\n",
      "episode: 2078   score: 8.0   memory length: 471168   epsilon: 0.2650853800093682    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 6.49\n",
      "episode: 2079   score: 3.0   memory length: 471381   epsilon: 0.26466364000936554    steps: 213    lr: 6.400000000000001e-06     evaluation reward: 6.46\n",
      "episode: 2080   score: 9.0   memory length: 471697   epsilon: 0.2640379600093616    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 6.53\n",
      "episode: 2081   score: 11.0   memory length: 472231   epsilon: 0.2629806400093549    steps: 534    lr: 6.400000000000001e-06     evaluation reward: 6.58\n",
      "episode: 2082   score: 7.0   memory length: 472591   epsilon: 0.2622678400093504    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 6.56\n",
      "episode: 2083   score: 6.0   memory length: 472935   epsilon: 0.2615867200093461    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 6.56\n",
      "episode: 2084   score: 3.0   memory length: 473182   epsilon: 0.261097660009343    steps: 247    lr: 6.400000000000001e-06     evaluation reward: 6.54\n",
      "episode: 2085   score: 6.0   memory length: 473538   epsilon: 0.2603927800093385    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 6.52\n",
      "episode: 2086   score: 5.0   memory length: 473829   epsilon: 0.2598166000093349    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 6.54\n",
      "episode: 2087   score: 10.0   memory length: 474318   epsilon: 0.25884838000932875    steps: 489    lr: 6.400000000000001e-06     evaluation reward: 6.57\n",
      "episode: 2088   score: 14.0   memory length: 474953   epsilon: 0.2575910800093208    steps: 635    lr: 6.400000000000001e-06     evaluation reward: 6.65\n",
      "episode: 2089   score: 6.0   memory length: 475311   epsilon: 0.2568822400093163    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 6.67\n",
      "episode: 2090   score: 6.0   memory length: 475666   epsilon: 0.25617934000931186    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 6.67\n",
      "episode: 2091   score: 3.0   memory length: 475894   epsilon: 0.255727900009309    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 6.68\n",
      "episode: 2092   score: 4.0   memory length: 476171   epsilon: 0.25517944000930554    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 6.68\n",
      "episode: 2093   score: 5.0   memory length: 476498   epsilon: 0.25453198000930144    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 6.68\n",
      "episode: 2094   score: 11.0   memory length: 477063   epsilon: 0.25341328000929436    steps: 565    lr: 6.400000000000001e-06     evaluation reward: 6.7\n",
      "episode: 2095   score: 8.0   memory length: 477452   epsilon: 0.2526430600092895    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 6.75\n",
      "episode: 2096   score: 11.0   memory length: 478017   epsilon: 0.2515243600092824    steps: 565    lr: 6.400000000000001e-06     evaluation reward: 6.82\n",
      "episode: 2097   score: 9.0   memory length: 478447   epsilon: 0.250672960009277    steps: 430    lr: 6.400000000000001e-06     evaluation reward: 6.85\n",
      "episode: 2098   score: 10.0   memory length: 478956   epsilon: 0.24966514000927065    steps: 509    lr: 6.400000000000001e-06     evaluation reward: 6.92\n",
      "episode: 2099   score: 8.0   memory length: 479393   epsilon: 0.24879988000926517    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 6.96\n",
      "episode: 2100   score: 6.0   memory length: 479715   epsilon: 0.24816232000926114    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 6.95\n",
      "episode: 2101   score: 8.0   memory length: 480151   epsilon: 0.24729904000925568    steps: 436    lr: 6.400000000000001e-06     evaluation reward: 6.95\n",
      "episode: 2102   score: 6.0   memory length: 480488   epsilon: 0.24663178000925146    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 6.95\n",
      "episode: 2103   score: 8.0   memory length: 480910   epsilon: 0.24579622000924617    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 6.96\n",
      "episode: 2104   score: 7.0   memory length: 481272   epsilon: 0.24507946000924163    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 6.97\n",
      "episode: 2105   score: 8.0   memory length: 481690   epsilon: 0.2442518200092364    steps: 418    lr: 6.400000000000001e-06     evaluation reward: 6.98\n",
      "episode: 2106   score: 9.0   memory length: 482121   epsilon: 0.243398440009231    steps: 431    lr: 6.400000000000001e-06     evaluation reward: 7.03\n",
      "episode: 2107   score: 8.0   memory length: 482540   epsilon: 0.24256882000922575    steps: 419    lr: 6.400000000000001e-06     evaluation reward: 7.09\n",
      "episode: 2108   score: 4.0   memory length: 482799   epsilon: 0.2420560000092225    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 7.06\n",
      "episode: 2109   score: 13.0   memory length: 483285   epsilon: 0.24109372000921642    steps: 486    lr: 6.400000000000001e-06     evaluation reward: 7.15\n",
      "episode: 2110   score: 8.0   memory length: 483724   epsilon: 0.24022450000921092    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 7.18\n",
      "episode: 2111   score: 8.0   memory length: 484094   epsilon: 0.23949190000920628    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 7.17\n",
      "episode: 2112   score: 10.0   memory length: 484634   epsilon: 0.23842270000919952    steps: 540    lr: 6.400000000000001e-06     evaluation reward: 7.21\n",
      "episode: 2113   score: 8.0   memory length: 485070   epsilon: 0.23755942000919406    steps: 436    lr: 6.400000000000001e-06     evaluation reward: 7.21\n",
      "episode: 2114   score: 8.0   memory length: 485495   epsilon: 0.23671792000918873    steps: 425    lr: 6.400000000000001e-06     evaluation reward: 7.25\n",
      "episode: 2115   score: 10.0   memory length: 486019   epsilon: 0.23568040000918217    steps: 524    lr: 6.400000000000001e-06     evaluation reward: 7.26\n",
      "episode: 2116   score: 9.0   memory length: 486494   epsilon: 0.23473990000917622    steps: 475    lr: 6.400000000000001e-06     evaluation reward: 7.29\n",
      "episode: 2117   score: 8.0   memory length: 486911   epsilon: 0.233914240009171    steps: 417    lr: 6.400000000000001e-06     evaluation reward: 7.33\n",
      "episode: 2118   score: 15.0   memory length: 487498   epsilon: 0.23275198000916364    steps: 587    lr: 6.400000000000001e-06     evaluation reward: 7.39\n",
      "episode: 2119   score: 4.0   memory length: 487773   epsilon: 0.2322074800091602    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 7.36\n",
      "episode: 2120   score: 7.0   memory length: 488147   epsilon: 0.2314669600091555    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 7.31\n",
      "episode: 2121   score: 8.0   memory length: 488596   epsilon: 0.23057794000914988    steps: 449    lr: 6.400000000000001e-06     evaluation reward: 7.31\n",
      "episode: 2122   score: 3.0   memory length: 488824   epsilon: 0.23012650000914703    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 7.26\n",
      "episode: 2123   score: 7.0   memory length: 489197   epsilon: 0.22938796000914236    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 7.16\n",
      "episode: 2124   score: 13.0   memory length: 489673   epsilon: 0.2284454800091364    steps: 476    lr: 6.400000000000001e-06     evaluation reward: 7.24\n",
      "episode: 2125   score: 6.0   memory length: 490030   epsilon: 0.22773862000913192    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 7.24\n",
      "episode: 2126   score: 5.0   memory length: 490326   epsilon: 0.2271525400091282    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 7.22\n",
      "episode: 2127   score: 7.0   memory length: 490701   epsilon: 0.22641004000912351    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 7.16\n",
      "episode: 2128   score: 7.0   memory length: 491128   epsilon: 0.22556458000911817    steps: 427    lr: 6.400000000000001e-06     evaluation reward: 7.2\n",
      "episode: 2129   score: 12.0   memory length: 491617   epsilon: 0.22459636000911204    steps: 489    lr: 6.400000000000001e-06     evaluation reward: 7.26\n",
      "episode: 2130   score: 4.0   memory length: 491912   epsilon: 0.22401226000910834    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 7.26\n",
      "episode: 2131   score: 7.0   memory length: 492298   epsilon: 0.2232479800091035    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 7.27\n",
      "episode: 2132   score: 9.0   memory length: 492756   epsilon: 0.22234114000909777    steps: 458    lr: 6.400000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2133   score: 10.0   memory length: 493283   epsilon: 0.22129768000909117    steps: 527    lr: 6.400000000000001e-06     evaluation reward: 7.38\n",
      "episode: 2134   score: 7.0   memory length: 493669   epsilon: 0.22053340000908633    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 7.36\n",
      "episode: 2135   score: 7.0   memory length: 494115   epsilon: 0.21965032000908075    steps: 446    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2136   score: 6.0   memory length: 494463   epsilon: 0.2189612800090764    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2137   score: 7.0   memory length: 494803   epsilon: 0.21828808000907213    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2138   score: 7.0   memory length: 495194   epsilon: 0.21751390000906723    steps: 391    lr: 6.400000000000001e-06     evaluation reward: 7.33\n",
      "episode: 2139   score: 12.0   memory length: 495647   epsilon: 0.21661696000906155    steps: 453    lr: 6.400000000000001e-06     evaluation reward: 7.37\n",
      "episode: 2140   score: 15.0   memory length: 496242   epsilon: 0.2154388600090541    steps: 595    lr: 6.400000000000001e-06     evaluation reward: 7.46\n",
      "episode: 2141   score: 13.0   memory length: 496818   epsilon: 0.21429838000904688    steps: 576    lr: 6.400000000000001e-06     evaluation reward: 7.55\n",
      "episode: 2142   score: 8.0   memory length: 497264   epsilon: 0.2134153000090413    steps: 446    lr: 6.400000000000001e-06     evaluation reward: 7.59\n",
      "episode: 2143   score: 3.0   memory length: 497475   epsilon: 0.21299752000903865    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 7.54\n",
      "episode: 2144   score: 7.0   memory length: 497847   epsilon: 0.212260960009034    steps: 372    lr: 6.400000000000001e-06     evaluation reward: 7.51\n",
      "episode: 2145   score: 7.0   memory length: 498239   epsilon: 0.21148480000902908    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 7.48\n",
      "episode: 2146   score: 7.0   memory length: 498616   epsilon: 0.21073834000902436    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 7.43\n",
      "episode: 2147   score: 4.0   memory length: 498891   epsilon: 0.21019384000902092    steps: 275    lr: 6.400000000000001e-06     evaluation reward: 7.36\n",
      "episode: 2148   score: 2.0   memory length: 499089   epsilon: 0.20980180000901844    steps: 198    lr: 6.400000000000001e-06     evaluation reward: 7.3\n",
      "episode: 2149   score: 8.0   memory length: 499494   epsilon: 0.20899990000901336    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2150   score: 6.0   memory length: 499819   epsilon: 0.2083564000090093    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 7.36\n",
      "episode: 2151   score: 6.0   memory length: 500213   epsilon: 0.20757628000900435    steps: 394    lr: 2.560000000000001e-06     evaluation reward: 7.35\n",
      "episode: 2152   score: 5.0   memory length: 500521   epsilon: 0.2069664400090005    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 7.32\n",
      "episode: 2153   score: 6.0   memory length: 500862   epsilon: 0.20629126000899622    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 7.29\n",
      "episode: 2154   score: 11.0   memory length: 501312   epsilon: 0.2054002600089906    steps: 450    lr: 2.560000000000001e-06     evaluation reward: 7.29\n",
      "episode: 2155   score: 7.0   memory length: 501719   epsilon: 0.2045944000089855    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 7.29\n",
      "episode: 2156   score: 6.0   memory length: 502091   epsilon: 0.20385784000898083    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 7.3\n",
      "episode: 2157   score: 5.0   memory length: 502397   epsilon: 0.203251960008977    steps: 306    lr: 2.560000000000001e-06     evaluation reward: 7.27\n",
      "episode: 2158   score: 9.0   memory length: 502922   epsilon: 0.20221246000897042    steps: 525    lr: 2.560000000000001e-06     evaluation reward: 7.33\n",
      "episode: 2159   score: 6.0   memory length: 503254   epsilon: 0.20155510000896626    steps: 332    lr: 2.560000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2160   score: 10.0   memory length: 503612   epsilon: 0.20084626000896177    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 7.34\n",
      "episode: 2161   score: 8.0   memory length: 504051   epsilon: 0.19997704000895627    steps: 439    lr: 2.560000000000001e-06     evaluation reward: 7.4\n",
      "episode: 2162   score: 6.0   memory length: 504407   epsilon: 0.19927216000895182    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 7.4\n",
      "episode: 2163   score: 20.0   memory length: 505104   epsilon: 0.19789210000894308    steps: 697    lr: 2.560000000000001e-06     evaluation reward: 7.51\n",
      "episode: 2164   score: 4.0   memory length: 505363   epsilon: 0.19737928000893984    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 7.52\n",
      "episode: 2165   score: 8.0   memory length: 505806   epsilon: 0.1965021400089343    steps: 443    lr: 2.560000000000001e-06     evaluation reward: 7.53\n",
      "episode: 2166   score: 4.0   memory length: 506102   epsilon: 0.19591606000893058    steps: 296    lr: 2.560000000000001e-06     evaluation reward: 7.49\n",
      "episode: 2167   score: 9.0   memory length: 506570   epsilon: 0.19498942000892472    steps: 468    lr: 2.560000000000001e-06     evaluation reward: 7.49\n",
      "episode: 2168   score: 15.0   memory length: 507146   epsilon: 0.1938489400089175    steps: 576    lr: 2.560000000000001e-06     evaluation reward: 7.59\n",
      "episode: 2169   score: 10.0   memory length: 507632   epsilon: 0.19288666000891141    steps: 486    lr: 2.560000000000001e-06     evaluation reward: 7.63\n",
      "episode: 2170   score: 4.0   memory length: 507909   epsilon: 0.19233820000890794    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 7.63\n",
      "episode: 2171   score: 5.0   memory length: 508217   epsilon: 0.1917283600089041    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 7.65\n",
      "episode: 2172   score: 10.0   memory length: 508723   epsilon: 0.19072648000889775    steps: 506    lr: 2.560000000000001e-06     evaluation reward: 7.7\n",
      "episode: 2173   score: 8.0   memory length: 509175   epsilon: 0.18983152000889209    steps: 452    lr: 2.560000000000001e-06     evaluation reward: 7.73\n",
      "episode: 2174   score: 14.0   memory length: 509803   epsilon: 0.18858808000888422    steps: 628    lr: 2.560000000000001e-06     evaluation reward: 7.82\n",
      "episode: 2175   score: 7.0   memory length: 510197   epsilon: 0.18780796000887928    steps: 394    lr: 2.560000000000001e-06     evaluation reward: 7.79\n",
      "episode: 2176   score: 12.0   memory length: 510788   epsilon: 0.18663778000887188    steps: 591    lr: 2.560000000000001e-06     evaluation reward: 7.82\n",
      "episode: 2177   score: 5.0   memory length: 511115   epsilon: 0.18599032000886778    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 7.79\n",
      "episode: 2178   score: 5.0   memory length: 511438   epsilon: 0.18535078000886374    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 7.76\n",
      "episode: 2179   score: 8.0   memory length: 511854   epsilon: 0.18452710000885852    steps: 416    lr: 2.560000000000001e-06     evaluation reward: 7.81\n",
      "episode: 2180   score: 2.0   memory length: 512052   epsilon: 0.18413506000885604    steps: 198    lr: 2.560000000000001e-06     evaluation reward: 7.74\n",
      "episode: 2181   score: 6.0   memory length: 512425   epsilon: 0.18339652000885137    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 7.69\n",
      "episode: 2182   score: 5.0   memory length: 512714   epsilon: 0.18282430000884775    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 7.67\n",
      "episode: 2183   score: 11.0   memory length: 513250   epsilon: 0.18176302000884104    steps: 536    lr: 2.560000000000001e-06     evaluation reward: 7.72\n",
      "episode: 2184   score: 5.0   memory length: 513543   epsilon: 0.18118288000883737    steps: 293    lr: 2.560000000000001e-06     evaluation reward: 7.74\n",
      "episode: 2185   score: 11.0   memory length: 513951   epsilon: 0.18037504000883225    steps: 408    lr: 2.560000000000001e-06     evaluation reward: 7.79\n",
      "episode: 2186   score: 7.0   memory length: 514329   epsilon: 0.17962660000882752    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 7.81\n",
      "episode: 2187   score: 7.0   memory length: 514733   epsilon: 0.17882668000882246    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 7.78\n",
      "episode: 2188   score: 4.0   memory length: 515009   epsilon: 0.178280200008819    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 7.68\n",
      "episode: 2189   score: 6.0   memory length: 515366   epsilon: 0.17757334000881453    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 7.68\n",
      "episode: 2190   score: 4.0   memory length: 515610   epsilon: 0.17709022000881147    steps: 244    lr: 2.560000000000001e-06     evaluation reward: 7.66\n",
      "episode: 2191   score: 6.0   memory length: 515989   epsilon: 0.17633980000880672    steps: 379    lr: 2.560000000000001e-06     evaluation reward: 7.69\n",
      "episode: 2192   score: 5.0   memory length: 516331   epsilon: 0.17566264000880244    steps: 342    lr: 2.560000000000001e-06     evaluation reward: 7.7\n",
      "episode: 2193   score: 4.0   memory length: 516590   epsilon: 0.1751498200087992    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 7.69\n",
      "episode: 2194   score: 11.0   memory length: 517111   epsilon: 0.17411824000879267    steps: 521    lr: 2.560000000000001e-06     evaluation reward: 7.69\n",
      "episode: 2195   score: 9.0   memory length: 517612   epsilon: 0.1731262600087864    steps: 501    lr: 2.560000000000001e-06     evaluation reward: 7.7\n",
      "episode: 2196   score: 12.0   memory length: 518156   epsilon: 0.17204914000877958    steps: 544    lr: 2.560000000000001e-06     evaluation reward: 7.71\n",
      "episode: 2197   score: 11.0   memory length: 518720   epsilon: 0.1709324200087725    steps: 564    lr: 2.560000000000001e-06     evaluation reward: 7.73\n",
      "episode: 2198   score: 6.0   memory length: 519080   epsilon: 0.170219620008768    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 7.69\n",
      "episode: 2199   score: 7.0   memory length: 519441   epsilon: 0.16950484000876348    steps: 361    lr: 2.560000000000001e-06     evaluation reward: 7.68\n",
      "episode: 2200   score: 9.0   memory length: 519884   epsilon: 0.16862770000875793    steps: 443    lr: 2.560000000000001e-06     evaluation reward: 7.71\n",
      "episode: 2201   score: 5.0   memory length: 520179   epsilon: 0.16804360000875423    steps: 295    lr: 2.560000000000001e-06     evaluation reward: 7.68\n",
      "episode: 2202   score: 10.0   memory length: 520649   epsilon: 0.16711300000874835    steps: 470    lr: 2.560000000000001e-06     evaluation reward: 7.72\n",
      "episode: 2203   score: 7.0   memory length: 521011   epsilon: 0.1663962400087438    steps: 362    lr: 2.560000000000001e-06     evaluation reward: 7.71\n",
      "episode: 2204   score: 4.0   memory length: 521286   epsilon: 0.16585174000874037    steps: 275    lr: 2.560000000000001e-06     evaluation reward: 7.68\n",
      "episode: 2205   score: 10.0   memory length: 521814   epsilon: 0.16480630000873375    steps: 528    lr: 2.560000000000001e-06     evaluation reward: 7.7\n",
      "episode: 2206   score: 9.0   memory length: 522286   epsilon: 0.16387174000872784    steps: 472    lr: 2.560000000000001e-06     evaluation reward: 7.7\n",
      "episode: 2207   score: 7.0   memory length: 522678   epsilon: 0.16309558000872293    steps: 392    lr: 2.560000000000001e-06     evaluation reward: 7.69\n",
      "episode: 2208   score: 7.0   memory length: 523052   epsilon: 0.16235506000871824    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 7.72\n",
      "episode: 2209   score: 13.0   memory length: 523552   epsilon: 0.16136506000871198    steps: 500    lr: 2.560000000000001e-06     evaluation reward: 7.72\n",
      "episode: 2210   score: 6.0   memory length: 523876   epsilon: 0.16072354000870792    steps: 324    lr: 2.560000000000001e-06     evaluation reward: 7.7\n",
      "episode: 2211   score: 10.0   memory length: 524417   epsilon: 0.15965236000870114    steps: 541    lr: 2.560000000000001e-06     evaluation reward: 7.72\n",
      "episode: 2212   score: 5.0   memory length: 524716   epsilon: 0.1590603400086974    steps: 299    lr: 2.560000000000001e-06     evaluation reward: 7.67\n",
      "episode: 2213   score: 12.0   memory length: 525284   epsilon: 0.15793570000869028    steps: 568    lr: 2.560000000000001e-06     evaluation reward: 7.71\n",
      "episode: 2214   score: 8.0   memory length: 525722   epsilon: 0.1570684600086848    steps: 438    lr: 2.560000000000001e-06     evaluation reward: 7.71\n",
      "episode: 2215   score: 4.0   memory length: 525984   epsilon: 0.1565497000086815    steps: 262    lr: 2.560000000000001e-06     evaluation reward: 7.65\n",
      "episode: 2216   score: 8.0   memory length: 526384   epsilon: 0.1557577000086765    steps: 400    lr: 2.560000000000001e-06     evaluation reward: 7.64\n",
      "episode: 2217   score: 10.0   memory length: 526904   epsilon: 0.15472810000867    steps: 520    lr: 2.560000000000001e-06     evaluation reward: 7.66\n",
      "episode: 2218   score: 5.0   memory length: 527231   epsilon: 0.1540806400086659    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 7.56\n",
      "episode: 2219   score: 14.0   memory length: 527742   epsilon: 0.1530688600086595    steps: 511    lr: 2.560000000000001e-06     evaluation reward: 7.66\n",
      "episode: 2220   score: 8.0   memory length: 528168   epsilon: 0.15222538000865415    steps: 426    lr: 2.560000000000001e-06     evaluation reward: 7.67\n",
      "episode: 2221   score: 5.0   memory length: 528473   epsilon: 0.15162148000865033    steps: 305    lr: 2.560000000000001e-06     evaluation reward: 7.64\n",
      "episode: 2222   score: 11.0   memory length: 528960   epsilon: 0.15065722000864423    steps: 487    lr: 2.560000000000001e-06     evaluation reward: 7.72\n",
      "episode: 2223   score: 8.0   memory length: 529440   epsilon: 0.14970682000863822    steps: 480    lr: 2.560000000000001e-06     evaluation reward: 7.73\n",
      "episode: 2224   score: 5.0   memory length: 529710   epsilon: 0.14917222000863484    steps: 270    lr: 2.560000000000001e-06     evaluation reward: 7.65\n",
      "episode: 2225   score: 4.0   memory length: 529984   epsilon: 0.1486297000086314    steps: 274    lr: 2.560000000000001e-06     evaluation reward: 7.63\n",
      "episode: 2226   score: 14.0   memory length: 530553   epsilon: 0.14750308000862428    steps: 569    lr: 2.560000000000001e-06     evaluation reward: 7.72\n",
      "episode: 2227   score: 8.0   memory length: 530992   epsilon: 0.14663386000861878    steps: 439    lr: 2.560000000000001e-06     evaluation reward: 7.73\n",
      "episode: 2228   score: 7.0   memory length: 531417   epsilon: 0.14579236000861345    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 7.73\n",
      "episode: 2229   score: 15.0   memory length: 531978   epsilon: 0.14468158000860643    steps: 561    lr: 2.560000000000001e-06     evaluation reward: 7.76\n",
      "episode: 2230   score: 9.0   memory length: 532422   epsilon: 0.14380246000860086    steps: 444    lr: 2.560000000000001e-06     evaluation reward: 7.81\n",
      "episode: 2231   score: 3.0   memory length: 532649   epsilon: 0.14335300000859802    steps: 227    lr: 2.560000000000001e-06     evaluation reward: 7.77\n",
      "episode: 2232   score: 6.0   memory length: 532995   epsilon: 0.14266792000859368    steps: 346    lr: 2.560000000000001e-06     evaluation reward: 7.74\n",
      "episode: 2233   score: 6.0   memory length: 533322   epsilon: 0.1420204600085896    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 7.7\n",
      "episode: 2234   score: 4.0   memory length: 533582   epsilon: 0.14150566000858633    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 7.67\n",
      "episode: 2235   score: 5.0   memory length: 533889   epsilon: 0.14089780000858249    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 7.65\n",
      "episode: 2236   score: 11.0   memory length: 534419   epsilon: 0.13984840000857585    steps: 530    lr: 2.560000000000001e-06     evaluation reward: 7.7\n",
      "episode: 2237   score: 10.0   memory length: 534928   epsilon: 0.13884058000856947    steps: 509    lr: 2.560000000000001e-06     evaluation reward: 7.73\n",
      "episode: 2238   score: 9.0   memory length: 535399   epsilon: 0.13790800000856357    steps: 471    lr: 2.560000000000001e-06     evaluation reward: 7.75\n",
      "episode: 2239   score: 14.0   memory length: 535976   epsilon: 0.13676554000855634    steps: 577    lr: 2.560000000000001e-06     evaluation reward: 7.77\n",
      "episode: 2240   score: 6.0   memory length: 536332   epsilon: 0.13606066000855188    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 7.68\n",
      "episode: 2241   score: 7.0   memory length: 536710   epsilon: 0.13531222000854715    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 7.62\n",
      "episode: 2242   score: 15.0   memory length: 537328   epsilon: 0.1340885800085394    steps: 618    lr: 2.560000000000001e-06     evaluation reward: 7.69\n",
      "episode: 2243   score: 5.0   memory length: 537621   epsilon: 0.13350844000853573    steps: 293    lr: 2.560000000000001e-06     evaluation reward: 7.71\n",
      "episode: 2244   score: 4.0   memory length: 537937   epsilon: 0.13288276000853178    steps: 316    lr: 2.560000000000001e-06     evaluation reward: 7.68\n",
      "episode: 2245   score: 5.0   memory length: 538230   epsilon: 0.1323026200085281    steps: 293    lr: 2.560000000000001e-06     evaluation reward: 7.66\n",
      "episode: 2246   score: 6.0   memory length: 538542   epsilon: 0.1316848600085242    steps: 312    lr: 2.560000000000001e-06     evaluation reward: 7.65\n",
      "episode: 2247   score: 14.0   memory length: 539115   epsilon: 0.13055032000851702    steps: 573    lr: 2.560000000000001e-06     evaluation reward: 7.75\n",
      "episode: 2248   score: 9.0   memory length: 539554   epsilon: 0.12968110000851152    steps: 439    lr: 2.560000000000001e-06     evaluation reward: 7.82\n",
      "episode: 2249   score: 6.0   memory length: 539905   epsilon: 0.12898612000850712    steps: 351    lr: 2.560000000000001e-06     evaluation reward: 7.8\n",
      "episode: 2250   score: 5.0   memory length: 540231   epsilon: 0.12834064000850304    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 7.79\n",
      "episode: 2251   score: 14.0   memory length: 540612   epsilon: 0.12758626000849826    steps: 381    lr: 2.560000000000001e-06     evaluation reward: 7.87\n",
      "episode: 2252   score: 8.0   memory length: 541046   epsilon: 0.12672694000849283    steps: 434    lr: 2.560000000000001e-06     evaluation reward: 7.9\n",
      "episode: 2253   score: 5.0   memory length: 541334   epsilon: 0.12615670000848922    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 7.89\n",
      "episode: 2254   score: 9.0   memory length: 541784   epsilon: 0.12526570000848358    steps: 450    lr: 2.560000000000001e-06     evaluation reward: 7.87\n",
      "episode: 2255   score: 5.0   memory length: 542093   epsilon: 0.12465388000848214    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 7.85\n",
      "episode: 2256   score: 7.0   memory length: 542487   epsilon: 0.12387376000848267    steps: 394    lr: 2.560000000000001e-06     evaluation reward: 7.86\n",
      "episode: 2257   score: 9.0   memory length: 542929   epsilon: 0.12299860000848327    steps: 442    lr: 2.560000000000001e-06     evaluation reward: 7.9\n",
      "episode: 2258   score: 7.0   memory length: 543279   epsilon: 0.12230560000848374    steps: 350    lr: 2.560000000000001e-06     evaluation reward: 7.88\n",
      "episode: 2259   score: 24.0   memory length: 544199   epsilon: 0.12048400000848498    steps: 920    lr: 2.560000000000001e-06     evaluation reward: 8.06\n",
      "episode: 2260   score: 8.0   memory length: 544583   epsilon: 0.1197236800084855    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 8.04\n",
      "episode: 2261   score: 27.0   memory length: 545393   epsilon: 0.1181198800084866    steps: 810    lr: 2.560000000000001e-06     evaluation reward: 8.23\n",
      "episode: 2262   score: 10.0   memory length: 545917   epsilon: 0.1170823600084873    steps: 524    lr: 2.560000000000001e-06     evaluation reward: 8.27\n",
      "episode: 2263   score: 9.0   memory length: 546411   epsilon: 0.11610424000848797    steps: 494    lr: 2.560000000000001e-06     evaluation reward: 8.16\n",
      "episode: 2264   score: 5.0   memory length: 546699   epsilon: 0.11553400000848836    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 8.17\n",
      "episode: 2265   score: 5.0   memory length: 546972   epsilon: 0.11499346000848873    steps: 273    lr: 2.560000000000001e-06     evaluation reward: 8.14\n",
      "episode: 2266   score: 2.0   memory length: 547170   epsilon: 0.114601420008489    steps: 198    lr: 2.560000000000001e-06     evaluation reward: 8.12\n",
      "episode: 2267   score: 12.0   memory length: 547678   epsilon: 0.11359558000848968    steps: 508    lr: 2.560000000000001e-06     evaluation reward: 8.15\n",
      "episode: 2268   score: 4.0   memory length: 547954   epsilon: 0.11304910000849006    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 8.04\n",
      "episode: 2269   score: 9.0   memory length: 548407   epsilon: 0.11215216000849067    steps: 453    lr: 2.560000000000001e-06     evaluation reward: 8.03\n",
      "episode: 2270   score: 7.0   memory length: 548780   epsilon: 0.11141362000849117    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 8.06\n",
      "episode: 2271   score: 6.0   memory length: 549117   epsilon: 0.11074636000849163    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 8.07\n",
      "episode: 2272   score: 15.0   memory length: 549723   epsilon: 0.10954648000849244    steps: 606    lr: 2.560000000000001e-06     evaluation reward: 8.12\n",
      "episode: 2273   score: 7.0   memory length: 550093   epsilon: 0.10881388000849294    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 8.11\n",
      "episode: 2274   score: 7.0   memory length: 550487   epsilon: 0.10803376000849348    steps: 394    lr: 2.560000000000001e-06     evaluation reward: 8.04\n",
      "episode: 2275   score: 9.0   memory length: 550874   epsilon: 0.107267500008494    steps: 387    lr: 2.560000000000001e-06     evaluation reward: 8.06\n",
      "episode: 2276   score: 8.0   memory length: 551280   epsilon: 0.10646362000849455    steps: 406    lr: 2.560000000000001e-06     evaluation reward: 8.02\n",
      "episode: 2277   score: 17.0   memory length: 551907   epsilon: 0.1052221600084954    steps: 627    lr: 2.560000000000001e-06     evaluation reward: 8.14\n",
      "episode: 2278   score: 3.0   memory length: 552120   epsilon: 0.10480042000849568    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 8.12\n",
      "episode: 2279   score: 10.0   memory length: 552642   epsilon: 0.10376686000849639    steps: 522    lr: 2.560000000000001e-06     evaluation reward: 8.14\n",
      "episode: 2280   score: 5.0   memory length: 552935   epsilon: 0.10318672000849678    steps: 293    lr: 2.560000000000001e-06     evaluation reward: 8.17\n",
      "episode: 2281   score: 10.0   memory length: 553468   epsilon: 0.1021313800084975    steps: 533    lr: 2.560000000000001e-06     evaluation reward: 8.21\n",
      "episode: 2282   score: 8.0   memory length: 553864   epsilon: 0.10134730000849804    steps: 396    lr: 2.560000000000001e-06     evaluation reward: 8.24\n",
      "episode: 2283   score: 16.0   memory length: 554460   epsilon: 0.10016722000849884    steps: 596    lr: 2.560000000000001e-06     evaluation reward: 8.29\n",
      "episode: 2284   score: 14.0   memory length: 554997   epsilon: 0.09910396000849957    steps: 537    lr: 2.560000000000001e-06     evaluation reward: 8.38\n",
      "episode: 2285   score: 12.0   memory length: 555453   epsilon: 0.09820108000850018    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 8.39\n",
      "episode: 2286   score: 5.0   memory length: 555758   epsilon: 0.0975971800085006    steps: 305    lr: 2.560000000000001e-06     evaluation reward: 8.37\n",
      "episode: 2287   score: 11.0   memory length: 556349   epsilon: 0.09642700000850139    steps: 591    lr: 2.560000000000001e-06     evaluation reward: 8.41\n",
      "episode: 2288   score: 9.0   memory length: 556800   epsilon: 0.095534020008502    steps: 451    lr: 2.560000000000001e-06     evaluation reward: 8.46\n",
      "episode: 2289   score: 10.0   memory length: 557304   epsilon: 0.09453610000850268    steps: 504    lr: 2.560000000000001e-06     evaluation reward: 8.5\n",
      "episode: 2290   score: 4.0   memory length: 557582   epsilon: 0.09398566000850306    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 8.5\n",
      "episode: 2291   score: 15.0   memory length: 558132   epsilon: 0.0928966600085038    steps: 550    lr: 2.560000000000001e-06     evaluation reward: 8.59\n",
      "episode: 2292   score: 2.0   memory length: 558330   epsilon: 0.09250462000850407    steps: 198    lr: 2.560000000000001e-06     evaluation reward: 8.56\n",
      "episode: 2293   score: 8.0   memory length: 558729   epsilon: 0.09171460000850461    steps: 399    lr: 2.560000000000001e-06     evaluation reward: 8.6\n",
      "episode: 2294   score: 8.0   memory length: 559149   epsilon: 0.09088300000850517    steps: 420    lr: 2.560000000000001e-06     evaluation reward: 8.57\n",
      "episode: 2295   score: 7.0   memory length: 559521   epsilon: 0.09014644000850568    steps: 372    lr: 2.560000000000001e-06     evaluation reward: 8.55\n",
      "episode: 2296   score: 9.0   memory length: 559961   epsilon: 0.08927524000850627    steps: 440    lr: 2.560000000000001e-06     evaluation reward: 8.52\n",
      "episode: 2297   score: 11.0   memory length: 560476   epsilon: 0.08825554000850697    steps: 515    lr: 2.560000000000001e-06     evaluation reward: 8.52\n",
      "episode: 2298   score: 10.0   memory length: 560959   epsilon: 0.08729920000850762    steps: 483    lr: 2.560000000000001e-06     evaluation reward: 8.56\n",
      "episode: 2299   score: 18.0   memory length: 561732   epsilon: 0.08576866000850866    steps: 773    lr: 2.560000000000001e-06     evaluation reward: 8.67\n",
      "episode: 2300   score: 7.0   memory length: 562106   epsilon: 0.08502814000850917    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 8.65\n",
      "episode: 2301   score: 14.0   memory length: 562667   epsilon: 0.08391736000850993    steps: 561    lr: 2.560000000000001e-06     evaluation reward: 8.74\n",
      "episode: 2302   score: 12.0   memory length: 563225   epsilon: 0.08281252000851068    steps: 558    lr: 2.560000000000001e-06     evaluation reward: 8.76\n",
      "episode: 2303   score: 10.0   memory length: 563672   epsilon: 0.08192746000851128    steps: 447    lr: 2.560000000000001e-06     evaluation reward: 8.79\n",
      "episode: 2304   score: 5.0   memory length: 564014   epsilon: 0.08125030000851174    steps: 342    lr: 2.560000000000001e-06     evaluation reward: 8.8\n",
      "episode: 2305   score: 5.0   memory length: 564326   epsilon: 0.08063254000851217    steps: 312    lr: 2.560000000000001e-06     evaluation reward: 8.75\n",
      "episode: 2306   score: 6.0   memory length: 564669   epsilon: 0.07995340000851263    steps: 343    lr: 2.560000000000001e-06     evaluation reward: 8.72\n",
      "episode: 2307   score: 13.0   memory length: 565114   epsilon: 0.07907230000851323    steps: 445    lr: 2.560000000000001e-06     evaluation reward: 8.78\n",
      "episode: 2308   score: 9.0   memory length: 565476   epsilon: 0.07835554000851372    steps: 362    lr: 2.560000000000001e-06     evaluation reward: 8.8\n",
      "episode: 2309   score: 13.0   memory length: 566071   epsilon: 0.07717744000851452    steps: 595    lr: 2.560000000000001e-06     evaluation reward: 8.8\n",
      "episode: 2310   score: 11.0   memory length: 566600   epsilon: 0.07613002000851524    steps: 529    lr: 2.560000000000001e-06     evaluation reward: 8.85\n",
      "episode: 2311   score: 18.0   memory length: 567204   epsilon: 0.07493410000851605    steps: 604    lr: 2.560000000000001e-06     evaluation reward: 8.93\n",
      "episode: 2312   score: 12.0   memory length: 567659   epsilon: 0.07403320000851667    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 9.0\n",
      "episode: 2313   score: 14.0   memory length: 568186   epsilon: 0.07298974000851738    steps: 527    lr: 2.560000000000001e-06     evaluation reward: 9.02\n",
      "episode: 2314   score: 10.0   memory length: 568688   epsilon: 0.07199578000851806    steps: 502    lr: 2.560000000000001e-06     evaluation reward: 9.04\n",
      "episode: 2315   score: 7.0   memory length: 569097   epsilon: 0.07118596000851861    steps: 409    lr: 2.560000000000001e-06     evaluation reward: 9.07\n",
      "episode: 2316   score: 8.0   memory length: 569554   epsilon: 0.07028110000851923    steps: 457    lr: 2.560000000000001e-06     evaluation reward: 9.07\n",
      "episode: 2317   score: 5.0   memory length: 569846   epsilon: 0.06970294000851962    steps: 292    lr: 2.560000000000001e-06     evaluation reward: 9.02\n",
      "episode: 2318   score: 4.0   memory length: 570119   epsilon: 0.06916240000851999    steps: 273    lr: 2.560000000000001e-06     evaluation reward: 9.01\n",
      "episode: 2319   score: 7.0   memory length: 570478   epsilon: 0.06845158000852047    steps: 359    lr: 2.560000000000001e-06     evaluation reward: 8.94\n",
      "episode: 2320   score: 5.0   memory length: 570786   epsilon: 0.06784174000852089    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 8.91\n",
      "episode: 2321   score: 8.0   memory length: 571221   epsilon: 0.06698044000852148    steps: 435    lr: 2.560000000000001e-06     evaluation reward: 8.94\n",
      "episode: 2322   score: 11.0   memory length: 571604   epsilon: 0.066222100008522    steps: 383    lr: 2.560000000000001e-06     evaluation reward: 8.94\n",
      "episode: 2323   score: 6.0   memory length: 571942   epsilon: 0.06555286000852245    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 8.92\n",
      "episode: 2324   score: 5.0   memory length: 572252   epsilon: 0.06493906000852287    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 8.92\n",
      "episode: 2325   score: 11.0   memory length: 572766   epsilon: 0.06392134000852356    steps: 514    lr: 2.560000000000001e-06     evaluation reward: 8.99\n",
      "episode: 2326   score: 12.0   memory length: 573232   epsilon: 0.0629986600085242    steps: 466    lr: 2.560000000000001e-06     evaluation reward: 8.97\n",
      "episode: 2327   score: 9.0   memory length: 573688   epsilon: 0.06209578000852481    steps: 456    lr: 2.560000000000001e-06     evaluation reward: 8.98\n",
      "episode: 2328   score: 9.0   memory length: 574162   epsilon: 0.06115726000852545    steps: 474    lr: 2.560000000000001e-06     evaluation reward: 9.0\n",
      "episode: 2329   score: 7.0   memory length: 574568   epsilon: 0.060353380008526    steps: 406    lr: 2.560000000000001e-06     evaluation reward: 8.92\n",
      "episode: 2330   score: 5.0   memory length: 574894   epsilon: 0.05970790000852644    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 8.88\n",
      "episode: 2331   score: 5.0   memory length: 575201   epsilon: 0.05910004000852685    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 8.9\n",
      "episode: 2332   score: 7.0   memory length: 575561   epsilon: 0.05838724000852734    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 8.91\n",
      "episode: 2333   score: 6.0   memory length: 575914   epsilon: 0.057688300008527815    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 8.91\n",
      "episode: 2334   score: 7.0   memory length: 576321   epsilon: 0.056882440008528365    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 8.94\n",
      "episode: 2335   score: 5.0   memory length: 576610   epsilon: 0.056310220008528755    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 8.94\n",
      "episode: 2336   score: 4.0   memory length: 576871   epsilon: 0.05579344000852911    steps: 261    lr: 2.560000000000001e-06     evaluation reward: 8.87\n",
      "episode: 2337   score: 11.0   memory length: 577408   epsilon: 0.05473018000852983    steps: 537    lr: 2.560000000000001e-06     evaluation reward: 8.88\n",
      "episode: 2338   score: 10.0   memory length: 577853   epsilon: 0.053849080008530434    steps: 445    lr: 2.560000000000001e-06     evaluation reward: 8.89\n",
      "episode: 2339   score: 11.0   memory length: 578275   epsilon: 0.053013520008531004    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 8.86\n",
      "episode: 2340   score: 9.0   memory length: 578727   epsilon: 0.052118560008531614    steps: 452    lr: 2.560000000000001e-06     evaluation reward: 8.89\n",
      "episode: 2341   score: 5.0   memory length: 579028   epsilon: 0.05152258000853202    steps: 301    lr: 2.560000000000001e-06     evaluation reward: 8.87\n",
      "episode: 2342   score: 11.0   memory length: 579552   epsilon: 0.05048506000853273    steps: 524    lr: 2.560000000000001e-06     evaluation reward: 8.83\n",
      "episode: 2343   score: 4.0   memory length: 579811   epsilon: 0.04997224000853308    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 8.82\n",
      "episode: 2344   score: 6.0   memory length: 580187   epsilon: 0.049227760008533586    steps: 376    lr: 2.560000000000001e-06     evaluation reward: 8.84\n",
      "episode: 2345   score: 9.0   memory length: 580642   epsilon: 0.0483268600085342    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 8.88\n",
      "episode: 2346   score: 6.0   memory length: 580965   epsilon: 0.04768732000853464    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 8.88\n",
      "episode: 2347   score: 9.0   memory length: 581410   epsilon: 0.04680622000853524    steps: 445    lr: 2.560000000000001e-06     evaluation reward: 8.83\n",
      "episode: 2348   score: 8.0   memory length: 581846   epsilon: 0.045942940008535826    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 8.82\n",
      "episode: 2349   score: 19.0   memory length: 582540   epsilon: 0.044568820008536764    steps: 694    lr: 2.560000000000001e-06     evaluation reward: 8.95\n",
      "episode: 2350   score: 6.0   memory length: 582879   epsilon: 0.04389760000853722    steps: 339    lr: 2.560000000000001e-06     evaluation reward: 8.96\n",
      "episode: 2351   score: 8.0   memory length: 583311   epsilon: 0.043042240008537805    steps: 432    lr: 2.560000000000001e-06     evaluation reward: 8.9\n",
      "episode: 2352   score: 9.0   memory length: 583802   epsilon: 0.04207006000853847    steps: 491    lr: 2.560000000000001e-06     evaluation reward: 8.91\n",
      "episode: 2353   score: 8.0   memory length: 584204   epsilon: 0.04127410000853901    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 8.94\n",
      "episode: 2354   score: 10.0   memory length: 584579   epsilon: 0.04053160000853952    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 8.95\n",
      "episode: 2355   score: 15.0   memory length: 585135   epsilon: 0.03943072000854027    steps: 556    lr: 2.560000000000001e-06     evaluation reward: 9.05\n",
      "episode: 2356   score: 8.0   memory length: 585593   epsilon: 0.03852388000854089    steps: 458    lr: 2.560000000000001e-06     evaluation reward: 9.06\n",
      "episode: 2357   score: 11.0   memory length: 586140   epsilon: 0.037440820008541625    steps: 547    lr: 2.560000000000001e-06     evaluation reward: 9.08\n",
      "episode: 2358   score: 7.0   memory length: 586526   epsilon: 0.03667654000854215    steps: 386    lr: 2.560000000000001e-06     evaluation reward: 9.08\n",
      "episode: 2359   score: 4.0   memory length: 586770   epsilon: 0.036193420008542476    steps: 244    lr: 2.560000000000001e-06     evaluation reward: 8.88\n",
      "episode: 2360   score: 9.0   memory length: 587221   epsilon: 0.035300440008543085    steps: 451    lr: 2.560000000000001e-06     evaluation reward: 8.89\n",
      "episode: 2361   score: 4.0   memory length: 587482   epsilon: 0.03478366000854344    steps: 261    lr: 2.560000000000001e-06     evaluation reward: 8.66\n",
      "episode: 2362   score: 7.0   memory length: 587872   epsilon: 0.034011460008543964    steps: 390    lr: 2.560000000000001e-06     evaluation reward: 8.63\n",
      "episode: 2363   score: 11.0   memory length: 588423   epsilon: 0.03292048000854471    steps: 551    lr: 2.560000000000001e-06     evaluation reward: 8.65\n",
      "episode: 2364   score: 8.0   memory length: 588827   epsilon: 0.032120560008545254    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 8.68\n",
      "episode: 2365   score: 5.0   memory length: 589132   epsilon: 0.031516660008545666    steps: 305    lr: 2.560000000000001e-06     evaluation reward: 8.68\n",
      "episode: 2366   score: 7.0   memory length: 589557   epsilon: 0.03067516000854624    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 8.73\n",
      "episode: 2367   score: 6.0   memory length: 589894   epsilon: 0.030007900008546695    steps: 337    lr: 2.560000000000001e-06     evaluation reward: 8.67\n",
      "episode: 2368   score: 7.0   memory length: 590239   epsilon: 0.02932480000854716    steps: 345    lr: 2.560000000000001e-06     evaluation reward: 8.7\n",
      "episode: 2369   score: 3.0   memory length: 590452   epsilon: 0.02890306000854745    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 8.64\n",
      "episode: 2370   score: 10.0   memory length: 590973   epsilon: 0.027871480008548152    steps: 521    lr: 2.560000000000001e-06     evaluation reward: 8.67\n",
      "episode: 2371   score: 12.0   memory length: 591482   epsilon: 0.02686366000854884    steps: 509    lr: 2.560000000000001e-06     evaluation reward: 8.73\n",
      "episode: 2372   score: 4.0   memory length: 591777   epsilon: 0.026279560008549238    steps: 295    lr: 2.560000000000001e-06     evaluation reward: 8.62\n",
      "episode: 2373   score: 7.0   memory length: 592166   epsilon: 0.025509340008549763    steps: 389    lr: 2.560000000000001e-06     evaluation reward: 8.62\n",
      "episode: 2374   score: 4.0   memory length: 592425   epsilon: 0.024996520008550113    steps: 259    lr: 2.560000000000001e-06     evaluation reward: 8.59\n",
      "episode: 2375   score: 10.0   memory length: 592904   epsilon: 0.02404810000855076    steps: 479    lr: 2.560000000000001e-06     evaluation reward: 8.6\n",
      "episode: 2376   score: 8.0   memory length: 593313   epsilon: 0.023238280008551312    steps: 409    lr: 2.560000000000001e-06     evaluation reward: 8.6\n",
      "episode: 2377   score: 10.0   memory length: 593822   epsilon: 0.022230460008552    steps: 509    lr: 2.560000000000001e-06     evaluation reward: 8.53\n",
      "episode: 2378   score: 13.0   memory length: 594314   epsilon: 0.021256300008552664    steps: 492    lr: 2.560000000000001e-06     evaluation reward: 8.63\n",
      "episode: 2379   score: 8.0   memory length: 594753   epsilon: 0.020387080008553257    steps: 439    lr: 2.560000000000001e-06     evaluation reward: 8.61\n",
      "episode: 2380   score: 4.0   memory length: 595045   epsilon: 0.01980892000855365    steps: 292    lr: 2.560000000000001e-06     evaluation reward: 8.6\n",
      "episode: 2381   score: 6.0   memory length: 595403   epsilon: 0.019100080008554135    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 8.56\n",
      "episode: 2382   score: 4.0   memory length: 595697   epsilon: 0.018517960008554532    steps: 294    lr: 2.560000000000001e-06     evaluation reward: 8.52\n",
      "episode: 2383   score: 6.0   memory length: 596095   epsilon: 0.01772992000855507    steps: 398    lr: 2.560000000000001e-06     evaluation reward: 8.42\n",
      "episode: 2384   score: 4.0   memory length: 596393   epsilon: 0.017139880008555472    steps: 298    lr: 2.560000000000001e-06     evaluation reward: 8.32\n",
      "episode: 2385   score: 8.0   memory length: 596845   epsilon: 0.016244920008556082    steps: 452    lr: 2.560000000000001e-06     evaluation reward: 8.28\n",
      "episode: 2386   score: 6.0   memory length: 597193   epsilon: 0.015555880008556492    steps: 348    lr: 2.560000000000001e-06     evaluation reward: 8.29\n",
      "episode: 2387   score: 8.0   memory length: 597603   epsilon: 0.014744080008556334    steps: 410    lr: 2.560000000000001e-06     evaluation reward: 8.26\n",
      "episode: 2388   score: 12.0   memory length: 598231   epsilon: 0.013500640008556093    steps: 628    lr: 2.560000000000001e-06     evaluation reward: 8.29\n",
      "episode: 2389   score: 11.0   memory length: 598735   epsilon: 0.0125027200085559    steps: 504    lr: 2.560000000000001e-06     evaluation reward: 8.3\n",
      "episode: 2390   score: 5.0   memory length: 599060   epsilon: 0.011859220008555774    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 8.31\n",
      "episode: 2391   score: 6.0   memory length: 599415   epsilon: 0.011156320008555638    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 8.22\n",
      "episode: 2392   score: 9.0   memory length: 599889   epsilon: 0.010217800008555456    steps: 474    lr: 2.560000000000001e-06     evaluation reward: 8.29\n",
      "episode: 2393   score: 31.0   memory length: 600585   epsilon: 0.009998020008555413    steps: 696    lr: 1.0240000000000005e-06     evaluation reward: 8.52\n",
      "episode: 2394   score: 6.0   memory length: 600904   epsilon: 0.009998020008555413    steps: 319    lr: 1.0240000000000005e-06     evaluation reward: 8.5\n",
      "episode: 2395   score: 11.0   memory length: 601423   epsilon: 0.009998020008555413    steps: 519    lr: 1.0240000000000005e-06     evaluation reward: 8.54\n",
      "episode: 2396   score: 9.0   memory length: 601877   epsilon: 0.009998020008555413    steps: 454    lr: 1.0240000000000005e-06     evaluation reward: 8.54\n",
      "episode: 2397   score: 9.0   memory length: 602236   epsilon: 0.009998020008555413    steps: 359    lr: 1.0240000000000005e-06     evaluation reward: 8.52\n",
      "episode: 2398   score: 7.0   memory length: 602641   epsilon: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     evaluation reward: 8.49\n",
      "episode: 2399   score: 12.0   memory length: 603149   epsilon: 0.009998020008555413    steps: 508    lr: 1.0240000000000005e-06     evaluation reward: 8.43\n",
      "episode: 2400   score: 10.0   memory length: 603595   epsilon: 0.009998020008555413    steps: 446    lr: 1.0240000000000005e-06     evaluation reward: 8.46\n",
      "episode: 2401   score: 7.0   memory length: 603967   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 8.39\n",
      "episode: 2402   score: 6.0   memory length: 604323   epsilon: 0.009998020008555413    steps: 356    lr: 1.0240000000000005e-06     evaluation reward: 8.33\n",
      "episode: 2403   score: 9.0   memory length: 604765   epsilon: 0.009998020008555413    steps: 442    lr: 1.0240000000000005e-06     evaluation reward: 8.32\n",
      "episode: 2404   score: 7.0   memory length: 605173   epsilon: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     evaluation reward: 8.34\n",
      "episode: 2405   score: 15.0   memory length: 605719   epsilon: 0.009998020008555413    steps: 546    lr: 1.0240000000000005e-06     evaluation reward: 8.44\n",
      "episode: 2406   score: 11.0   memory length: 606157   epsilon: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     evaluation reward: 8.49\n",
      "episode: 2407   score: 6.0   memory length: 606498   epsilon: 0.009998020008555413    steps: 341    lr: 1.0240000000000005e-06     evaluation reward: 8.42\n",
      "episode: 2408   score: 8.0   memory length: 606921   epsilon: 0.009998020008555413    steps: 423    lr: 1.0240000000000005e-06     evaluation reward: 8.41\n",
      "episode: 2409   score: 8.0   memory length: 607377   epsilon: 0.009998020008555413    steps: 456    lr: 1.0240000000000005e-06     evaluation reward: 8.36\n",
      "episode: 2410   score: 4.0   memory length: 607636   epsilon: 0.009998020008555413    steps: 259    lr: 1.0240000000000005e-06     evaluation reward: 8.29\n",
      "episode: 2411   score: 12.0   memory length: 608054   epsilon: 0.009998020008555413    steps: 418    lr: 1.0240000000000005e-06     evaluation reward: 8.23\n",
      "episode: 2412   score: 13.0   memory length: 608659   epsilon: 0.009998020008555413    steps: 605    lr: 1.0240000000000005e-06     evaluation reward: 8.24\n",
      "episode: 2413   score: 12.0   memory length: 609272   epsilon: 0.009998020008555413    steps: 613    lr: 1.0240000000000005e-06     evaluation reward: 8.22\n",
      "episode: 2414   score: 9.0   memory length: 609762   epsilon: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     evaluation reward: 8.21\n",
      "episode: 2415   score: 6.0   memory length: 610099   epsilon: 0.009998020008555413    steps: 337    lr: 1.0240000000000005e-06     evaluation reward: 8.2\n",
      "episode: 2416   score: 6.0   memory length: 610454   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 8.18\n",
      "episode: 2417   score: 10.0   memory length: 610960   epsilon: 0.009998020008555413    steps: 506    lr: 1.0240000000000005e-06     evaluation reward: 8.23\n",
      "episode: 2418   score: 7.0   memory length: 611346   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 8.26\n",
      "episode: 2419   score: 10.0   memory length: 611884   epsilon: 0.009998020008555413    steps: 538    lr: 1.0240000000000005e-06     evaluation reward: 8.29\n",
      "episode: 2420   score: 6.0   memory length: 612208   epsilon: 0.009998020008555413    steps: 324    lr: 1.0240000000000005e-06     evaluation reward: 8.3\n",
      "episode: 2421   score: 4.0   memory length: 612467   epsilon: 0.009998020008555413    steps: 259    lr: 1.0240000000000005e-06     evaluation reward: 8.26\n",
      "episode: 2422   score: 18.0   memory length: 613157   epsilon: 0.009998020008555413    steps: 690    lr: 1.0240000000000005e-06     evaluation reward: 8.33\n",
      "episode: 2423   score: 6.0   memory length: 613491   epsilon: 0.009998020008555413    steps: 334    lr: 1.0240000000000005e-06     evaluation reward: 8.33\n",
      "episode: 2424   score: 8.0   memory length: 613900   epsilon: 0.009998020008555413    steps: 409    lr: 1.0240000000000005e-06     evaluation reward: 8.36\n",
      "episode: 2425   score: 26.0   memory length: 614466   epsilon: 0.009998020008555413    steps: 566    lr: 1.0240000000000005e-06     evaluation reward: 8.51\n",
      "episode: 2426   score: 10.0   memory length: 614951   epsilon: 0.009998020008555413    steps: 485    lr: 1.0240000000000005e-06     evaluation reward: 8.49\n",
      "episode: 2427   score: 9.0   memory length: 615418   epsilon: 0.009998020008555413    steps: 467    lr: 1.0240000000000005e-06     evaluation reward: 8.49\n",
      "episode: 2428   score: 14.0   memory length: 615968   epsilon: 0.009998020008555413    steps: 550    lr: 1.0240000000000005e-06     evaluation reward: 8.54\n",
      "episode: 2429   score: 9.0   memory length: 616466   epsilon: 0.009998020008555413    steps: 498    lr: 1.0240000000000005e-06     evaluation reward: 8.56\n",
      "episode: 2430   score: 7.0   memory length: 616841   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 8.58\n",
      "episode: 2431   score: 10.0   memory length: 617232   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 8.63\n",
      "episode: 2432   score: 9.0   memory length: 617721   epsilon: 0.009998020008555413    steps: 489    lr: 1.0240000000000005e-06     evaluation reward: 8.65\n",
      "episode: 2433   score: 2.0   memory length: 617919   epsilon: 0.009998020008555413    steps: 198    lr: 1.0240000000000005e-06     evaluation reward: 8.61\n",
      "episode: 2434   score: 6.0   memory length: 618275   epsilon: 0.009998020008555413    steps: 356    lr: 1.0240000000000005e-06     evaluation reward: 8.6\n",
      "episode: 2435   score: 12.0   memory length: 618723   epsilon: 0.009998020008555413    steps: 448    lr: 1.0240000000000005e-06     evaluation reward: 8.67\n",
      "episode: 2436   score: 18.0   memory length: 619370   epsilon: 0.009998020008555413    steps: 647    lr: 1.0240000000000005e-06     evaluation reward: 8.81\n",
      "episode: 2437   score: 10.0   memory length: 619858   epsilon: 0.009998020008555413    steps: 488    lr: 1.0240000000000005e-06     evaluation reward: 8.8\n",
      "episode: 2438   score: 8.0   memory length: 620298   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 8.78\n",
      "episode: 2439   score: 12.0   memory length: 620820   epsilon: 0.009998020008555413    steps: 522    lr: 1.0240000000000005e-06     evaluation reward: 8.79\n",
      "episode: 2440   score: 6.0   memory length: 621193   epsilon: 0.009998020008555413    steps: 373    lr: 1.0240000000000005e-06     evaluation reward: 8.76\n",
      "episode: 2441   score: 9.0   memory length: 621719   epsilon: 0.009998020008555413    steps: 526    lr: 1.0240000000000005e-06     evaluation reward: 8.8\n",
      "episode: 2442   score: 8.0   memory length: 622164   epsilon: 0.009998020008555413    steps: 445    lr: 1.0240000000000005e-06     evaluation reward: 8.77\n",
      "episode: 2443   score: 11.0   memory length: 622552   epsilon: 0.009998020008555413    steps: 388    lr: 1.0240000000000005e-06     evaluation reward: 8.84\n",
      "episode: 2444   score: 7.0   memory length: 622935   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 8.85\n",
      "episode: 2445   score: 11.0   memory length: 623442   epsilon: 0.009998020008555413    steps: 507    lr: 1.0240000000000005e-06     evaluation reward: 8.87\n",
      "episode: 2446   score: 5.0   memory length: 623749   epsilon: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     evaluation reward: 8.86\n",
      "episode: 2447   score: 8.0   memory length: 624140   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 8.85\n",
      "episode: 2448   score: 7.0   memory length: 624514   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 8.84\n",
      "episode: 2449   score: 7.0   memory length: 624922   epsilon: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     evaluation reward: 8.72\n",
      "episode: 2450   score: 9.0   memory length: 625374   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 8.75\n",
      "episode: 2451   score: 12.0   memory length: 625847   epsilon: 0.009998020008555413    steps: 473    lr: 1.0240000000000005e-06     evaluation reward: 8.79\n",
      "episode: 2452   score: 16.0   memory length: 626409   epsilon: 0.009998020008555413    steps: 562    lr: 1.0240000000000005e-06     evaluation reward: 8.86\n",
      "episode: 2453   score: 9.0   memory length: 626861   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 8.87\n",
      "episode: 2454   score: 9.0   memory length: 627328   epsilon: 0.009998020008555413    steps: 467    lr: 1.0240000000000005e-06     evaluation reward: 8.86\n",
      "episode: 2455   score: 9.0   memory length: 627782   epsilon: 0.009998020008555413    steps: 454    lr: 1.0240000000000005e-06     evaluation reward: 8.8\n",
      "episode: 2456   score: 9.0   memory length: 628223   epsilon: 0.009998020008555413    steps: 441    lr: 1.0240000000000005e-06     evaluation reward: 8.81\n",
      "episode: 2457   score: 9.0   memory length: 628679   epsilon: 0.009998020008555413    steps: 456    lr: 1.0240000000000005e-06     evaluation reward: 8.79\n",
      "episode: 2458   score: 8.0   memory length: 629064   epsilon: 0.009998020008555413    steps: 385    lr: 1.0240000000000005e-06     evaluation reward: 8.8\n",
      "episode: 2459   score: 6.0   memory length: 629418   epsilon: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     evaluation reward: 8.82\n",
      "episode: 2460   score: 12.0   memory length: 629847   epsilon: 0.009998020008555413    steps: 429    lr: 1.0240000000000005e-06     evaluation reward: 8.85\n",
      "episode: 2461   score: 9.0   memory length: 630338   epsilon: 0.009998020008555413    steps: 491    lr: 1.0240000000000005e-06     evaluation reward: 8.9\n",
      "episode: 2462   score: 5.0   memory length: 630628   epsilon: 0.009998020008555413    steps: 290    lr: 1.0240000000000005e-06     evaluation reward: 8.88\n",
      "episode: 2463   score: 9.0   memory length: 631083   epsilon: 0.009998020008555413    steps: 455    lr: 1.0240000000000005e-06     evaluation reward: 8.86\n",
      "episode: 2464   score: 12.0   memory length: 631582   epsilon: 0.009998020008555413    steps: 499    lr: 1.0240000000000005e-06     evaluation reward: 8.9\n",
      "episode: 2465   score: 4.0   memory length: 631823   epsilon: 0.009998020008555413    steps: 241    lr: 1.0240000000000005e-06     evaluation reward: 8.89\n",
      "episode: 2466   score: 8.0   memory length: 632233   epsilon: 0.009998020008555413    steps: 410    lr: 1.0240000000000005e-06     evaluation reward: 8.9\n",
      "episode: 2467   score: 8.0   memory length: 632656   epsilon: 0.009998020008555413    steps: 423    lr: 1.0240000000000005e-06     evaluation reward: 8.92\n",
      "episode: 2468   score: 14.0   memory length: 633271   epsilon: 0.009998020008555413    steps: 615    lr: 1.0240000000000005e-06     evaluation reward: 8.99\n",
      "episode: 2469   score: 12.0   memory length: 633853   epsilon: 0.009998020008555413    steps: 582    lr: 1.0240000000000005e-06     evaluation reward: 9.08\n",
      "episode: 2470   score: 3.0   memory length: 634080   epsilon: 0.009998020008555413    steps: 227    lr: 1.0240000000000005e-06     evaluation reward: 9.01\n",
      "episode: 2471   score: 7.0   memory length: 634471   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 8.96\n",
      "episode: 2472   score: 11.0   memory length: 635017   epsilon: 0.009998020008555413    steps: 546    lr: 1.0240000000000005e-06     evaluation reward: 9.03\n",
      "episode: 2473   score: 10.0   memory length: 635456   epsilon: 0.009998020008555413    steps: 439    lr: 1.0240000000000005e-06     evaluation reward: 9.06\n",
      "episode: 2474   score: 8.0   memory length: 635842   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 9.1\n",
      "episode: 2475   score: 14.0   memory length: 636490   epsilon: 0.009998020008555413    steps: 648    lr: 1.0240000000000005e-06     evaluation reward: 9.14\n",
      "episode: 2476   score: 17.0   memory length: 637008   epsilon: 0.009998020008555413    steps: 518    lr: 1.0240000000000005e-06     evaluation reward: 9.23\n",
      "episode: 2477   score: 12.0   memory length: 637556   epsilon: 0.009998020008555413    steps: 548    lr: 1.0240000000000005e-06     evaluation reward: 9.25\n",
      "episode: 2478   score: 10.0   memory length: 638043   epsilon: 0.009998020008555413    steps: 487    lr: 1.0240000000000005e-06     evaluation reward: 9.22\n",
      "episode: 2479   score: 8.0   memory length: 638501   epsilon: 0.009998020008555413    steps: 458    lr: 1.0240000000000005e-06     evaluation reward: 9.22\n",
      "episode: 2480   score: 7.0   memory length: 638873   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 9.25\n",
      "episode: 2481   score: 8.0   memory length: 639300   epsilon: 0.009998020008555413    steps: 427    lr: 1.0240000000000005e-06     evaluation reward: 9.27\n",
      "episode: 2482   score: 9.0   memory length: 639752   epsilon: 0.009998020008555413    steps: 452    lr: 1.0240000000000005e-06     evaluation reward: 9.32\n",
      "episode: 2483   score: 12.0   memory length: 640295   epsilon: 0.009998020008555413    steps: 543    lr: 1.0240000000000005e-06     evaluation reward: 9.38\n",
      "episode: 2484   score: 6.0   memory length: 640635   epsilon: 0.009998020008555413    steps: 340    lr: 1.0240000000000005e-06     evaluation reward: 9.4\n",
      "episode: 2485   score: 7.0   memory length: 641039   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 9.39\n",
      "episode: 2486   score: 5.0   memory length: 641364   epsilon: 0.009998020008555413    steps: 325    lr: 1.0240000000000005e-06     evaluation reward: 9.38\n",
      "episode: 2487   score: 6.0   memory length: 641692   epsilon: 0.009998020008555413    steps: 328    lr: 1.0240000000000005e-06     evaluation reward: 9.36\n",
      "episode: 2488   score: 7.0   memory length: 642048   epsilon: 0.009998020008555413    steps: 356    lr: 1.0240000000000005e-06     evaluation reward: 9.31\n",
      "episode: 2489   score: 4.0   memory length: 642325   epsilon: 0.009998020008555413    steps: 277    lr: 1.0240000000000005e-06     evaluation reward: 9.24\n",
      "episode: 2490   score: 7.0   memory length: 642696   epsilon: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     evaluation reward: 9.26\n",
      "episode: 2491   score: 7.0   memory length: 643069   epsilon: 0.009998020008555413    steps: 373    lr: 1.0240000000000005e-06     evaluation reward: 9.27\n",
      "episode: 2492   score: 8.0   memory length: 643507   epsilon: 0.009998020008555413    steps: 438    lr: 1.0240000000000005e-06     evaluation reward: 9.26\n",
      "episode: 2493   score: 5.0   memory length: 643801   epsilon: 0.009998020008555413    steps: 294    lr: 1.0240000000000005e-06     evaluation reward: 9.0\n",
      "episode: 2494   score: 12.0   memory length: 644347   epsilon: 0.009998020008555413    steps: 546    lr: 1.0240000000000005e-06     evaluation reward: 9.06\n",
      "episode: 2495   score: 11.0   memory length: 644879   epsilon: 0.009998020008555413    steps: 532    lr: 1.0240000000000005e-06     evaluation reward: 9.06\n",
      "episode: 2496   score: 6.0   memory length: 645214   epsilon: 0.009998020008555413    steps: 335    lr: 1.0240000000000005e-06     evaluation reward: 9.03\n",
      "episode: 2497   score: 7.0   memory length: 645601   epsilon: 0.009998020008555413    steps: 387    lr: 1.0240000000000005e-06     evaluation reward: 9.01\n",
      "episode: 2498   score: 12.0   memory length: 646083   epsilon: 0.009998020008555413    steps: 482    lr: 1.0240000000000005e-06     evaluation reward: 9.06\n",
      "episode: 2499   score: 10.0   memory length: 646458   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 9.04\n",
      "episode: 2500   score: 17.0   memory length: 646835   epsilon: 0.009998020008555413    steps: 377    lr: 1.0240000000000005e-06     evaluation reward: 9.11\n",
      "episode: 2501   score: 8.0   memory length: 647240   epsilon: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     evaluation reward: 9.12\n",
      "episode: 2502   score: 4.0   memory length: 647516   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 9.1\n",
      "episode: 2503   score: 10.0   memory length: 648024   epsilon: 0.009998020008555413    steps: 508    lr: 1.0240000000000005e-06     evaluation reward: 9.11\n",
      "episode: 2504   score: 7.0   memory length: 648410   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 9.11\n",
      "episode: 2505   score: 7.0   memory length: 648785   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 9.03\n",
      "episode: 2506   score: 9.0   memory length: 649239   epsilon: 0.009998020008555413    steps: 454    lr: 1.0240000000000005e-06     evaluation reward: 9.01\n",
      "episode: 2507   score: 12.0   memory length: 649811   epsilon: 0.009998020008555413    steps: 572    lr: 1.0240000000000005e-06     evaluation reward: 9.07\n",
      "episode: 2508   score: 10.0   memory length: 650323   epsilon: 0.009998020008555413    steps: 512    lr: 1.0240000000000005e-06     evaluation reward: 9.09\n",
      "episode: 2509   score: 10.0   memory length: 650794   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 9.11\n",
      "episode: 2510   score: 10.0   memory length: 651278   epsilon: 0.009998020008555413    steps: 484    lr: 1.0240000000000005e-06     evaluation reward: 9.17\n",
      "episode: 2511   score: 18.0   memory length: 651981   epsilon: 0.009998020008555413    steps: 703    lr: 1.0240000000000005e-06     evaluation reward: 9.23\n",
      "episode: 2512   score: 15.0   memory length: 652601   epsilon: 0.009998020008555413    steps: 620    lr: 1.0240000000000005e-06     evaluation reward: 9.25\n",
      "episode: 2513   score: 15.0   memory length: 653174   epsilon: 0.009998020008555413    steps: 573    lr: 1.0240000000000005e-06     evaluation reward: 9.28\n",
      "episode: 2514   score: 8.0   memory length: 653621   epsilon: 0.009998020008555413    steps: 447    lr: 1.0240000000000005e-06     evaluation reward: 9.27\n",
      "episode: 2515   score: 7.0   memory length: 654005   epsilon: 0.009998020008555413    steps: 384    lr: 1.0240000000000005e-06     evaluation reward: 9.28\n",
      "episode: 2516   score: 7.0   memory length: 654382   epsilon: 0.009998020008555413    steps: 377    lr: 1.0240000000000005e-06     evaluation reward: 9.29\n",
      "episode: 2517   score: 4.0   memory length: 654642   epsilon: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     evaluation reward: 9.23\n",
      "episode: 2518   score: 4.0   memory length: 654958   epsilon: 0.009998020008555413    steps: 316    lr: 1.0240000000000005e-06     evaluation reward: 9.2\n",
      "episode: 2519   score: 9.0   memory length: 655433   epsilon: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     evaluation reward: 9.19\n",
      "episode: 2520   score: 9.0   memory length: 655914   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 9.22\n",
      "episode: 2521   score: 6.0   memory length: 656262   epsilon: 0.009998020008555413    steps: 348    lr: 1.0240000000000005e-06     evaluation reward: 9.24\n",
      "episode: 2522   score: 5.0   memory length: 656559   epsilon: 0.009998020008555413    steps: 297    lr: 1.0240000000000005e-06     evaluation reward: 9.11\n",
      "episode: 2523   score: 7.0   memory length: 656950   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 9.12\n",
      "episode: 2524   score: 6.0   memory length: 657306   epsilon: 0.009998020008555413    steps: 356    lr: 1.0240000000000005e-06     evaluation reward: 9.1\n",
      "episode: 2525   score: 6.0   memory length: 657640   epsilon: 0.009998020008555413    steps: 334    lr: 1.0240000000000005e-06     evaluation reward: 8.9\n",
      "episode: 2526   score: 8.0   memory length: 658033   epsilon: 0.009998020008555413    steps: 393    lr: 1.0240000000000005e-06     evaluation reward: 8.88\n",
      "episode: 2527   score: 10.0   memory length: 658520   epsilon: 0.009998020008555413    steps: 487    lr: 1.0240000000000005e-06     evaluation reward: 8.89\n",
      "episode: 2528   score: 15.0   memory length: 659054   epsilon: 0.009998020008555413    steps: 534    lr: 1.0240000000000005e-06     evaluation reward: 8.9\n",
      "episode: 2529   score: 5.0   memory length: 659380   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 8.86\n",
      "episode: 2530   score: 6.0   memory length: 659691   epsilon: 0.009998020008555413    steps: 311    lr: 1.0240000000000005e-06     evaluation reward: 8.85\n",
      "episode: 2531   score: 5.0   memory length: 660020   epsilon: 0.009998020008555413    steps: 329    lr: 1.0240000000000005e-06     evaluation reward: 8.8\n",
      "episode: 2532   score: 9.0   memory length: 660484   epsilon: 0.009998020008555413    steps: 464    lr: 1.0240000000000005e-06     evaluation reward: 8.8\n",
      "episode: 2533   score: 7.0   memory length: 660844   epsilon: 0.009998020008555413    steps: 360    lr: 1.0240000000000005e-06     evaluation reward: 8.85\n",
      "episode: 2534   score: 12.0   memory length: 661338   epsilon: 0.009998020008555413    steps: 494    lr: 1.0240000000000005e-06     evaluation reward: 8.91\n",
      "episode: 2535   score: 12.0   memory length: 661891   epsilon: 0.009998020008555413    steps: 553    lr: 1.0240000000000005e-06     evaluation reward: 8.91\n",
      "episode: 2536   score: 18.0   memory length: 662579   epsilon: 0.009998020008555413    steps: 688    lr: 1.0240000000000005e-06     evaluation reward: 8.91\n",
      "episode: 2537   score: 6.0   memory length: 662952   epsilon: 0.009998020008555413    steps: 373    lr: 1.0240000000000005e-06     evaluation reward: 8.87\n",
      "episode: 2538   score: 9.0   memory length: 663413   epsilon: 0.009998020008555413    steps: 461    lr: 1.0240000000000005e-06     evaluation reward: 8.88\n",
      "episode: 2539   score: 4.0   memory length: 663675   epsilon: 0.009998020008555413    steps: 262    lr: 1.0240000000000005e-06     evaluation reward: 8.8\n",
      "episode: 2540   score: 10.0   memory length: 664150   epsilon: 0.009998020008555413    steps: 475    lr: 1.0240000000000005e-06     evaluation reward: 8.84\n",
      "episode: 2541   score: 5.0   memory length: 664472   epsilon: 0.009998020008555413    steps: 322    lr: 1.0240000000000005e-06     evaluation reward: 8.8\n",
      "episode: 2542   score: 8.0   memory length: 664894   epsilon: 0.009998020008555413    steps: 422    lr: 1.0240000000000005e-06     evaluation reward: 8.8\n",
      "episode: 2543   score: 12.0   memory length: 665355   epsilon: 0.009998020008555413    steps: 461    lr: 1.0240000000000005e-06     evaluation reward: 8.81\n",
      "episode: 2544   score: 4.0   memory length: 665615   epsilon: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     evaluation reward: 8.78\n",
      "episode: 2545   score: 10.0   memory length: 666098   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 8.77\n",
      "episode: 2546   score: 7.0   memory length: 666500   epsilon: 0.009998020008555413    steps: 402    lr: 1.0240000000000005e-06     evaluation reward: 8.79\n",
      "episode: 2547   score: 8.0   memory length: 666926   epsilon: 0.009998020008555413    steps: 426    lr: 1.0240000000000005e-06     evaluation reward: 8.79\n",
      "episode: 2548   score: 9.0   memory length: 667393   epsilon: 0.009998020008555413    steps: 467    lr: 1.0240000000000005e-06     evaluation reward: 8.81\n",
      "episode: 2549   score: 7.0   memory length: 667779   epsilon: 0.009998020008555413    steps: 386    lr: 1.0240000000000005e-06     evaluation reward: 8.81\n",
      "episode: 2550   score: 18.0   memory length: 668407   epsilon: 0.009998020008555413    steps: 628    lr: 1.0240000000000005e-06     evaluation reward: 8.9\n",
      "episode: 2551   score: 9.0   memory length: 668885   epsilon: 0.009998020008555413    steps: 478    lr: 1.0240000000000005e-06     evaluation reward: 8.87\n",
      "episode: 2552   score: 8.0   memory length: 669311   epsilon: 0.009998020008555413    steps: 426    lr: 1.0240000000000005e-06     evaluation reward: 8.79\n",
      "episode: 2553   score: 6.0   memory length: 669669   epsilon: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     evaluation reward: 8.76\n",
      "episode: 2554   score: 6.0   memory length: 670005   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 8.73\n",
      "episode: 2555   score: 9.0   memory length: 670450   epsilon: 0.009998020008555413    steps: 445    lr: 1.0240000000000005e-06     evaluation reward: 8.73\n",
      "episode: 2556   score: 13.0   memory length: 670976   epsilon: 0.009998020008555413    steps: 526    lr: 1.0240000000000005e-06     evaluation reward: 8.77\n",
      "episode: 2557   score: 8.0   memory length: 671394   epsilon: 0.009998020008555413    steps: 418    lr: 1.0240000000000005e-06     evaluation reward: 8.76\n",
      "episode: 2558   score: 8.0   memory length: 671805   epsilon: 0.009998020008555413    steps: 411    lr: 1.0240000000000005e-06     evaluation reward: 8.76\n",
      "episode: 2559   score: 9.0   memory length: 672293   epsilon: 0.009998020008555413    steps: 488    lr: 1.0240000000000005e-06     evaluation reward: 8.79\n",
      "episode: 2560   score: 4.0   memory length: 672574   epsilon: 0.009998020008555413    steps: 281    lr: 1.0240000000000005e-06     evaluation reward: 8.71\n",
      "episode: 2561   score: 6.0   memory length: 672948   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 8.68\n",
      "episode: 2562   score: 4.0   memory length: 673243   epsilon: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     evaluation reward: 8.67\n",
      "episode: 2563   score: 5.0   memory length: 673570   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 8.63\n",
      "episode: 2564   score: 10.0   memory length: 674122   epsilon: 0.009998020008555413    steps: 552    lr: 1.0240000000000005e-06     evaluation reward: 8.61\n",
      "episode: 2565   score: 6.0   memory length: 674455   epsilon: 0.009998020008555413    steps: 333    lr: 1.0240000000000005e-06     evaluation reward: 8.63\n",
      "episode: 2566   score: 9.0   memory length: 674904   epsilon: 0.009998020008555413    steps: 449    lr: 1.0240000000000005e-06     evaluation reward: 8.64\n",
      "episode: 2567   score: 6.0   memory length: 675262   epsilon: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     evaluation reward: 8.62\n",
      "episode: 2568   score: 5.0   memory length: 675570   epsilon: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     evaluation reward: 8.53\n",
      "episode: 2569   score: 6.0   memory length: 675965   epsilon: 0.009998020008555413    steps: 395    lr: 1.0240000000000005e-06     evaluation reward: 8.47\n",
      "episode: 2570   score: 11.0   memory length: 676517   epsilon: 0.009998020008555413    steps: 552    lr: 1.0240000000000005e-06     evaluation reward: 8.55\n",
      "episode: 2571   score: 8.0   memory length: 676942   epsilon: 0.009998020008555413    steps: 425    lr: 1.0240000000000005e-06     evaluation reward: 8.56\n",
      "episode: 2572   score: 5.0   memory length: 677249   epsilon: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     evaluation reward: 8.5\n",
      "episode: 2573   score: 8.0   memory length: 677640   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 8.48\n",
      "episode: 2574   score: 7.0   memory length: 678047   epsilon: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     evaluation reward: 8.47\n",
      "episode: 2575   score: 9.0   memory length: 678533   epsilon: 0.009998020008555413    steps: 486    lr: 1.0240000000000005e-06     evaluation reward: 8.42\n",
      "episode: 2576   score: 11.0   memory length: 679069   epsilon: 0.009998020008555413    steps: 536    lr: 1.0240000000000005e-06     evaluation reward: 8.36\n",
      "episode: 2577   score: 11.0   memory length: 679641   epsilon: 0.009998020008555413    steps: 572    lr: 1.0240000000000005e-06     evaluation reward: 8.35\n",
      "episode: 2578   score: 6.0   memory length: 680020   epsilon: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     evaluation reward: 8.31\n",
      "episode: 2579   score: 16.0   memory length: 680707   epsilon: 0.009998020008555413    steps: 687    lr: 1.0240000000000005e-06     evaluation reward: 8.39\n",
      "episode: 2580   score: 10.0   memory length: 681228   epsilon: 0.009998020008555413    steps: 521    lr: 1.0240000000000005e-06     evaluation reward: 8.42\n",
      "episode: 2581   score: 9.0   memory length: 681645   epsilon: 0.009998020008555413    steps: 417    lr: 1.0240000000000005e-06     evaluation reward: 8.43\n",
      "episode: 2582   score: 10.0   memory length: 682117   epsilon: 0.009998020008555413    steps: 472    lr: 1.0240000000000005e-06     evaluation reward: 8.44\n",
      "episode: 2583   score: 9.0   memory length: 682572   epsilon: 0.009998020008555413    steps: 455    lr: 1.0240000000000005e-06     evaluation reward: 8.41\n",
      "episode: 2584   score: 10.0   memory length: 683091   epsilon: 0.009998020008555413    steps: 519    lr: 1.0240000000000005e-06     evaluation reward: 8.45\n",
      "episode: 2585   score: 10.0   memory length: 683560   epsilon: 0.009998020008555413    steps: 469    lr: 1.0240000000000005e-06     evaluation reward: 8.48\n",
      "episode: 2586   score: 10.0   memory length: 684052   epsilon: 0.009998020008555413    steps: 492    lr: 1.0240000000000005e-06     evaluation reward: 8.53\n",
      "episode: 2587   score: 12.0   memory length: 684637   epsilon: 0.009998020008555413    steps: 585    lr: 1.0240000000000005e-06     evaluation reward: 8.59\n",
      "episode: 2588   score: 19.0   memory length: 685301   epsilon: 0.009998020008555413    steps: 664    lr: 1.0240000000000005e-06     evaluation reward: 8.71\n",
      "episode: 2589   score: 18.0   memory length: 685931   epsilon: 0.009998020008555413    steps: 630    lr: 1.0240000000000005e-06     evaluation reward: 8.85\n",
      "episode: 2590   score: 7.0   memory length: 686356   epsilon: 0.009998020008555413    steps: 425    lr: 1.0240000000000005e-06     evaluation reward: 8.85\n",
      "episode: 2591   score: 15.0   memory length: 686855   epsilon: 0.009998020008555413    steps: 499    lr: 1.0240000000000005e-06     evaluation reward: 8.93\n",
      "episode: 2592   score: 14.0   memory length: 687407   epsilon: 0.009998020008555413    steps: 552    lr: 1.0240000000000005e-06     evaluation reward: 8.99\n",
      "episode: 2593   score: 8.0   memory length: 687808   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 9.02\n",
      "episode: 2594   score: 5.0   memory length: 688132   epsilon: 0.009998020008555413    steps: 324    lr: 1.0240000000000005e-06     evaluation reward: 8.95\n",
      "episode: 2595   score: 9.0   memory length: 688583   epsilon: 0.009998020008555413    steps: 451    lr: 1.0240000000000005e-06     evaluation reward: 8.93\n",
      "episode: 2596   score: 10.0   memory length: 689102   epsilon: 0.009998020008555413    steps: 519    lr: 1.0240000000000005e-06     evaluation reward: 8.97\n",
      "episode: 2597   score: 6.0   memory length: 689459   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 8.96\n",
      "episode: 2598   score: 8.0   memory length: 689901   epsilon: 0.009998020008555413    steps: 442    lr: 1.0240000000000005e-06     evaluation reward: 8.92\n",
      "episode: 2599   score: 10.0   memory length: 690382   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 8.92\n",
      "episode: 2600   score: 8.0   memory length: 690787   epsilon: 0.009998020008555413    steps: 405    lr: 1.0240000000000005e-06     evaluation reward: 8.83\n",
      "episode: 2601   score: 13.0   memory length: 691270   epsilon: 0.009998020008555413    steps: 483    lr: 1.0240000000000005e-06     evaluation reward: 8.88\n",
      "episode: 2602   score: 7.0   memory length: 691698   epsilon: 0.009998020008555413    steps: 428    lr: 1.0240000000000005e-06     evaluation reward: 8.91\n",
      "episode: 2603   score: 12.0   memory length: 692139   epsilon: 0.009998020008555413    steps: 441    lr: 1.0240000000000005e-06     evaluation reward: 8.93\n",
      "episode: 2604   score: 6.0   memory length: 692476   epsilon: 0.009998020008555413    steps: 337    lr: 1.0240000000000005e-06     evaluation reward: 8.92\n",
      "episode: 2605   score: 8.0   memory length: 692897   epsilon: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     evaluation reward: 8.93\n",
      "episode: 2606   score: 15.0   memory length: 693477   epsilon: 0.009998020008555413    steps: 580    lr: 1.0240000000000005e-06     evaluation reward: 8.99\n",
      "episode: 2607   score: 11.0   memory length: 694003   epsilon: 0.009998020008555413    steps: 526    lr: 1.0240000000000005e-06     evaluation reward: 8.98\n",
      "episode: 2608   score: 7.0   memory length: 694368   epsilon: 0.009998020008555413    steps: 365    lr: 1.0240000000000005e-06     evaluation reward: 8.95\n",
      "episode: 2609   score: 7.0   memory length: 694737   epsilon: 0.009998020008555413    steps: 369    lr: 1.0240000000000005e-06     evaluation reward: 8.92\n",
      "episode: 2610   score: 13.0   memory length: 695390   epsilon: 0.009998020008555413    steps: 653    lr: 1.0240000000000005e-06     evaluation reward: 8.95\n",
      "episode: 2611   score: 9.0   memory length: 695830   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 8.86\n",
      "episode: 2612   score: 5.0   memory length: 696155   epsilon: 0.009998020008555413    steps: 325    lr: 1.0240000000000005e-06     evaluation reward: 8.76\n",
      "episode: 2613   score: 12.0   memory length: 696759   epsilon: 0.009998020008555413    steps: 604    lr: 1.0240000000000005e-06     evaluation reward: 8.73\n",
      "episode: 2614   score: 5.0   memory length: 697050   epsilon: 0.009998020008555413    steps: 291    lr: 1.0240000000000005e-06     evaluation reward: 8.7\n",
      "episode: 2615   score: 31.0   memory length: 697905   epsilon: 0.009998020008555413    steps: 855    lr: 1.0240000000000005e-06     evaluation reward: 8.94\n",
      "episode: 2616   score: 5.0   memory length: 698197   epsilon: 0.009998020008555413    steps: 292    lr: 1.0240000000000005e-06     evaluation reward: 8.92\n",
      "episode: 2617   score: 8.0   memory length: 698691   epsilon: 0.009998020008555413    steps: 494    lr: 1.0240000000000005e-06     evaluation reward: 8.96\n",
      "episode: 2618   score: 10.0   memory length: 699172   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 9.02\n",
      "episode: 2619   score: 10.0   memory length: 699643   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 9.03\n",
      "episode: 2620   score: 9.0   memory length: 700109   epsilon: 0.009998020008555413    steps: 466    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2621   score: 9.0   memory length: 700552   epsilon: 0.009998020008555413    steps: 443    lr: 4.0960000000000023e-07     evaluation reward: 9.06\n",
      "episode: 2622   score: 9.0   memory length: 701019   epsilon: 0.009998020008555413    steps: 467    lr: 4.0960000000000023e-07     evaluation reward: 9.1\n",
      "episode: 2623   score: 9.0   memory length: 701498   epsilon: 0.009998020008555413    steps: 479    lr: 4.0960000000000023e-07     evaluation reward: 9.12\n",
      "episode: 2624   score: 10.0   memory length: 702017   epsilon: 0.009998020008555413    steps: 519    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2625   score: 9.0   memory length: 702491   epsilon: 0.009998020008555413    steps: 474    lr: 4.0960000000000023e-07     evaluation reward: 9.19\n",
      "episode: 2626   score: 5.0   memory length: 702799   epsilon: 0.009998020008555413    steps: 308    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2627   score: 10.0   memory length: 703307   epsilon: 0.009998020008555413    steps: 508    lr: 4.0960000000000023e-07     evaluation reward: 9.16\n",
      "episode: 2628   score: 8.0   memory length: 703720   epsilon: 0.009998020008555413    steps: 413    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2629   score: 13.0   memory length: 704334   epsilon: 0.009998020008555413    steps: 614    lr: 4.0960000000000023e-07     evaluation reward: 9.17\n",
      "episode: 2630   score: 4.0   memory length: 704609   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 9.15\n",
      "episode: 2631   score: 9.0   memory length: 705081   epsilon: 0.009998020008555413    steps: 472    lr: 4.0960000000000023e-07     evaluation reward: 9.19\n",
      "episode: 2632   score: 9.0   memory length: 705536   epsilon: 0.009998020008555413    steps: 455    lr: 4.0960000000000023e-07     evaluation reward: 9.19\n",
      "episode: 2633   score: 6.0   memory length: 705875   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 9.18\n",
      "episode: 2634   score: 5.0   memory length: 706163   epsilon: 0.009998020008555413    steps: 288    lr: 4.0960000000000023e-07     evaluation reward: 9.11\n",
      "episode: 2635   score: 10.0   memory length: 706618   epsilon: 0.009998020008555413    steps: 455    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2636   score: 9.0   memory length: 707087   epsilon: 0.009998020008555413    steps: 469    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2637   score: 4.0   memory length: 707334   epsilon: 0.009998020008555413    steps: 247    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2638   score: 5.0   memory length: 707659   epsilon: 0.009998020008555413    steps: 325    lr: 4.0960000000000023e-07     evaluation reward: 8.94\n",
      "episode: 2639   score: 7.0   memory length: 708048   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2640   score: 4.0   memory length: 708325   epsilon: 0.009998020008555413    steps: 277    lr: 4.0960000000000023e-07     evaluation reward: 8.91\n",
      "episode: 2641   score: 13.0   memory length: 708981   epsilon: 0.009998020008555413    steps: 656    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2642   score: 10.0   memory length: 709486   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2643   score: 14.0   memory length: 709991   epsilon: 0.009998020008555413    steps: 505    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2644   score: 5.0   memory length: 710299   epsilon: 0.009998020008555413    steps: 308    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2645   score: 5.0   memory length: 710613   epsilon: 0.009998020008555413    steps: 314    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2646   score: 12.0   memory length: 711128   epsilon: 0.009998020008555413    steps: 515    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2647   score: 9.0   memory length: 711559   epsilon: 0.009998020008555413    steps: 431    lr: 4.0960000000000023e-07     evaluation reward: 9.05\n",
      "episode: 2648   score: 17.0   memory length: 712067   epsilon: 0.009998020008555413    steps: 508    lr: 4.0960000000000023e-07     evaluation reward: 9.13\n",
      "episode: 2649   score: 8.0   memory length: 712463   epsilon: 0.009998020008555413    steps: 396    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2650   score: 5.0   memory length: 712752   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2651   score: 5.0   memory length: 713078   epsilon: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2652   score: 7.0   memory length: 713442   epsilon: 0.009998020008555413    steps: 364    lr: 4.0960000000000023e-07     evaluation reward: 8.96\n",
      "episode: 2653   score: 10.0   memory length: 713915   epsilon: 0.009998020008555413    steps: 473    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2654   score: 12.0   memory length: 714467   epsilon: 0.009998020008555413    steps: 552    lr: 4.0960000000000023e-07     evaluation reward: 9.06\n",
      "episode: 2655   score: 11.0   memory length: 714906   epsilon: 0.009998020008555413    steps: 439    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2656   score: 6.0   memory length: 715261   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2657   score: 10.0   memory length: 715816   epsilon: 0.009998020008555413    steps: 555    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2658   score: 9.0   memory length: 716325   epsilon: 0.009998020008555413    steps: 509    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2659   score: 13.0   memory length: 716977   epsilon: 0.009998020008555413    steps: 652    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2660   score: 7.0   memory length: 717356   epsilon: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     evaluation reward: 9.11\n",
      "episode: 2661   score: 8.0   memory length: 717799   epsilon: 0.009998020008555413    steps: 443    lr: 4.0960000000000023e-07     evaluation reward: 9.13\n",
      "episode: 2662   score: 11.0   memory length: 718300   epsilon: 0.009998020008555413    steps: 501    lr: 4.0960000000000023e-07     evaluation reward: 9.2\n",
      "episode: 2663   score: 7.0   memory length: 718731   epsilon: 0.009998020008555413    steps: 431    lr: 4.0960000000000023e-07     evaluation reward: 9.22\n",
      "episode: 2664   score: 10.0   memory length: 719191   epsilon: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     evaluation reward: 9.22\n",
      "episode: 2665   score: 7.0   memory length: 719599   epsilon: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     evaluation reward: 9.23\n",
      "episode: 2666   score: 15.0   memory length: 720131   epsilon: 0.009998020008555413    steps: 532    lr: 4.0960000000000023e-07     evaluation reward: 9.29\n",
      "episode: 2667   score: 7.0   memory length: 720485   epsilon: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     evaluation reward: 9.3\n",
      "episode: 2668   score: 5.0   memory length: 720807   epsilon: 0.009998020008555413    steps: 322    lr: 4.0960000000000023e-07     evaluation reward: 9.3\n",
      "episode: 2669   score: 7.0   memory length: 721191   epsilon: 0.009998020008555413    steps: 384    lr: 4.0960000000000023e-07     evaluation reward: 9.31\n",
      "episode: 2670   score: 12.0   memory length: 721817   epsilon: 0.009998020008555413    steps: 626    lr: 4.0960000000000023e-07     evaluation reward: 9.32\n",
      "episode: 2671   score: 8.0   memory length: 722225   epsilon: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     evaluation reward: 9.32\n",
      "episode: 2672   score: 5.0   memory length: 722551   epsilon: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     evaluation reward: 9.32\n",
      "episode: 2673   score: 10.0   memory length: 723046   epsilon: 0.009998020008555413    steps: 495    lr: 4.0960000000000023e-07     evaluation reward: 9.34\n",
      "episode: 2674   score: 11.0   memory length: 723575   epsilon: 0.009998020008555413    steps: 529    lr: 4.0960000000000023e-07     evaluation reward: 9.38\n",
      "episode: 2675   score: 10.0   memory length: 724046   epsilon: 0.009998020008555413    steps: 471    lr: 4.0960000000000023e-07     evaluation reward: 9.39\n",
      "episode: 2676   score: 5.0   memory length: 724357   epsilon: 0.009998020008555413    steps: 311    lr: 4.0960000000000023e-07     evaluation reward: 9.33\n",
      "episode: 2677   score: 10.0   memory length: 724874   epsilon: 0.009998020008555413    steps: 517    lr: 4.0960000000000023e-07     evaluation reward: 9.32\n",
      "episode: 2678   score: 8.0   memory length: 725295   epsilon: 0.009998020008555413    steps: 421    lr: 4.0960000000000023e-07     evaluation reward: 9.34\n",
      "episode: 2679   score: 11.0   memory length: 725778   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 9.29\n",
      "episode: 2680   score: 8.0   memory length: 726220   epsilon: 0.009998020008555413    steps: 442    lr: 4.0960000000000023e-07     evaluation reward: 9.27\n",
      "episode: 2681   score: 8.0   memory length: 726627   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 9.26\n",
      "episode: 2682   score: 11.0   memory length: 727131   epsilon: 0.009998020008555413    steps: 504    lr: 4.0960000000000023e-07     evaluation reward: 9.27\n",
      "episode: 2683   score: 5.0   memory length: 727476   epsilon: 0.009998020008555413    steps: 345    lr: 4.0960000000000023e-07     evaluation reward: 9.23\n",
      "episode: 2684   score: 10.0   memory length: 727909   epsilon: 0.009998020008555413    steps: 433    lr: 4.0960000000000023e-07     evaluation reward: 9.23\n",
      "episode: 2685   score: 11.0   memory length: 728288   epsilon: 0.009998020008555413    steps: 379    lr: 4.0960000000000023e-07     evaluation reward: 9.24\n",
      "episode: 2686   score: 15.0   memory length: 728819   epsilon: 0.009998020008555413    steps: 531    lr: 4.0960000000000023e-07     evaluation reward: 9.29\n",
      "episode: 2687   score: 6.0   memory length: 729175   epsilon: 0.009998020008555413    steps: 356    lr: 4.0960000000000023e-07     evaluation reward: 9.23\n",
      "episode: 2688   score: 6.0   memory length: 729488   epsilon: 0.009998020008555413    steps: 313    lr: 4.0960000000000023e-07     evaluation reward: 9.1\n",
      "episode: 2689   score: 12.0   memory length: 730046   epsilon: 0.009998020008555413    steps: 558    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2690   score: 6.0   memory length: 730401   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2691   score: 8.0   memory length: 730823   epsilon: 0.009998020008555413    steps: 422    lr: 4.0960000000000023e-07     evaluation reward: 8.96\n",
      "episode: 2692   score: 11.0   memory length: 731311   epsilon: 0.009998020008555413    steps: 488    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2693   score: 8.0   memory length: 731705   epsilon: 0.009998020008555413    steps: 394    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2694   score: 10.0   memory length: 732177   epsilon: 0.009998020008555413    steps: 472    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2695   score: 5.0   memory length: 732501   epsilon: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     evaluation reward: 8.94\n",
      "episode: 2696   score: 8.0   memory length: 732924   epsilon: 0.009998020008555413    steps: 423    lr: 4.0960000000000023e-07     evaluation reward: 8.92\n",
      "episode: 2697   score: 7.0   memory length: 733301   epsilon: 0.009998020008555413    steps: 377    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2698   score: 4.0   memory length: 733575   epsilon: 0.009998020008555413    steps: 274    lr: 4.0960000000000023e-07     evaluation reward: 8.89\n",
      "episode: 2699   score: 5.0   memory length: 733881   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 8.84\n",
      "episode: 2700   score: 13.0   memory length: 734516   epsilon: 0.009998020008555413    steps: 635    lr: 4.0960000000000023e-07     evaluation reward: 8.89\n",
      "episode: 2701   score: 20.0   memory length: 735110   epsilon: 0.009998020008555413    steps: 594    lr: 4.0960000000000023e-07     evaluation reward: 8.96\n",
      "episode: 2702   score: 8.0   memory length: 735554   epsilon: 0.009998020008555413    steps: 444    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2703   score: 5.0   memory length: 735844   epsilon: 0.009998020008555413    steps: 290    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2704   score: 15.0   memory length: 736471   epsilon: 0.009998020008555413    steps: 627    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2705   score: 10.0   memory length: 737006   epsilon: 0.009998020008555413    steps: 535    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2706   score: 7.0   memory length: 737402   epsilon: 0.009998020008555413    steps: 396    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2707   score: 11.0   memory length: 737879   epsilon: 0.009998020008555413    steps: 477    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2708   score: 4.0   memory length: 738141   epsilon: 0.009998020008555413    steps: 262    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2709   score: 19.0   memory length: 738732   epsilon: 0.009998020008555413    steps: 591    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2710   score: 11.0   memory length: 739243   epsilon: 0.009998020008555413    steps: 511    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2711   score: 11.0   memory length: 739693   epsilon: 0.009998020008555413    steps: 450    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2712   score: 4.0   memory length: 739950   epsilon: 0.009998020008555413    steps: 257    lr: 4.0960000000000023e-07     evaluation reward: 9.01\n",
      "episode: 2713   score: 10.0   memory length: 740283   epsilon: 0.009998020008555413    steps: 333    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2714   score: 8.0   memory length: 740707   epsilon: 0.009998020008555413    steps: 424    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2715   score: 10.0   memory length: 741226   epsilon: 0.009998020008555413    steps: 519    lr: 4.0960000000000023e-07     evaluation reward: 8.81\n",
      "episode: 2716   score: 11.0   memory length: 741750   epsilon: 0.009998020008555413    steps: 524    lr: 4.0960000000000023e-07     evaluation reward: 8.87\n",
      "episode: 2717   score: 4.0   memory length: 742045   epsilon: 0.009998020008555413    steps: 295    lr: 4.0960000000000023e-07     evaluation reward: 8.83\n",
      "episode: 2718   score: 10.0   memory length: 742573   epsilon: 0.009998020008555413    steps: 528    lr: 4.0960000000000023e-07     evaluation reward: 8.83\n",
      "episode: 2719   score: 10.0   memory length: 742930   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 8.83\n",
      "episode: 2720   score: 8.0   memory length: 743366   epsilon: 0.009998020008555413    steps: 436    lr: 4.0960000000000023e-07     evaluation reward: 8.82\n",
      "episode: 2721   score: 4.0   memory length: 743607   epsilon: 0.009998020008555413    steps: 241    lr: 4.0960000000000023e-07     evaluation reward: 8.77\n",
      "episode: 2722   score: 9.0   memory length: 744048   epsilon: 0.009998020008555413    steps: 441    lr: 4.0960000000000023e-07     evaluation reward: 8.77\n",
      "episode: 2723   score: 8.0   memory length: 744507   epsilon: 0.009998020008555413    steps: 459    lr: 4.0960000000000023e-07     evaluation reward: 8.76\n",
      "episode: 2724   score: 6.0   memory length: 744848   epsilon: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     evaluation reward: 8.72\n",
      "episode: 2725   score: 9.0   memory length: 745260   epsilon: 0.009998020008555413    steps: 412    lr: 4.0960000000000023e-07     evaluation reward: 8.72\n",
      "episode: 2726   score: 9.0   memory length: 745754   epsilon: 0.009998020008555413    steps: 494    lr: 4.0960000000000023e-07     evaluation reward: 8.76\n",
      "episode: 2727   score: 5.0   memory length: 746078   epsilon: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     evaluation reward: 8.71\n",
      "episode: 2728   score: 8.0   memory length: 746471   epsilon: 0.009998020008555413    steps: 393    lr: 4.0960000000000023e-07     evaluation reward: 8.71\n",
      "episode: 2729   score: 6.0   memory length: 746825   epsilon: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     evaluation reward: 8.64\n",
      "episode: 2730   score: 6.0   memory length: 747182   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 8.66\n",
      "episode: 2731   score: 11.0   memory length: 747602   epsilon: 0.009998020008555413    steps: 420    lr: 4.0960000000000023e-07     evaluation reward: 8.68\n",
      "episode: 2732   score: 6.0   memory length: 747958   epsilon: 0.009998020008555413    steps: 356    lr: 4.0960000000000023e-07     evaluation reward: 8.65\n",
      "episode: 2733   score: 10.0   memory length: 748284   epsilon: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     evaluation reward: 8.69\n",
      "episode: 2734   score: 10.0   memory length: 748660   epsilon: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     evaluation reward: 8.74\n",
      "episode: 2735   score: 9.0   memory length: 749182   epsilon: 0.009998020008555413    steps: 522    lr: 4.0960000000000023e-07     evaluation reward: 8.73\n",
      "episode: 2736   score: 6.0   memory length: 749536   epsilon: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     evaluation reward: 8.7\n",
      "episode: 2737   score: 15.0   memory length: 750101   epsilon: 0.009998020008555413    steps: 565    lr: 4.0960000000000023e-07     evaluation reward: 8.81\n",
      "episode: 2738   score: 10.0   memory length: 750459   epsilon: 0.009998020008555413    steps: 358    lr: 4.0960000000000023e-07     evaluation reward: 8.86\n",
      "episode: 2739   score: 6.0   memory length: 750816   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 8.85\n",
      "episode: 2740   score: 11.0   memory length: 751345   epsilon: 0.009998020008555413    steps: 529    lr: 4.0960000000000023e-07     evaluation reward: 8.92\n",
      "episode: 2741   score: 4.0   memory length: 751620   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 8.83\n",
      "episode: 2742   score: 7.0   memory length: 751985   epsilon: 0.009998020008555413    steps: 365    lr: 4.0960000000000023e-07     evaluation reward: 8.8\n",
      "episode: 2743   score: 6.0   memory length: 752329   epsilon: 0.009998020008555413    steps: 344    lr: 4.0960000000000023e-07     evaluation reward: 8.72\n",
      "episode: 2744   score: 9.0   memory length: 752748   epsilon: 0.009998020008555413    steps: 419    lr: 4.0960000000000023e-07     evaluation reward: 8.76\n",
      "episode: 2745   score: 6.0   memory length: 753084   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 8.77\n",
      "episode: 2746   score: 8.0   memory length: 753490   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 8.73\n",
      "episode: 2747   score: 11.0   memory length: 754026   epsilon: 0.009998020008555413    steps: 536    lr: 4.0960000000000023e-07     evaluation reward: 8.75\n",
      "episode: 2748   score: 7.0   memory length: 754434   epsilon: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     evaluation reward: 8.65\n",
      "episode: 2749   score: 9.0   memory length: 754860   epsilon: 0.009998020008555413    steps: 426    lr: 4.0960000000000023e-07     evaluation reward: 8.66\n",
      "episode: 2750   score: 11.0   memory length: 755234   epsilon: 0.009998020008555413    steps: 374    lr: 4.0960000000000023e-07     evaluation reward: 8.72\n",
      "episode: 2751   score: 6.0   memory length: 755568   epsilon: 0.009998020008555413    steps: 334    lr: 4.0960000000000023e-07     evaluation reward: 8.73\n",
      "episode: 2752   score: 7.0   memory length: 755974   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 8.73\n",
      "episode: 2753   score: 13.0   memory length: 756424   epsilon: 0.009998020008555413    steps: 450    lr: 4.0960000000000023e-07     evaluation reward: 8.76\n",
      "episode: 2754   score: 7.0   memory length: 756810   epsilon: 0.009998020008555413    steps: 386    lr: 4.0960000000000023e-07     evaluation reward: 8.71\n",
      "episode: 2755   score: 11.0   memory length: 757375   epsilon: 0.009998020008555413    steps: 565    lr: 4.0960000000000023e-07     evaluation reward: 8.71\n",
      "episode: 2756   score: 5.0   memory length: 757681   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 8.7\n",
      "episode: 2757   score: 8.0   memory length: 758086   epsilon: 0.009998020008555413    steps: 405    lr: 4.0960000000000023e-07     evaluation reward: 8.68\n",
      "episode: 2758   score: 11.0   memory length: 758629   epsilon: 0.009998020008555413    steps: 543    lr: 4.0960000000000023e-07     evaluation reward: 8.7\n",
      "episode: 2759   score: 7.0   memory length: 759024   epsilon: 0.009998020008555413    steps: 395    lr: 4.0960000000000023e-07     evaluation reward: 8.64\n",
      "episode: 2760   score: 20.0   memory length: 759769   epsilon: 0.009998020008555413    steps: 745    lr: 4.0960000000000023e-07     evaluation reward: 8.77\n",
      "episode: 2761   score: 8.0   memory length: 760221   epsilon: 0.009998020008555413    steps: 452    lr: 4.0960000000000023e-07     evaluation reward: 8.77\n",
      "episode: 2762   score: 5.0   memory length: 760510   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 8.71\n",
      "episode: 2763   score: 6.0   memory length: 760861   epsilon: 0.009998020008555413    steps: 351    lr: 4.0960000000000023e-07     evaluation reward: 8.7\n",
      "episode: 2764   score: 10.0   memory length: 761190   epsilon: 0.009998020008555413    steps: 329    lr: 4.0960000000000023e-07     evaluation reward: 8.7\n",
      "episode: 2765   score: 4.0   memory length: 761465   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 8.67\n",
      "episode: 2766   score: 10.0   memory length: 761950   epsilon: 0.009998020008555413    steps: 485    lr: 4.0960000000000023e-07     evaluation reward: 8.62\n",
      "episode: 2767   score: 5.0   memory length: 762241   epsilon: 0.009998020008555413    steps: 291    lr: 4.0960000000000023e-07     evaluation reward: 8.6\n",
      "episode: 2768   score: 7.0   memory length: 762648   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 8.62\n",
      "episode: 2769   score: 11.0   memory length: 763208   epsilon: 0.009998020008555413    steps: 560    lr: 4.0960000000000023e-07     evaluation reward: 8.66\n",
      "episode: 2770   score: 8.0   memory length: 763666   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 8.62\n",
      "episode: 2771   score: 14.0   memory length: 764167   epsilon: 0.009998020008555413    steps: 501    lr: 4.0960000000000023e-07     evaluation reward: 8.68\n",
      "episode: 2772   score: 11.0   memory length: 764686   epsilon: 0.009998020008555413    steps: 519    lr: 4.0960000000000023e-07     evaluation reward: 8.74\n",
      "episode: 2773   score: 10.0   memory length: 765189   epsilon: 0.009998020008555413    steps: 503    lr: 4.0960000000000023e-07     evaluation reward: 8.74\n",
      "episode: 2774   score: 10.0   memory length: 765671   epsilon: 0.009998020008555413    steps: 482    lr: 4.0960000000000023e-07     evaluation reward: 8.73\n",
      "episode: 2775   score: 15.0   memory length: 766224   epsilon: 0.009998020008555413    steps: 553    lr: 4.0960000000000023e-07     evaluation reward: 8.78\n",
      "episode: 2776   score: 10.0   memory length: 766692   epsilon: 0.009998020008555413    steps: 468    lr: 4.0960000000000023e-07     evaluation reward: 8.83\n",
      "episode: 2777   score: 12.0   memory length: 767184   epsilon: 0.009998020008555413    steps: 492    lr: 4.0960000000000023e-07     evaluation reward: 8.85\n",
      "episode: 2778   score: 9.0   memory length: 767659   epsilon: 0.009998020008555413    steps: 475    lr: 4.0960000000000023e-07     evaluation reward: 8.86\n",
      "episode: 2779   score: 11.0   memory length: 768214   epsilon: 0.009998020008555413    steps: 555    lr: 4.0960000000000023e-07     evaluation reward: 8.86\n",
      "episode: 2780   score: 18.0   memory length: 768835   epsilon: 0.009998020008555413    steps: 621    lr: 4.0960000000000023e-07     evaluation reward: 8.96\n",
      "episode: 2781   score: 9.0   memory length: 769309   epsilon: 0.009998020008555413    steps: 474    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2782   score: 8.0   memory length: 769716   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 8.94\n",
      "episode: 2783   score: 6.0   memory length: 770041   epsilon: 0.009998020008555413    steps: 325    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2784   score: 15.0   memory length: 770595   epsilon: 0.009998020008555413    steps: 554    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2785   score: 6.0   memory length: 770970   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2786   score: 19.0   memory length: 771663   epsilon: 0.009998020008555413    steps: 693    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2787   score: 12.0   memory length: 772069   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 9.05\n",
      "episode: 2788   score: 14.0   memory length: 772705   epsilon: 0.009998020008555413    steps: 636    lr: 4.0960000000000023e-07     evaluation reward: 9.13\n",
      "episode: 2789   score: 11.0   memory length: 773238   epsilon: 0.009998020008555413    steps: 533    lr: 4.0960000000000023e-07     evaluation reward: 9.12\n",
      "episode: 2790   score: 8.0   memory length: 773660   epsilon: 0.009998020008555413    steps: 422    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2791   score: 8.0   memory length: 774096   epsilon: 0.009998020008555413    steps: 436    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2792   score: 5.0   memory length: 774373   epsilon: 0.009998020008555413    steps: 277    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2793   score: 7.0   memory length: 774783   epsilon: 0.009998020008555413    steps: 410    lr: 4.0960000000000023e-07     evaluation reward: 9.07\n",
      "episode: 2794   score: 8.0   memory length: 775208   epsilon: 0.009998020008555413    steps: 425    lr: 4.0960000000000023e-07     evaluation reward: 9.05\n",
      "episode: 2795   score: 3.0   memory length: 775418   epsilon: 0.009998020008555413    steps: 210    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2796   score: 12.0   memory length: 775862   epsilon: 0.009998020008555413    steps: 444    lr: 4.0960000000000023e-07     evaluation reward: 9.07\n",
      "episode: 2797   score: 5.0   memory length: 776189   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 9.05\n",
      "episode: 2798   score: 12.0   memory length: 776746   epsilon: 0.009998020008555413    steps: 557    lr: 4.0960000000000023e-07     evaluation reward: 9.13\n",
      "episode: 2799   score: 12.0   memory length: 777374   epsilon: 0.009998020008555413    steps: 628    lr: 4.0960000000000023e-07     evaluation reward: 9.2\n",
      "episode: 2800   score: 7.0   memory length: 777728   epsilon: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     evaluation reward: 9.14\n",
      "episode: 2801   score: 12.0   memory length: 778293   epsilon: 0.009998020008555413    steps: 565    lr: 4.0960000000000023e-07     evaluation reward: 9.06\n",
      "episode: 2802   score: 7.0   memory length: 778669   epsilon: 0.009998020008555413    steps: 376    lr: 4.0960000000000023e-07     evaluation reward: 9.05\n",
      "episode: 2803   score: 5.0   memory length: 779001   epsilon: 0.009998020008555413    steps: 332    lr: 4.0960000000000023e-07     evaluation reward: 9.05\n",
      "episode: 2804   score: 16.0   memory length: 779604   epsilon: 0.009998020008555413    steps: 603    lr: 4.0960000000000023e-07     evaluation reward: 9.06\n",
      "episode: 2805   score: 11.0   memory length: 780158   epsilon: 0.009998020008555413    steps: 554    lr: 4.0960000000000023e-07     evaluation reward: 9.07\n",
      "episode: 2806   score: 5.0   memory length: 780483   epsilon: 0.009998020008555413    steps: 325    lr: 4.0960000000000023e-07     evaluation reward: 9.05\n",
      "episode: 2807   score: 9.0   memory length: 780977   epsilon: 0.009998020008555413    steps: 494    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2808   score: 9.0   memory length: 781495   epsilon: 0.009998020008555413    steps: 518    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2809   score: 8.0   memory length: 781902   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2810   score: 4.0   memory length: 782181   epsilon: 0.009998020008555413    steps: 279    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2811   score: 7.0   memory length: 782545   epsilon: 0.009998020008555413    steps: 364    lr: 4.0960000000000023e-07     evaluation reward: 8.86\n",
      "episode: 2812   score: 4.0   memory length: 782807   epsilon: 0.009998020008555413    steps: 262    lr: 4.0960000000000023e-07     evaluation reward: 8.86\n",
      "episode: 2813   score: 11.0   memory length: 783171   epsilon: 0.009998020008555413    steps: 364    lr: 4.0960000000000023e-07     evaluation reward: 8.87\n",
      "episode: 2814   score: 2.0   memory length: 783369   epsilon: 0.009998020008555413    steps: 198    lr: 4.0960000000000023e-07     evaluation reward: 8.81\n",
      "episode: 2815   score: 8.0   memory length: 783776   epsilon: 0.009998020008555413    steps: 407    lr: 4.0960000000000023e-07     evaluation reward: 8.79\n",
      "episode: 2816   score: 6.0   memory length: 784173   epsilon: 0.009998020008555413    steps: 397    lr: 4.0960000000000023e-07     evaluation reward: 8.74\n",
      "episode: 2817   score: 8.0   memory length: 784626   epsilon: 0.009998020008555413    steps: 453    lr: 4.0960000000000023e-07     evaluation reward: 8.78\n",
      "episode: 2818   score: 8.0   memory length: 785057   epsilon: 0.009998020008555413    steps: 431    lr: 4.0960000000000023e-07     evaluation reward: 8.76\n",
      "episode: 2819   score: 14.0   memory length: 785569   epsilon: 0.009998020008555413    steps: 512    lr: 4.0960000000000023e-07     evaluation reward: 8.8\n",
      "episode: 2820   score: 19.0   memory length: 786136   epsilon: 0.009998020008555413    steps: 567    lr: 4.0960000000000023e-07     evaluation reward: 8.91\n",
      "episode: 2821   score: 12.0   memory length: 786775   epsilon: 0.009998020008555413    steps: 639    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2822   score: 5.0   memory length: 787102   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2823   score: 6.0   memory length: 787448   epsilon: 0.009998020008555413    steps: 346    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2824   score: 15.0   memory length: 788097   epsilon: 0.009998020008555413    steps: 649    lr: 4.0960000000000023e-07     evaluation reward: 9.02\n",
      "episode: 2825   score: 3.0   memory length: 788327   epsilon: 0.009998020008555413    steps: 230    lr: 4.0960000000000023e-07     evaluation reward: 8.96\n",
      "episode: 2826   score: 10.0   memory length: 788810   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2827   score: 8.0   memory length: 789238   epsilon: 0.009998020008555413    steps: 428    lr: 4.0960000000000023e-07     evaluation reward: 9.0\n",
      "episode: 2828   score: 6.0   memory length: 789577   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2829   score: 11.0   memory length: 790144   epsilon: 0.009998020008555413    steps: 567    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2830   score: 8.0   memory length: 790548   epsilon: 0.009998020008555413    steps: 404    lr: 4.0960000000000023e-07     evaluation reward: 9.05\n",
      "episode: 2831   score: 15.0   memory length: 791121   epsilon: 0.009998020008555413    steps: 573    lr: 4.0960000000000023e-07     evaluation reward: 9.09\n",
      "episode: 2832   score: 7.0   memory length: 791469   epsilon: 0.009998020008555413    steps: 348    lr: 4.0960000000000023e-07     evaluation reward: 9.1\n",
      "episode: 2833   score: 4.0   memory length: 791712   epsilon: 0.009998020008555413    steps: 243    lr: 4.0960000000000023e-07     evaluation reward: 9.04\n",
      "episode: 2834   score: 5.0   memory length: 791987   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2835   score: 5.0   memory length: 792280   epsilon: 0.009998020008555413    steps: 293    lr: 4.0960000000000023e-07     evaluation reward: 8.95\n",
      "episode: 2836   score: 10.0   memory length: 792798   epsilon: 0.009998020008555413    steps: 518    lr: 4.0960000000000023e-07     evaluation reward: 8.99\n",
      "episode: 2837   score: 7.0   memory length: 793171   epsilon: 0.009998020008555413    steps: 373    lr: 4.0960000000000023e-07     evaluation reward: 8.91\n",
      "episode: 2838   score: 5.0   memory length: 793450   epsilon: 0.009998020008555413    steps: 279    lr: 4.0960000000000023e-07     evaluation reward: 8.86\n",
      "episode: 2839   score: 10.0   memory length: 793933   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 8.9\n",
      "episode: 2840   score: 7.0   memory length: 794299   epsilon: 0.009998020008555413    steps: 366    lr: 4.0960000000000023e-07     evaluation reward: 8.86\n",
      "episode: 2841   score: 12.0   memory length: 794880   epsilon: 0.009998020008555413    steps: 581    lr: 4.0960000000000023e-07     evaluation reward: 8.94\n",
      "episode: 2842   score: 6.0   memory length: 795190   epsilon: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2843   score: 11.0   memory length: 795596   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2844   score: 8.0   memory length: 796030   epsilon: 0.009998020008555413    steps: 434    lr: 4.0960000000000023e-07     evaluation reward: 8.97\n",
      "episode: 2845   score: 12.0   memory length: 796438   epsilon: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     evaluation reward: 9.03\n",
      "episode: 2846   score: 3.0   memory length: 796648   epsilon: 0.009998020008555413    steps: 210    lr: 4.0960000000000023e-07     evaluation reward: 8.98\n",
      "episode: 2847   score: 5.0   memory length: 796957   epsilon: 0.009998020008555413    steps: 309    lr: 4.0960000000000023e-07     evaluation reward: 8.92\n",
      "episode: 2848   score: 9.0   memory length: 797431   epsilon: 0.009998020008555413    steps: 474    lr: 4.0960000000000023e-07     evaluation reward: 8.94\n",
      "episode: 2849   score: 8.0   memory length: 797876   epsilon: 0.009998020008555413    steps: 445    lr: 4.0960000000000023e-07     evaluation reward: 8.93\n",
      "episode: 2850   score: 12.0   memory length: 798350   epsilon: 0.009998020008555413    steps: 474    lr: 4.0960000000000023e-07     evaluation reward: 8.94\n",
      "episode: 2851   score: 20.0   memory length: 799083   epsilon: 0.009998020008555413    steps: 733    lr: 4.0960000000000023e-07     evaluation reward: 9.08\n",
      "episode: 2852   score: 10.0   memory length: 799480   epsilon: 0.009998020008555413    steps: 397    lr: 4.0960000000000023e-07     evaluation reward: 9.11\n",
      "episode: 2853   score: 9.0   memory length: 799927   epsilon: 0.009998020008555413    steps: 447    lr: 4.0960000000000023e-07     evaluation reward: 9.07\n",
      "episode: 2854   score: 12.0   memory length: 800476   epsilon: 0.009998020008555413    steps: 549    lr: 1.638400000000001e-07     evaluation reward: 9.12\n",
      "episode: 2855   score: 9.0   memory length: 800960   epsilon: 0.009998020008555413    steps: 484    lr: 1.638400000000001e-07     evaluation reward: 9.1\n",
      "episode: 2856   score: 10.0   memory length: 801460   epsilon: 0.009998020008555413    steps: 500    lr: 1.638400000000001e-07     evaluation reward: 9.15\n",
      "episode: 2857   score: 7.0   memory length: 801869   epsilon: 0.009998020008555413    steps: 409    lr: 1.638400000000001e-07     evaluation reward: 9.14\n",
      "episode: 2858   score: 8.0   memory length: 802299   epsilon: 0.009998020008555413    steps: 430    lr: 1.638400000000001e-07     evaluation reward: 9.11\n",
      "episode: 2859   score: 5.0   memory length: 802589   epsilon: 0.009998020008555413    steps: 290    lr: 1.638400000000001e-07     evaluation reward: 9.09\n",
      "episode: 2860   score: 8.0   memory length: 803031   epsilon: 0.009998020008555413    steps: 442    lr: 1.638400000000001e-07     evaluation reward: 8.97\n",
      "episode: 2861   score: 6.0   memory length: 803371   epsilon: 0.009998020008555413    steps: 340    lr: 1.638400000000001e-07     evaluation reward: 8.95\n",
      "episode: 2862   score: 2.0   memory length: 803569   epsilon: 0.009998020008555413    steps: 198    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2863   score: 4.0   memory length: 803844   epsilon: 0.009998020008555413    steps: 275    lr: 1.638400000000001e-07     evaluation reward: 8.9\n",
      "episode: 2864   score: 6.0   memory length: 804175   epsilon: 0.009998020008555413    steps: 331    lr: 1.638400000000001e-07     evaluation reward: 8.86\n",
      "episode: 2865   score: 6.0   memory length: 804517   epsilon: 0.009998020008555413    steps: 342    lr: 1.638400000000001e-07     evaluation reward: 8.88\n",
      "episode: 2866   score: 15.0   memory length: 805109   epsilon: 0.009998020008555413    steps: 592    lr: 1.638400000000001e-07     evaluation reward: 8.93\n",
      "episode: 2867   score: 13.0   memory length: 805704   epsilon: 0.009998020008555413    steps: 595    lr: 1.638400000000001e-07     evaluation reward: 9.01\n",
      "episode: 2868   score: 7.0   memory length: 806091   epsilon: 0.009998020008555413    steps: 387    lr: 1.638400000000001e-07     evaluation reward: 9.01\n",
      "episode: 2869   score: 12.0   memory length: 806704   epsilon: 0.009998020008555413    steps: 613    lr: 1.638400000000001e-07     evaluation reward: 9.02\n",
      "episode: 2870   score: 22.0   memory length: 807295   epsilon: 0.009998020008555413    steps: 591    lr: 1.638400000000001e-07     evaluation reward: 9.16\n",
      "episode: 2871   score: 11.0   memory length: 807803   epsilon: 0.009998020008555413    steps: 508    lr: 1.638400000000001e-07     evaluation reward: 9.13\n",
      "episode: 2872   score: 11.0   memory length: 808165   epsilon: 0.009998020008555413    steps: 362    lr: 1.638400000000001e-07     evaluation reward: 9.13\n",
      "episode: 2873   score: 15.0   memory length: 808713   epsilon: 0.009998020008555413    steps: 548    lr: 1.638400000000001e-07     evaluation reward: 9.18\n",
      "episode: 2874   score: 11.0   memory length: 809110   epsilon: 0.009998020008555413    steps: 397    lr: 1.638400000000001e-07     evaluation reward: 9.19\n",
      "episode: 2875   score: 4.0   memory length: 809375   epsilon: 0.009998020008555413    steps: 265    lr: 1.638400000000001e-07     evaluation reward: 9.08\n",
      "episode: 2876   score: 9.0   memory length: 809830   epsilon: 0.009998020008555413    steps: 455    lr: 1.638400000000001e-07     evaluation reward: 9.07\n",
      "episode: 2877   score: 11.0   memory length: 810364   epsilon: 0.009998020008555413    steps: 534    lr: 1.638400000000001e-07     evaluation reward: 9.06\n",
      "episode: 2878   score: 12.0   memory length: 810967   epsilon: 0.009998020008555413    steps: 603    lr: 1.638400000000001e-07     evaluation reward: 9.09\n",
      "episode: 2879   score: 11.0   memory length: 811477   epsilon: 0.009998020008555413    steps: 510    lr: 1.638400000000001e-07     evaluation reward: 9.09\n",
      "episode: 2880   score: 9.0   memory length: 811800   epsilon: 0.009998020008555413    steps: 323    lr: 1.638400000000001e-07     evaluation reward: 9.0\n",
      "episode: 2881   score: 12.0   memory length: 812331   epsilon: 0.009998020008555413    steps: 531    lr: 1.638400000000001e-07     evaluation reward: 9.03\n",
      "episode: 2882   score: 6.0   memory length: 812707   epsilon: 0.009998020008555413    steps: 376    lr: 1.638400000000001e-07     evaluation reward: 9.01\n",
      "episode: 2883   score: 19.0   memory length: 813341   epsilon: 0.009998020008555413    steps: 634    lr: 1.638400000000001e-07     evaluation reward: 9.14\n",
      "episode: 2884   score: 11.0   memory length: 813751   epsilon: 0.009998020008555413    steps: 410    lr: 1.638400000000001e-07     evaluation reward: 9.1\n",
      "episode: 2885   score: 9.0   memory length: 814206   epsilon: 0.009998020008555413    steps: 455    lr: 1.638400000000001e-07     evaluation reward: 9.13\n",
      "episode: 2886   score: 17.0   memory length: 814695   epsilon: 0.009998020008555413    steps: 489    lr: 1.638400000000001e-07     evaluation reward: 9.11\n",
      "episode: 2887   score: 6.0   memory length: 815019   epsilon: 0.009998020008555413    steps: 324    lr: 1.638400000000001e-07     evaluation reward: 9.05\n",
      "episode: 2888   score: 7.0   memory length: 815419   epsilon: 0.009998020008555413    steps: 400    lr: 1.638400000000001e-07     evaluation reward: 8.98\n",
      "episode: 2889   score: 6.0   memory length: 815774   epsilon: 0.009998020008555413    steps: 355    lr: 1.638400000000001e-07     evaluation reward: 8.93\n",
      "episode: 2890   score: 7.0   memory length: 816152   epsilon: 0.009998020008555413    steps: 378    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2891   score: 5.0   memory length: 816460   epsilon: 0.009998020008555413    steps: 308    lr: 1.638400000000001e-07     evaluation reward: 8.89\n",
      "episode: 2892   score: 9.0   memory length: 816967   epsilon: 0.009998020008555413    steps: 507    lr: 1.638400000000001e-07     evaluation reward: 8.93\n",
      "episode: 2893   score: 5.0   memory length: 817260   epsilon: 0.009998020008555413    steps: 293    lr: 1.638400000000001e-07     evaluation reward: 8.91\n",
      "episode: 2894   score: 6.0   memory length: 817654   epsilon: 0.009998020008555413    steps: 394    lr: 1.638400000000001e-07     evaluation reward: 8.89\n",
      "episode: 2895   score: 11.0   memory length: 818101   epsilon: 0.009998020008555413    steps: 447    lr: 1.638400000000001e-07     evaluation reward: 8.97\n",
      "episode: 2896   score: 7.0   memory length: 818439   epsilon: 0.009998020008555413    steps: 338    lr: 1.638400000000001e-07     evaluation reward: 8.92\n",
      "episode: 2897   score: 11.0   memory length: 818921   epsilon: 0.009998020008555413    steps: 482    lr: 1.638400000000001e-07     evaluation reward: 8.98\n",
      "episode: 2898   score: 20.0   memory length: 819561   epsilon: 0.009998020008555413    steps: 640    lr: 1.638400000000001e-07     evaluation reward: 9.06\n",
      "episode: 2899   score: 8.0   memory length: 819968   epsilon: 0.009998020008555413    steps: 407    lr: 1.638400000000001e-07     evaluation reward: 9.02\n",
      "episode: 2900   score: 6.0   memory length: 820321   epsilon: 0.009998020008555413    steps: 353    lr: 1.638400000000001e-07     evaluation reward: 9.01\n",
      "episode: 2901   score: 11.0   memory length: 820686   epsilon: 0.009998020008555413    steps: 365    lr: 1.638400000000001e-07     evaluation reward: 9.0\n",
      "episode: 2902   score: 8.0   memory length: 821103   epsilon: 0.009998020008555413    steps: 417    lr: 1.638400000000001e-07     evaluation reward: 9.01\n",
      "episode: 2903   score: 26.0   memory length: 821820   epsilon: 0.009998020008555413    steps: 717    lr: 1.638400000000001e-07     evaluation reward: 9.22\n",
      "episode: 2904   score: 9.0   memory length: 822271   epsilon: 0.009998020008555413    steps: 451    lr: 1.638400000000001e-07     evaluation reward: 9.15\n",
      "episode: 2905   score: 15.0   memory length: 822700   epsilon: 0.009998020008555413    steps: 429    lr: 1.638400000000001e-07     evaluation reward: 9.19\n",
      "episode: 2906   score: 7.0   memory length: 823044   epsilon: 0.009998020008555413    steps: 344    lr: 1.638400000000001e-07     evaluation reward: 9.21\n",
      "episode: 2907   score: 10.0   memory length: 823418   epsilon: 0.009998020008555413    steps: 374    lr: 1.638400000000001e-07     evaluation reward: 9.22\n",
      "episode: 2908   score: 5.0   memory length: 823726   epsilon: 0.009998020008555413    steps: 308    lr: 1.638400000000001e-07     evaluation reward: 9.18\n",
      "episode: 2909   score: 14.0   memory length: 824358   epsilon: 0.009998020008555413    steps: 632    lr: 1.638400000000001e-07     evaluation reward: 9.24\n",
      "episode: 2910   score: 10.0   memory length: 824705   epsilon: 0.009998020008555413    steps: 347    lr: 1.638400000000001e-07     evaluation reward: 9.3\n",
      "episode: 2911   score: 12.0   memory length: 825281   epsilon: 0.009998020008555413    steps: 576    lr: 1.638400000000001e-07     evaluation reward: 9.35\n",
      "episode: 2912   score: 9.0   memory length: 825683   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 9.4\n",
      "episode: 2913   score: 9.0   memory length: 826128   epsilon: 0.009998020008555413    steps: 445    lr: 1.638400000000001e-07     evaluation reward: 9.38\n",
      "episode: 2914   score: 8.0   memory length: 826535   epsilon: 0.009998020008555413    steps: 407    lr: 1.638400000000001e-07     evaluation reward: 9.44\n",
      "episode: 2915   score: 6.0   memory length: 826848   epsilon: 0.009998020008555413    steps: 313    lr: 1.638400000000001e-07     evaluation reward: 9.42\n",
      "episode: 2916   score: 11.0   memory length: 827383   epsilon: 0.009998020008555413    steps: 535    lr: 1.638400000000001e-07     evaluation reward: 9.47\n",
      "episode: 2917   score: 6.0   memory length: 827758   epsilon: 0.009998020008555413    steps: 375    lr: 1.638400000000001e-07     evaluation reward: 9.45\n",
      "episode: 2918   score: 5.0   memory length: 828047   epsilon: 0.009998020008555413    steps: 289    lr: 1.638400000000001e-07     evaluation reward: 9.42\n",
      "episode: 2919   score: 7.0   memory length: 828442   epsilon: 0.009998020008555413    steps: 395    lr: 1.638400000000001e-07     evaluation reward: 9.35\n",
      "episode: 2920   score: 10.0   memory length: 828949   epsilon: 0.009998020008555413    steps: 507    lr: 1.638400000000001e-07     evaluation reward: 9.26\n",
      "episode: 2921   score: 11.0   memory length: 829506   epsilon: 0.009998020008555413    steps: 557    lr: 1.638400000000001e-07     evaluation reward: 9.25\n",
      "episode: 2922   score: 11.0   memory length: 829884   epsilon: 0.009998020008555413    steps: 378    lr: 1.638400000000001e-07     evaluation reward: 9.31\n",
      "episode: 2923   score: 22.0   memory length: 830504   epsilon: 0.009998020008555413    steps: 620    lr: 1.638400000000001e-07     evaluation reward: 9.47\n",
      "episode: 2924   score: 9.0   memory length: 830940   epsilon: 0.009998020008555413    steps: 436    lr: 1.638400000000001e-07     evaluation reward: 9.41\n",
      "episode: 2925   score: 6.0   memory length: 831265   epsilon: 0.009998020008555413    steps: 325    lr: 1.638400000000001e-07     evaluation reward: 9.44\n",
      "episode: 2926   score: 11.0   memory length: 831755   epsilon: 0.009998020008555413    steps: 490    lr: 1.638400000000001e-07     evaluation reward: 9.45\n",
      "episode: 2927   score: 13.0   memory length: 832270   epsilon: 0.009998020008555413    steps: 515    lr: 1.638400000000001e-07     evaluation reward: 9.5\n",
      "episode: 2928   score: 12.0   memory length: 832833   epsilon: 0.009998020008555413    steps: 563    lr: 1.638400000000001e-07     evaluation reward: 9.56\n",
      "episode: 2929   score: 6.0   memory length: 833211   epsilon: 0.009998020008555413    steps: 378    lr: 1.638400000000001e-07     evaluation reward: 9.51\n",
      "episode: 2930   score: 8.0   memory length: 833665   epsilon: 0.009998020008555413    steps: 454    lr: 1.638400000000001e-07     evaluation reward: 9.51\n",
      "episode: 2931   score: 6.0   memory length: 834043   epsilon: 0.009998020008555413    steps: 378    lr: 1.638400000000001e-07     evaluation reward: 9.42\n",
      "episode: 2932   score: 8.0   memory length: 834468   epsilon: 0.009998020008555413    steps: 425    lr: 1.638400000000001e-07     evaluation reward: 9.43\n",
      "episode: 2933   score: 9.0   memory length: 834958   epsilon: 0.009998020008555413    steps: 490    lr: 1.638400000000001e-07     evaluation reward: 9.48\n",
      "episode: 2934   score: 9.0   memory length: 835431   epsilon: 0.009998020008555413    steps: 473    lr: 1.638400000000001e-07     evaluation reward: 9.52\n",
      "episode: 2935   score: 15.0   memory length: 835986   epsilon: 0.009998020008555413    steps: 555    lr: 1.638400000000001e-07     evaluation reward: 9.62\n",
      "episode: 2936   score: 6.0   memory length: 836317   epsilon: 0.009998020008555413    steps: 331    lr: 1.638400000000001e-07     evaluation reward: 9.58\n",
      "episode: 2937   score: 17.0   memory length: 836982   epsilon: 0.009998020008555413    steps: 665    lr: 1.638400000000001e-07     evaluation reward: 9.68\n",
      "episode: 2938   score: 11.0   memory length: 837514   epsilon: 0.009998020008555413    steps: 532    lr: 1.638400000000001e-07     evaluation reward: 9.74\n",
      "episode: 2939   score: 8.0   memory length: 837937   epsilon: 0.009998020008555413    steps: 423    lr: 1.638400000000001e-07     evaluation reward: 9.72\n",
      "episode: 2940   score: 10.0   memory length: 838476   epsilon: 0.009998020008555413    steps: 539    lr: 1.638400000000001e-07     evaluation reward: 9.75\n",
      "episode: 2941   score: 13.0   memory length: 838934   epsilon: 0.009998020008555413    steps: 458    lr: 1.638400000000001e-07     evaluation reward: 9.76\n",
      "episode: 2942   score: 9.0   memory length: 839419   epsilon: 0.009998020008555413    steps: 485    lr: 1.638400000000001e-07     evaluation reward: 9.79\n",
      "episode: 2943   score: 11.0   memory length: 839972   epsilon: 0.009998020008555413    steps: 553    lr: 1.638400000000001e-07     evaluation reward: 9.79\n",
      "episode: 2944   score: 9.0   memory length: 840376   epsilon: 0.009998020008555413    steps: 404    lr: 1.638400000000001e-07     evaluation reward: 9.8\n",
      "episode: 2945   score: 8.0   memory length: 840819   epsilon: 0.009998020008555413    steps: 443    lr: 1.638400000000001e-07     evaluation reward: 9.76\n",
      "episode: 2946   score: 6.0   memory length: 841171   epsilon: 0.009998020008555413    steps: 352    lr: 1.638400000000001e-07     evaluation reward: 9.79\n",
      "episode: 2947   score: 11.0   memory length: 841657   epsilon: 0.009998020008555413    steps: 486    lr: 1.638400000000001e-07     evaluation reward: 9.85\n",
      "episode: 2948   score: 10.0   memory length: 842184   epsilon: 0.009998020008555413    steps: 527    lr: 1.638400000000001e-07     evaluation reward: 9.86\n",
      "episode: 2949   score: 8.0   memory length: 842619   epsilon: 0.009998020008555413    steps: 435    lr: 1.638400000000001e-07     evaluation reward: 9.86\n",
      "episode: 2950   score: 11.0   memory length: 843245   epsilon: 0.009998020008555413    steps: 626    lr: 1.638400000000001e-07     evaluation reward: 9.85\n",
      "episode: 2951   score: 3.0   memory length: 843453   epsilon: 0.009998020008555413    steps: 208    lr: 1.638400000000001e-07     evaluation reward: 9.68\n",
      "episode: 2952   score: 11.0   memory length: 844025   epsilon: 0.009998020008555413    steps: 572    lr: 1.638400000000001e-07     evaluation reward: 9.69\n",
      "episode: 2953   score: 6.0   memory length: 844387   epsilon: 0.009998020008555413    steps: 362    lr: 1.638400000000001e-07     evaluation reward: 9.66\n",
      "episode: 2954   score: 7.0   memory length: 844754   epsilon: 0.009998020008555413    steps: 367    lr: 1.638400000000001e-07     evaluation reward: 9.61\n",
      "episode: 2955   score: 12.0   memory length: 845198   epsilon: 0.009998020008555413    steps: 444    lr: 1.638400000000001e-07     evaluation reward: 9.64\n",
      "episode: 2956   score: 11.0   memory length: 845762   epsilon: 0.009998020008555413    steps: 564    lr: 1.638400000000001e-07     evaluation reward: 9.65\n",
      "episode: 2957   score: 7.0   memory length: 846117   epsilon: 0.009998020008555413    steps: 355    lr: 1.638400000000001e-07     evaluation reward: 9.65\n",
      "episode: 2958   score: 10.0   memory length: 846638   epsilon: 0.009998020008555413    steps: 521    lr: 1.638400000000001e-07     evaluation reward: 9.67\n",
      "episode: 2959   score: 25.0   memory length: 847407   epsilon: 0.009998020008555413    steps: 769    lr: 1.638400000000001e-07     evaluation reward: 9.87\n",
      "episode: 2960   score: 9.0   memory length: 847872   epsilon: 0.009998020008555413    steps: 465    lr: 1.638400000000001e-07     evaluation reward: 9.88\n",
      "episode: 2961   score: 8.0   memory length: 848306   epsilon: 0.009998020008555413    steps: 434    lr: 1.638400000000001e-07     evaluation reward: 9.9\n",
      "episode: 2962   score: 4.0   memory length: 848601   epsilon: 0.009998020008555413    steps: 295    lr: 1.638400000000001e-07     evaluation reward: 9.92\n",
      "episode: 2963   score: 3.0   memory length: 848832   epsilon: 0.009998020008555413    steps: 231    lr: 1.638400000000001e-07     evaluation reward: 9.91\n",
      "episode: 2964   score: 16.0   memory length: 849555   epsilon: 0.009998020008555413    steps: 723    lr: 1.638400000000001e-07     evaluation reward: 10.01\n",
      "episode: 2965   score: 7.0   memory length: 849917   epsilon: 0.009998020008555413    steps: 362    lr: 1.638400000000001e-07     evaluation reward: 10.02\n",
      "episode: 2966   score: 15.0   memory length: 850344   epsilon: 0.009998020008555413    steps: 427    lr: 1.638400000000001e-07     evaluation reward: 10.02\n",
      "episode: 2967   score: 10.0   memory length: 850870   epsilon: 0.009998020008555413    steps: 526    lr: 1.638400000000001e-07     evaluation reward: 9.99\n",
      "episode: 2968   score: 9.0   memory length: 851342   epsilon: 0.009998020008555413    steps: 472    lr: 1.638400000000001e-07     evaluation reward: 10.01\n",
      "episode: 2969   score: 6.0   memory length: 851685   epsilon: 0.009998020008555413    steps: 343    lr: 1.638400000000001e-07     evaluation reward: 9.95\n",
      "episode: 2970   score: 8.0   memory length: 852089   epsilon: 0.009998020008555413    steps: 404    lr: 1.638400000000001e-07     evaluation reward: 9.81\n",
      "episode: 2971   score: 12.0   memory length: 852642   epsilon: 0.009998020008555413    steps: 553    lr: 1.638400000000001e-07     evaluation reward: 9.82\n",
      "episode: 2972   score: 15.0   memory length: 853075   epsilon: 0.009998020008555413    steps: 433    lr: 1.638400000000001e-07     evaluation reward: 9.86\n",
      "episode: 2973   score: 3.0   memory length: 853303   epsilon: 0.009998020008555413    steps: 228    lr: 1.638400000000001e-07     evaluation reward: 9.74\n",
      "episode: 2974   score: 12.0   memory length: 853862   epsilon: 0.009998020008555413    steps: 559    lr: 1.638400000000001e-07     evaluation reward: 9.75\n",
      "episode: 2975   score: 7.0   memory length: 854265   epsilon: 0.009998020008555413    steps: 403    lr: 1.638400000000001e-07     evaluation reward: 9.78\n",
      "episode: 2976   score: 8.0   memory length: 854669   epsilon: 0.009998020008555413    steps: 404    lr: 1.638400000000001e-07     evaluation reward: 9.77\n",
      "episode: 2977   score: 28.0   memory length: 855457   epsilon: 0.009998020008555413    steps: 788    lr: 1.638400000000001e-07     evaluation reward: 9.94\n",
      "episode: 2978   score: 12.0   memory length: 856070   epsilon: 0.009998020008555413    steps: 613    lr: 1.638400000000001e-07     evaluation reward: 9.94\n",
      "episode: 2979   score: 9.0   memory length: 856544   epsilon: 0.009998020008555413    steps: 474    lr: 1.638400000000001e-07     evaluation reward: 9.92\n",
      "episode: 2980   score: 12.0   memory length: 857107   epsilon: 0.009998020008555413    steps: 563    lr: 1.638400000000001e-07     evaluation reward: 9.95\n",
      "episode: 2981   score: 6.0   memory length: 857452   epsilon: 0.009998020008555413    steps: 345    lr: 1.638400000000001e-07     evaluation reward: 9.89\n",
      "episode: 2982   score: 7.0   memory length: 857858   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 9.9\n",
      "episode: 2983   score: 15.0   memory length: 858440   epsilon: 0.009998020008555413    steps: 582    lr: 1.638400000000001e-07     evaluation reward: 9.86\n",
      "episode: 2984   score: 11.0   memory length: 858836   epsilon: 0.009998020008555413    steps: 396    lr: 1.638400000000001e-07     evaluation reward: 9.86\n",
      "episode: 2985   score: 7.0   memory length: 859245   epsilon: 0.009998020008555413    steps: 409    lr: 1.638400000000001e-07     evaluation reward: 9.84\n",
      "episode: 2986   score: 15.0   memory length: 859802   epsilon: 0.009998020008555413    steps: 557    lr: 1.638400000000001e-07     evaluation reward: 9.82\n",
      "episode: 2987   score: 16.0   memory length: 860393   epsilon: 0.009998020008555413    steps: 591    lr: 1.638400000000001e-07     evaluation reward: 9.92\n",
      "episode: 2988   score: 9.0   memory length: 860877   epsilon: 0.009998020008555413    steps: 484    lr: 1.638400000000001e-07     evaluation reward: 9.94\n",
      "episode: 2989   score: 10.0   memory length: 861418   epsilon: 0.009998020008555413    steps: 541    lr: 1.638400000000001e-07     evaluation reward: 9.98\n",
      "episode: 2990   score: 5.0   memory length: 861728   epsilon: 0.009998020008555413    steps: 310    lr: 1.638400000000001e-07     evaluation reward: 9.96\n",
      "episode: 2991   score: 13.0   memory length: 862232   epsilon: 0.009998020008555413    steps: 504    lr: 1.638400000000001e-07     evaluation reward: 10.04\n",
      "episode: 2992   score: 12.0   memory length: 862797   epsilon: 0.009998020008555413    steps: 565    lr: 1.638400000000001e-07     evaluation reward: 10.07\n",
      "episode: 2993   score: 3.0   memory length: 863010   epsilon: 0.009998020008555413    steps: 213    lr: 1.638400000000001e-07     evaluation reward: 10.05\n",
      "episode: 2994   score: 15.0   memory length: 863595   epsilon: 0.009998020008555413    steps: 585    lr: 1.638400000000001e-07     evaluation reward: 10.14\n",
      "episode: 2995   score: 7.0   memory length: 863969   epsilon: 0.009998020008555413    steps: 374    lr: 1.638400000000001e-07     evaluation reward: 10.1\n",
      "episode: 2996   score: 8.0   memory length: 864353   epsilon: 0.009998020008555413    steps: 384    lr: 1.638400000000001e-07     evaluation reward: 10.11\n",
      "episode: 2997   score: 12.0   memory length: 864923   epsilon: 0.009998020008555413    steps: 570    lr: 1.638400000000001e-07     evaluation reward: 10.12\n",
      "episode: 2998   score: 6.0   memory length: 865267   epsilon: 0.009998020008555413    steps: 344    lr: 1.638400000000001e-07     evaluation reward: 9.98\n",
      "episode: 2999   score: 5.0   memory length: 865559   epsilon: 0.009998020008555413    steps: 292    lr: 1.638400000000001e-07     evaluation reward: 9.95\n",
      "episode: 3000   score: 16.0   memory length: 866131   epsilon: 0.009998020008555413    steps: 572    lr: 1.638400000000001e-07     evaluation reward: 10.05\n",
      "episode: 3001   score: 11.0   memory length: 866674   epsilon: 0.009998020008555413    steps: 543    lr: 1.638400000000001e-07     evaluation reward: 10.05\n",
      "episode: 3002   score: 7.0   memory length: 867068   epsilon: 0.009998020008555413    steps: 394    lr: 1.638400000000001e-07     evaluation reward: 10.04\n",
      "episode: 3003   score: 9.0   memory length: 867525   epsilon: 0.009998020008555413    steps: 457    lr: 1.638400000000001e-07     evaluation reward: 9.87\n",
      "episode: 3004   score: 7.0   memory length: 867926   epsilon: 0.009998020008555413    steps: 401    lr: 1.638400000000001e-07     evaluation reward: 9.85\n",
      "episode: 3005   score: 9.0   memory length: 868396   epsilon: 0.009998020008555413    steps: 470    lr: 1.638400000000001e-07     evaluation reward: 9.79\n",
      "episode: 3006   score: 13.0   memory length: 868926   epsilon: 0.009998020008555413    steps: 530    lr: 1.638400000000001e-07     evaluation reward: 9.85\n",
      "episode: 3007   score: 14.0   memory length: 869482   epsilon: 0.009998020008555413    steps: 556    lr: 1.638400000000001e-07     evaluation reward: 9.89\n",
      "episode: 3008   score: 13.0   memory length: 870089   epsilon: 0.009998020008555413    steps: 607    lr: 1.638400000000001e-07     evaluation reward: 9.97\n",
      "episode: 3009   score: 2.0   memory length: 870269   epsilon: 0.009998020008555413    steps: 180    lr: 1.638400000000001e-07     evaluation reward: 9.85\n",
      "episode: 3010   score: 6.0   memory length: 870618   epsilon: 0.009998020008555413    steps: 349    lr: 1.638400000000001e-07     evaluation reward: 9.81\n",
      "episode: 3011   score: 6.0   memory length: 870998   epsilon: 0.009998020008555413    steps: 380    lr: 1.638400000000001e-07     evaluation reward: 9.75\n",
      "episode: 3012   score: 7.0   memory length: 871371   epsilon: 0.009998020008555413    steps: 373    lr: 1.638400000000001e-07     evaluation reward: 9.73\n",
      "episode: 3013   score: 7.0   memory length: 871720   epsilon: 0.009998020008555413    steps: 349    lr: 1.638400000000001e-07     evaluation reward: 9.71\n",
      "episode: 3014   score: 8.0   memory length: 872108   epsilon: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     evaluation reward: 9.71\n",
      "episode: 3015   score: 17.0   memory length: 872722   epsilon: 0.009998020008555413    steps: 614    lr: 1.638400000000001e-07     evaluation reward: 9.82\n",
      "episode: 3016   score: 8.0   memory length: 873129   epsilon: 0.009998020008555413    steps: 407    lr: 1.638400000000001e-07     evaluation reward: 9.79\n",
      "episode: 3017   score: 9.0   memory length: 873585   epsilon: 0.009998020008555413    steps: 456    lr: 1.638400000000001e-07     evaluation reward: 9.82\n",
      "episode: 3018   score: 6.0   memory length: 873921   epsilon: 0.009998020008555413    steps: 336    lr: 1.638400000000001e-07     evaluation reward: 9.83\n",
      "episode: 3019   score: 8.0   memory length: 874333   epsilon: 0.009998020008555413    steps: 412    lr: 1.638400000000001e-07     evaluation reward: 9.84\n",
      "episode: 3020   score: 13.0   memory length: 874934   epsilon: 0.009998020008555413    steps: 601    lr: 1.638400000000001e-07     evaluation reward: 9.87\n",
      "episode: 3021   score: 14.0   memory length: 875454   epsilon: 0.009998020008555413    steps: 520    lr: 1.638400000000001e-07     evaluation reward: 9.9\n",
      "episode: 3022   score: 6.0   memory length: 875754   epsilon: 0.009998020008555413    steps: 300    lr: 1.638400000000001e-07     evaluation reward: 9.85\n",
      "episode: 3023   score: 19.0   memory length: 876470   epsilon: 0.009998020008555413    steps: 716    lr: 1.638400000000001e-07     evaluation reward: 9.82\n",
      "episode: 3024   score: 16.0   memory length: 877052   epsilon: 0.009998020008555413    steps: 582    lr: 1.638400000000001e-07     evaluation reward: 9.89\n",
      "episode: 3025   score: 10.0   memory length: 877565   epsilon: 0.009998020008555413    steps: 513    lr: 1.638400000000001e-07     evaluation reward: 9.93\n",
      "episode: 3026   score: 10.0   memory length: 877924   epsilon: 0.009998020008555413    steps: 359    lr: 1.638400000000001e-07     evaluation reward: 9.92\n",
      "episode: 3027   score: 7.0   memory length: 878313   epsilon: 0.009998020008555413    steps: 389    lr: 1.638400000000001e-07     evaluation reward: 9.86\n",
      "episode: 3028   score: 5.0   memory length: 878617   epsilon: 0.009998020008555413    steps: 304    lr: 1.638400000000001e-07     evaluation reward: 9.79\n",
      "episode: 3029   score: 6.0   memory length: 878961   epsilon: 0.009998020008555413    steps: 344    lr: 1.638400000000001e-07     evaluation reward: 9.79\n",
      "episode: 3030   score: 4.0   memory length: 879205   epsilon: 0.009998020008555413    steps: 244    lr: 1.638400000000001e-07     evaluation reward: 9.75\n",
      "episode: 3031   score: 11.0   memory length: 879742   epsilon: 0.009998020008555413    steps: 537    lr: 1.638400000000001e-07     evaluation reward: 9.8\n",
      "episode: 3032   score: 9.0   memory length: 880207   epsilon: 0.009998020008555413    steps: 465    lr: 1.638400000000001e-07     evaluation reward: 9.81\n",
      "episode: 3033   score: 4.0   memory length: 880485   epsilon: 0.009998020008555413    steps: 278    lr: 1.638400000000001e-07     evaluation reward: 9.76\n",
      "episode: 3034   score: 15.0   memory length: 881076   epsilon: 0.009998020008555413    steps: 591    lr: 1.638400000000001e-07     evaluation reward: 9.82\n",
      "episode: 3035   score: 9.0   memory length: 881550   epsilon: 0.009998020008555413    steps: 474    lr: 1.638400000000001e-07     evaluation reward: 9.76\n",
      "episode: 3036   score: 6.0   memory length: 881865   epsilon: 0.009998020008555413    steps: 315    lr: 1.638400000000001e-07     evaluation reward: 9.76\n",
      "episode: 3037   score: 8.0   memory length: 882305   epsilon: 0.009998020008555413    steps: 440    lr: 1.638400000000001e-07     evaluation reward: 9.67\n",
      "episode: 3038   score: 4.0   memory length: 882549   epsilon: 0.009998020008555413    steps: 244    lr: 1.638400000000001e-07     evaluation reward: 9.6\n",
      "episode: 3039   score: 5.0   memory length: 882855   epsilon: 0.009998020008555413    steps: 306    lr: 1.638400000000001e-07     evaluation reward: 9.57\n",
      "episode: 3040   score: 8.0   memory length: 883257   epsilon: 0.009998020008555413    steps: 402    lr: 1.638400000000001e-07     evaluation reward: 9.55\n",
      "episode: 3041   score: 14.0   memory length: 883770   epsilon: 0.009998020008555413    steps: 513    lr: 1.638400000000001e-07     evaluation reward: 9.56\n",
      "episode: 3042   score: 5.0   memory length: 884097   epsilon: 0.009998020008555413    steps: 327    lr: 1.638400000000001e-07     evaluation reward: 9.52\n",
      "episode: 3043   score: 6.0   memory length: 884418   epsilon: 0.009998020008555413    steps: 321    lr: 1.638400000000001e-07     evaluation reward: 9.47\n",
      "episode: 3044   score: 7.0   memory length: 884806   epsilon: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     evaluation reward: 9.45\n",
      "episode: 3045   score: 5.0   memory length: 885133   epsilon: 0.009998020008555413    steps: 327    lr: 1.638400000000001e-07     evaluation reward: 9.42\n",
      "episode: 3046   score: 12.0   memory length: 885670   epsilon: 0.009998020008555413    steps: 537    lr: 1.638400000000001e-07     evaluation reward: 9.48\n",
      "episode: 3047   score: 8.0   memory length: 886092   epsilon: 0.009998020008555413    steps: 422    lr: 1.638400000000001e-07     evaluation reward: 9.45\n",
      "episode: 3048   score: 5.0   memory length: 886415   epsilon: 0.009998020008555413    steps: 323    lr: 1.638400000000001e-07     evaluation reward: 9.4\n",
      "episode: 3049   score: 15.0   memory length: 886962   epsilon: 0.009998020008555413    steps: 547    lr: 1.638400000000001e-07     evaluation reward: 9.47\n",
      "episode: 3050   score: 4.0   memory length: 887235   epsilon: 0.009998020008555413    steps: 273    lr: 1.638400000000001e-07     evaluation reward: 9.4\n",
      "episode: 3051   score: 7.0   memory length: 887611   epsilon: 0.009998020008555413    steps: 376    lr: 1.638400000000001e-07     evaluation reward: 9.44\n",
      "episode: 3052   score: 7.0   memory length: 888007   epsilon: 0.009998020008555413    steps: 396    lr: 1.638400000000001e-07     evaluation reward: 9.4\n",
      "episode: 3053   score: 12.0   memory length: 888589   epsilon: 0.009998020008555413    steps: 582    lr: 1.638400000000001e-07     evaluation reward: 9.46\n",
      "episode: 3054   score: 8.0   memory length: 889015   epsilon: 0.009998020008555413    steps: 426    lr: 1.638400000000001e-07     evaluation reward: 9.47\n",
      "episode: 3055   score: 10.0   memory length: 889499   epsilon: 0.009998020008555413    steps: 484    lr: 1.638400000000001e-07     evaluation reward: 9.45\n",
      "episode: 3056   score: 9.0   memory length: 890019   epsilon: 0.009998020008555413    steps: 520    lr: 1.638400000000001e-07     evaluation reward: 9.43\n",
      "episode: 3057   score: 8.0   memory length: 890438   epsilon: 0.009998020008555413    steps: 419    lr: 1.638400000000001e-07     evaluation reward: 9.44\n",
      "episode: 3058   score: 4.0   memory length: 890713   epsilon: 0.009998020008555413    steps: 275    lr: 1.638400000000001e-07     evaluation reward: 9.38\n",
      "episode: 3059   score: 5.0   memory length: 891003   epsilon: 0.009998020008555413    steps: 290    lr: 1.638400000000001e-07     evaluation reward: 9.18\n",
      "episode: 3060   score: 13.0   memory length: 891553   epsilon: 0.009998020008555413    steps: 550    lr: 1.638400000000001e-07     evaluation reward: 9.22\n",
      "episode: 3061   score: 8.0   memory length: 891959   epsilon: 0.009998020008555413    steps: 406    lr: 1.638400000000001e-07     evaluation reward: 9.22\n",
      "episode: 3062   score: 12.0   memory length: 892595   epsilon: 0.009998020008555413    steps: 636    lr: 1.638400000000001e-07     evaluation reward: 9.3\n",
      "episode: 3063   score: 5.0   memory length: 892888   epsilon: 0.009998020008555413    steps: 293    lr: 1.638400000000001e-07     evaluation reward: 9.32\n",
      "episode: 3064   score: 4.0   memory length: 893146   epsilon: 0.009998020008555413    steps: 258    lr: 1.638400000000001e-07     evaluation reward: 9.2\n",
      "episode: 3065   score: 7.0   memory length: 893532   epsilon: 0.009998020008555413    steps: 386    lr: 1.638400000000001e-07     evaluation reward: 9.2\n",
      "episode: 3066   score: 7.0   memory length: 893920   epsilon: 0.009998020008555413    steps: 388    lr: 1.638400000000001e-07     evaluation reward: 9.12\n",
      "episode: 3067   score: 6.0   memory length: 894271   epsilon: 0.009998020008555413    steps: 351    lr: 1.638400000000001e-07     evaluation reward: 9.08\n",
      "episode: 3068   score: 10.0   memory length: 894758   epsilon: 0.009998020008555413    steps: 487    lr: 1.638400000000001e-07     evaluation reward: 9.09\n",
      "episode: 3069   score: 11.0   memory length: 895316   epsilon: 0.009998020008555413    steps: 558    lr: 1.638400000000001e-07     evaluation reward: 9.14\n",
      "episode: 3070   score: 13.0   memory length: 895925   epsilon: 0.009998020008555413    steps: 609    lr: 1.638400000000001e-07     evaluation reward: 9.19\n",
      "episode: 3071   score: 6.0   memory length: 896265   epsilon: 0.009998020008555413    steps: 340    lr: 1.638400000000001e-07     evaluation reward: 9.13\n",
      "episode: 3072   score: 11.0   memory length: 896791   epsilon: 0.009998020008555413    steps: 526    lr: 1.638400000000001e-07     evaluation reward: 9.09\n",
      "episode: 3073   score: 8.0   memory length: 897262   epsilon: 0.009998020008555413    steps: 471    lr: 1.638400000000001e-07     evaluation reward: 9.14\n",
      "episode: 3074   score: 4.0   memory length: 897505   epsilon: 0.009998020008555413    steps: 243    lr: 1.638400000000001e-07     evaluation reward: 9.06\n",
      "episode: 3075   score: 5.0   memory length: 897796   epsilon: 0.009998020008555413    steps: 291    lr: 1.638400000000001e-07     evaluation reward: 9.04\n",
      "episode: 3076   score: 10.0   memory length: 898267   epsilon: 0.009998020008555413    steps: 471    lr: 1.638400000000001e-07     evaluation reward: 9.06\n",
      "episode: 3077   score: 11.0   memory length: 898784   epsilon: 0.009998020008555413    steps: 517    lr: 1.638400000000001e-07     evaluation reward: 8.89\n",
      "episode: 3078   score: 12.0   memory length: 899371   epsilon: 0.009998020008555413    steps: 587    lr: 1.638400000000001e-07     evaluation reward: 8.89\n",
      "episode: 3079   score: 9.0   memory length: 899836   epsilon: 0.009998020008555413    steps: 465    lr: 1.638400000000001e-07     evaluation reward: 8.89\n",
      "episode: 3080   score: 14.0   memory length: 900434   epsilon: 0.009998020008555413    steps: 598    lr: 6.553600000000004e-08     evaluation reward: 8.91\n",
      "episode: 3081   score: 12.0   memory length: 900880   epsilon: 0.009998020008555413    steps: 446    lr: 6.553600000000004e-08     evaluation reward: 8.97\n",
      "episode: 3082   score: 15.0   memory length: 901386   epsilon: 0.009998020008555413    steps: 506    lr: 6.553600000000004e-08     evaluation reward: 9.05\n",
      "episode: 3083   score: 5.0   memory length: 901694   epsilon: 0.009998020008555413    steps: 308    lr: 6.553600000000004e-08     evaluation reward: 8.95\n",
      "episode: 3084   score: 14.0   memory length: 902078   epsilon: 0.009998020008555413    steps: 384    lr: 6.553600000000004e-08     evaluation reward: 8.98\n",
      "episode: 3085   score: 7.0   memory length: 902418   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 8.98\n",
      "episode: 3086   score: 7.0   memory length: 902778   epsilon: 0.009998020008555413    steps: 360    lr: 6.553600000000004e-08     evaluation reward: 8.9\n",
      "episode: 3087   score: 7.0   memory length: 903138   epsilon: 0.009998020008555413    steps: 360    lr: 6.553600000000004e-08     evaluation reward: 8.81\n",
      "episode: 3088   score: 19.0   memory length: 903808   epsilon: 0.009998020008555413    steps: 670    lr: 6.553600000000004e-08     evaluation reward: 8.91\n",
      "episode: 3089   score: 6.0   memory length: 904136   epsilon: 0.009998020008555413    steps: 328    lr: 6.553600000000004e-08     evaluation reward: 8.87\n",
      "episode: 3090   score: 8.0   memory length: 904562   epsilon: 0.009998020008555413    steps: 426    lr: 6.553600000000004e-08     evaluation reward: 8.9\n",
      "episode: 3091   score: 5.0   memory length: 904889   epsilon: 0.009998020008555413    steps: 327    lr: 6.553600000000004e-08     evaluation reward: 8.82\n",
      "episode: 3092   score: 11.0   memory length: 905426   epsilon: 0.009998020008555413    steps: 537    lr: 6.553600000000004e-08     evaluation reward: 8.81\n",
      "episode: 3093   score: 13.0   memory length: 905923   epsilon: 0.009998020008555413    steps: 497    lr: 6.553600000000004e-08     evaluation reward: 8.91\n",
      "episode: 3094   score: 7.0   memory length: 906369   epsilon: 0.009998020008555413    steps: 446    lr: 6.553600000000004e-08     evaluation reward: 8.83\n",
      "episode: 3095   score: 7.0   memory length: 906707   epsilon: 0.009998020008555413    steps: 338    lr: 6.553600000000004e-08     evaluation reward: 8.83\n",
      "episode: 3096   score: 6.0   memory length: 907052   epsilon: 0.009998020008555413    steps: 345    lr: 6.553600000000004e-08     evaluation reward: 8.81\n",
      "episode: 3097   score: 9.0   memory length: 907519   epsilon: 0.009998020008555413    steps: 467    lr: 6.553600000000004e-08     evaluation reward: 8.78\n",
      "episode: 3098   score: 16.0   memory length: 908205   epsilon: 0.009998020008555413    steps: 686    lr: 6.553600000000004e-08     evaluation reward: 8.88\n",
      "episode: 3099   score: 8.0   memory length: 908662   epsilon: 0.009998020008555413    steps: 457    lr: 6.553600000000004e-08     evaluation reward: 8.91\n",
      "episode: 3100   score: 6.0   memory length: 909003   epsilon: 0.009998020008555413    steps: 341    lr: 6.553600000000004e-08     evaluation reward: 8.81\n",
      "episode: 3101   score: 11.0   memory length: 909509   epsilon: 0.009998020008555413    steps: 506    lr: 6.553600000000004e-08     evaluation reward: 8.81\n",
      "episode: 3102   score: 8.0   memory length: 909948   epsilon: 0.009998020008555413    steps: 439    lr: 6.553600000000004e-08     evaluation reward: 8.82\n",
      "episode: 3103   score: 14.0   memory length: 910598   epsilon: 0.009998020008555413    steps: 650    lr: 6.553600000000004e-08     evaluation reward: 8.87\n",
      "episode: 3104   score: 9.0   memory length: 911033   epsilon: 0.009998020008555413    steps: 435    lr: 6.553600000000004e-08     evaluation reward: 8.89\n",
      "episode: 3105   score: 9.0   memory length: 911459   epsilon: 0.009998020008555413    steps: 426    lr: 6.553600000000004e-08     evaluation reward: 8.89\n",
      "episode: 3106   score: 7.0   memory length: 911837   epsilon: 0.009998020008555413    steps: 378    lr: 6.553600000000004e-08     evaluation reward: 8.83\n",
      "episode: 3107   score: 6.0   memory length: 912194   epsilon: 0.009998020008555413    steps: 357    lr: 6.553600000000004e-08     evaluation reward: 8.75\n",
      "episode: 3108   score: 5.0   memory length: 912482   epsilon: 0.009998020008555413    steps: 288    lr: 6.553600000000004e-08     evaluation reward: 8.67\n",
      "episode: 3109   score: 4.0   memory length: 912741   epsilon: 0.009998020008555413    steps: 259    lr: 6.553600000000004e-08     evaluation reward: 8.69\n",
      "episode: 3110   score: 12.0   memory length: 913267   epsilon: 0.009998020008555413    steps: 526    lr: 6.553600000000004e-08     evaluation reward: 8.75\n",
      "episode: 3111   score: 11.0   memory length: 913768   epsilon: 0.009998020008555413    steps: 501    lr: 6.553600000000004e-08     evaluation reward: 8.8\n",
      "episode: 3112   score: 11.0   memory length: 914311   epsilon: 0.009998020008555413    steps: 543    lr: 6.553600000000004e-08     evaluation reward: 8.84\n",
      "episode: 3113   score: 9.0   memory length: 914785   epsilon: 0.009998020008555413    steps: 474    lr: 6.553600000000004e-08     evaluation reward: 8.86\n",
      "episode: 3114   score: 4.0   memory length: 915048   epsilon: 0.009998020008555413    steps: 263    lr: 6.553600000000004e-08     evaluation reward: 8.82\n",
      "episode: 3115   score: 14.0   memory length: 915523   epsilon: 0.009998020008555413    steps: 475    lr: 6.553600000000004e-08     evaluation reward: 8.79\n",
      "episode: 3116   score: 6.0   memory length: 915851   epsilon: 0.009998020008555413    steps: 328    lr: 6.553600000000004e-08     evaluation reward: 8.77\n",
      "episode: 3117   score: 8.0   memory length: 916254   epsilon: 0.009998020008555413    steps: 403    lr: 6.553600000000004e-08     evaluation reward: 8.76\n",
      "episode: 3118   score: 4.0   memory length: 916509   epsilon: 0.009998020008555413    steps: 255    lr: 6.553600000000004e-08     evaluation reward: 8.74\n",
      "episode: 3119   score: 10.0   memory length: 917008   epsilon: 0.009998020008555413    steps: 499    lr: 6.553600000000004e-08     evaluation reward: 8.76\n",
      "episode: 3120   score: 14.0   memory length: 917652   epsilon: 0.009998020008555413    steps: 644    lr: 6.553600000000004e-08     evaluation reward: 8.77\n",
      "episode: 3121   score: 4.0   memory length: 917932   epsilon: 0.009998020008555413    steps: 280    lr: 6.553600000000004e-08     evaluation reward: 8.67\n",
      "episode: 3122   score: 8.0   memory length: 918357   epsilon: 0.009998020008555413    steps: 425    lr: 6.553600000000004e-08     evaluation reward: 8.69\n",
      "episode: 3123   score: 7.0   memory length: 918731   epsilon: 0.009998020008555413    steps: 374    lr: 6.553600000000004e-08     evaluation reward: 8.57\n",
      "episode: 3124   score: 20.0   memory length: 919411   epsilon: 0.009998020008555413    steps: 680    lr: 6.553600000000004e-08     evaluation reward: 8.61\n",
      "episode: 3125   score: 7.0   memory length: 919798   epsilon: 0.009998020008555413    steps: 387    lr: 6.553600000000004e-08     evaluation reward: 8.58\n",
      "episode: 3126   score: 4.0   memory length: 920077   epsilon: 0.009998020008555413    steps: 279    lr: 6.553600000000004e-08     evaluation reward: 8.52\n",
      "episode: 3127   score: 11.0   memory length: 920607   epsilon: 0.009998020008555413    steps: 530    lr: 6.553600000000004e-08     evaluation reward: 8.56\n",
      "episode: 3128   score: 11.0   memory length: 921155   epsilon: 0.009998020008555413    steps: 548    lr: 6.553600000000004e-08     evaluation reward: 8.62\n",
      "episode: 3129   score: 5.0   memory length: 921445   epsilon: 0.009998020008555413    steps: 290    lr: 6.553600000000004e-08     evaluation reward: 8.61\n",
      "episode: 3130   score: 12.0   memory length: 922019   epsilon: 0.009998020008555413    steps: 574    lr: 6.553600000000004e-08     evaluation reward: 8.69\n",
      "episode: 3131   score: 9.0   memory length: 922457   epsilon: 0.009998020008555413    steps: 438    lr: 6.553600000000004e-08     evaluation reward: 8.67\n",
      "episode: 3132   score: 4.0   memory length: 922716   epsilon: 0.009998020008555413    steps: 259    lr: 6.553600000000004e-08     evaluation reward: 8.62\n",
      "episode: 3133   score: 6.0   memory length: 923073   epsilon: 0.009998020008555413    steps: 357    lr: 6.553600000000004e-08     evaluation reward: 8.64\n",
      "episode: 3134   score: 8.0   memory length: 923543   epsilon: 0.009998020008555413    steps: 470    lr: 6.553600000000004e-08     evaluation reward: 8.57\n",
      "episode: 3135   score: 11.0   memory length: 923985   epsilon: 0.009998020008555413    steps: 442    lr: 6.553600000000004e-08     evaluation reward: 8.59\n",
      "episode: 3136   score: 9.0   memory length: 924443   epsilon: 0.009998020008555413    steps: 458    lr: 6.553600000000004e-08     evaluation reward: 8.62\n",
      "episode: 3137   score: 9.0   memory length: 924966   epsilon: 0.009998020008555413    steps: 523    lr: 6.553600000000004e-08     evaluation reward: 8.63\n",
      "episode: 3138   score: 10.0   memory length: 925453   epsilon: 0.009998020008555413    steps: 487    lr: 6.553600000000004e-08     evaluation reward: 8.69\n",
      "episode: 3139   score: 8.0   memory length: 925874   epsilon: 0.009998020008555413    steps: 421    lr: 6.553600000000004e-08     evaluation reward: 8.72\n",
      "episode: 3140   score: 11.0   memory length: 926331   epsilon: 0.009998020008555413    steps: 457    lr: 6.553600000000004e-08     evaluation reward: 8.75\n",
      "episode: 3141   score: 6.0   memory length: 926669   epsilon: 0.009998020008555413    steps: 338    lr: 6.553600000000004e-08     evaluation reward: 8.67\n",
      "episode: 3142   score: 7.0   memory length: 927043   epsilon: 0.009998020008555413    steps: 374    lr: 6.553600000000004e-08     evaluation reward: 8.69\n",
      "episode: 3143   score: 13.0   memory length: 927657   epsilon: 0.009998020008555413    steps: 614    lr: 6.553600000000004e-08     evaluation reward: 8.76\n",
      "episode: 3144   score: 11.0   memory length: 928194   epsilon: 0.009998020008555413    steps: 537    lr: 6.553600000000004e-08     evaluation reward: 8.8\n",
      "episode: 3145   score: 13.0   memory length: 928840   epsilon: 0.009998020008555413    steps: 646    lr: 6.553600000000004e-08     evaluation reward: 8.88\n",
      "episode: 3146   score: 7.0   memory length: 929229   epsilon: 0.009998020008555413    steps: 389    lr: 6.553600000000004e-08     evaluation reward: 8.83\n",
      "episode: 3147   score: 4.0   memory length: 929491   epsilon: 0.009998020008555413    steps: 262    lr: 6.553600000000004e-08     evaluation reward: 8.79\n",
      "episode: 3148   score: 7.0   memory length: 929864   epsilon: 0.009998020008555413    steps: 373    lr: 6.553600000000004e-08     evaluation reward: 8.81\n",
      "episode: 3149   score: 6.0   memory length: 930222   epsilon: 0.009998020008555413    steps: 358    lr: 6.553600000000004e-08     evaluation reward: 8.72\n",
      "episode: 3150   score: 10.0   memory length: 930576   epsilon: 0.009998020008555413    steps: 354    lr: 6.553600000000004e-08     evaluation reward: 8.78\n",
      "episode: 3151   score: 9.0   memory length: 931067   epsilon: 0.009998020008555413    steps: 491    lr: 6.553600000000004e-08     evaluation reward: 8.8\n",
      "episode: 3152   score: 6.0   memory length: 931426   epsilon: 0.009998020008555413    steps: 359    lr: 6.553600000000004e-08     evaluation reward: 8.79\n",
      "episode: 3153   score: 8.0   memory length: 931850   epsilon: 0.009998020008555413    steps: 424    lr: 6.553600000000004e-08     evaluation reward: 8.75\n",
      "episode: 3154   score: 8.0   memory length: 932257   epsilon: 0.009998020008555413    steps: 407    lr: 6.553600000000004e-08     evaluation reward: 8.75\n",
      "episode: 3155   score: 7.0   memory length: 932645   epsilon: 0.009998020008555413    steps: 388    lr: 6.553600000000004e-08     evaluation reward: 8.72\n",
      "episode: 3156   score: 8.0   memory length: 933082   epsilon: 0.009998020008555413    steps: 437    lr: 6.553600000000004e-08     evaluation reward: 8.71\n",
      "episode: 3157   score: 6.0   memory length: 933441   epsilon: 0.009998020008555413    steps: 359    lr: 6.553600000000004e-08     evaluation reward: 8.69\n",
      "episode: 3158   score: 8.0   memory length: 933830   epsilon: 0.009998020008555413    steps: 389    lr: 6.553600000000004e-08     evaluation reward: 8.73\n",
      "episode: 3159   score: 8.0   memory length: 934236   epsilon: 0.009998020008555413    steps: 406    lr: 6.553600000000004e-08     evaluation reward: 8.76\n",
      "episode: 3160   score: 14.0   memory length: 934956   epsilon: 0.009998020008555413    steps: 720    lr: 6.553600000000004e-08     evaluation reward: 8.77\n",
      "episode: 3161   score: 9.0   memory length: 935431   epsilon: 0.009998020008555413    steps: 475    lr: 6.553600000000004e-08     evaluation reward: 8.78\n",
      "episode: 3162   score: 6.0   memory length: 935768   epsilon: 0.009998020008555413    steps: 337    lr: 6.553600000000004e-08     evaluation reward: 8.72\n",
      "episode: 3163   score: 5.0   memory length: 936080   epsilon: 0.009998020008555413    steps: 312    lr: 6.553600000000004e-08     evaluation reward: 8.72\n",
      "episode: 3164   score: 13.0   memory length: 936559   epsilon: 0.009998020008555413    steps: 479    lr: 6.553600000000004e-08     evaluation reward: 8.81\n",
      "episode: 3165   score: 5.0   memory length: 936869   epsilon: 0.009998020008555413    steps: 310    lr: 6.553600000000004e-08     evaluation reward: 8.79\n",
      "episode: 3166   score: 6.0   memory length: 937264   epsilon: 0.009998020008555413    steps: 395    lr: 6.553600000000004e-08     evaluation reward: 8.78\n",
      "episode: 3167   score: 8.0   memory length: 937725   epsilon: 0.009998020008555413    steps: 461    lr: 6.553600000000004e-08     evaluation reward: 8.8\n",
      "episode: 3168   score: 6.0   memory length: 938100   epsilon: 0.009998020008555413    steps: 375    lr: 6.553600000000004e-08     evaluation reward: 8.76\n",
      "episode: 3169   score: 10.0   memory length: 938632   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 8.75\n",
      "episode: 3170   score: 7.0   memory length: 939005   epsilon: 0.009998020008555413    steps: 373    lr: 6.553600000000004e-08     evaluation reward: 8.69\n",
      "episode: 3171   score: 5.0   memory length: 939286   epsilon: 0.009998020008555413    steps: 281    lr: 6.553600000000004e-08     evaluation reward: 8.68\n",
      "episode: 3172   score: 11.0   memory length: 939834   epsilon: 0.009998020008555413    steps: 548    lr: 6.553600000000004e-08     evaluation reward: 8.68\n",
      "episode: 3173   score: 9.0   memory length: 940273   epsilon: 0.009998020008555413    steps: 439    lr: 6.553600000000004e-08     evaluation reward: 8.69\n",
      "episode: 3174   score: 7.0   memory length: 940675   epsilon: 0.009998020008555413    steps: 402    lr: 6.553600000000004e-08     evaluation reward: 8.72\n",
      "episode: 3175   score: 8.0   memory length: 941125   epsilon: 0.009998020008555413    steps: 450    lr: 6.553600000000004e-08     evaluation reward: 8.75\n",
      "episode: 3176   score: 3.0   memory length: 941353   epsilon: 0.009998020008555413    steps: 228    lr: 6.553600000000004e-08     evaluation reward: 8.68\n",
      "episode: 3177   score: 5.0   memory length: 941637   epsilon: 0.009998020008555413    steps: 284    lr: 6.553600000000004e-08     evaluation reward: 8.62\n",
      "episode: 3178   score: 10.0   memory length: 941992   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 8.6\n",
      "episode: 3179   score: 16.0   memory length: 942673   epsilon: 0.009998020008555413    steps: 681    lr: 6.553600000000004e-08     evaluation reward: 8.67\n",
      "episode: 3180   score: 10.0   memory length: 943163   epsilon: 0.009998020008555413    steps: 490    lr: 6.553600000000004e-08     evaluation reward: 8.63\n",
      "episode: 3181   score: 7.0   memory length: 943555   epsilon: 0.009998020008555413    steps: 392    lr: 6.553600000000004e-08     evaluation reward: 8.58\n",
      "episode: 3182   score: 5.0   memory length: 943861   epsilon: 0.009998020008555413    steps: 306    lr: 6.553600000000004e-08     evaluation reward: 8.48\n",
      "episode: 3183   score: 10.0   memory length: 944359   epsilon: 0.009998020008555413    steps: 498    lr: 6.553600000000004e-08     evaluation reward: 8.53\n",
      "episode: 3184   score: 10.0   memory length: 944885   epsilon: 0.009998020008555413    steps: 526    lr: 6.553600000000004e-08     evaluation reward: 8.49\n",
      "episode: 3185   score: 8.0   memory length: 945310   epsilon: 0.009998020008555413    steps: 425    lr: 6.553600000000004e-08     evaluation reward: 8.5\n",
      "episode: 3186   score: 5.0   memory length: 945600   epsilon: 0.009998020008555413    steps: 290    lr: 6.553600000000004e-08     evaluation reward: 8.48\n",
      "episode: 3187   score: 4.0   memory length: 945844   epsilon: 0.009998020008555413    steps: 244    lr: 6.553600000000004e-08     evaluation reward: 8.45\n",
      "episode: 3188   score: 6.0   memory length: 946168   epsilon: 0.009998020008555413    steps: 324    lr: 6.553600000000004e-08     evaluation reward: 8.32\n",
      "episode: 3189   score: 9.0   memory length: 946598   epsilon: 0.009998020008555413    steps: 430    lr: 6.553600000000004e-08     evaluation reward: 8.35\n",
      "episode: 3190   score: 7.0   memory length: 946989   epsilon: 0.009998020008555413    steps: 391    lr: 6.553600000000004e-08     evaluation reward: 8.34\n",
      "episode: 3191   score: 9.0   memory length: 947335   epsilon: 0.009998020008555413    steps: 346    lr: 6.553600000000004e-08     evaluation reward: 8.38\n",
      "episode: 3192   score: 7.0   memory length: 947711   epsilon: 0.009998020008555413    steps: 376    lr: 6.553600000000004e-08     evaluation reward: 8.34\n",
      "episode: 3193   score: 12.0   memory length: 948299   epsilon: 0.009998020008555413    steps: 588    lr: 6.553600000000004e-08     evaluation reward: 8.33\n",
      "episode: 3194   score: 15.0   memory length: 948853   epsilon: 0.009998020008555413    steps: 554    lr: 6.553600000000004e-08     evaluation reward: 8.41\n",
      "episode: 3195   score: 6.0   memory length: 949191   epsilon: 0.009998020008555413    steps: 338    lr: 6.553600000000004e-08     evaluation reward: 8.4\n",
      "episode: 3196   score: 6.0   memory length: 949530   epsilon: 0.009998020008555413    steps: 339    lr: 6.553600000000004e-08     evaluation reward: 8.4\n",
      "episode: 3197   score: 19.0   memory length: 950250   epsilon: 0.009998020008555413    steps: 720    lr: 6.553600000000004e-08     evaluation reward: 8.5\n",
      "episode: 3198   score: 10.0   memory length: 950782   epsilon: 0.009998020008555413    steps: 532    lr: 6.553600000000004e-08     evaluation reward: 8.44\n",
      "episode: 3199   score: 9.0   memory length: 951271   epsilon: 0.009998020008555413    steps: 489    lr: 6.553600000000004e-08     evaluation reward: 8.45\n",
      "episode: 3200   score: 7.0   memory length: 951659   epsilon: 0.009998020008555413    steps: 388    lr: 6.553600000000004e-08     evaluation reward: 8.46\n",
      "episode: 3201   score: 11.0   memory length: 952179   epsilon: 0.009998020008555413    steps: 520    lr: 6.553600000000004e-08     evaluation reward: 8.46\n",
      "episode: 3202   score: 22.0   memory length: 952846   epsilon: 0.009998020008555413    steps: 667    lr: 6.553600000000004e-08     evaluation reward: 8.6\n",
      "episode: 3203   score: 6.0   memory length: 953190   epsilon: 0.009998020008555413    steps: 344    lr: 6.553600000000004e-08     evaluation reward: 8.52\n",
      "episode: 3204   score: 7.0   memory length: 953553   epsilon: 0.009998020008555413    steps: 363    lr: 6.553600000000004e-08     evaluation reward: 8.5\n",
      "episode: 3205   score: 7.0   memory length: 953921   epsilon: 0.009998020008555413    steps: 368    lr: 6.553600000000004e-08     evaluation reward: 8.48\n",
      "episode: 3206   score: 7.0   memory length: 954294   epsilon: 0.009998020008555413    steps: 373    lr: 6.553600000000004e-08     evaluation reward: 8.48\n",
      "episode: 3207   score: 6.0   memory length: 954634   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 8.48\n",
      "episode: 3208   score: 7.0   memory length: 954997   epsilon: 0.009998020008555413    steps: 363    lr: 6.553600000000004e-08     evaluation reward: 8.5\n",
      "episode: 3209   score: 7.0   memory length: 955357   epsilon: 0.009998020008555413    steps: 360    lr: 6.553600000000004e-08     evaluation reward: 8.53\n",
      "episode: 3210   score: 8.0   memory length: 955793   epsilon: 0.009998020008555413    steps: 436    lr: 6.553600000000004e-08     evaluation reward: 8.49\n",
      "episode: 3211   score: 9.0   memory length: 956225   epsilon: 0.009998020008555413    steps: 432    lr: 6.553600000000004e-08     evaluation reward: 8.47\n",
      "episode: 3212   score: 7.0   memory length: 956613   epsilon: 0.009998020008555413    steps: 388    lr: 6.553600000000004e-08     evaluation reward: 8.43\n",
      "episode: 3213   score: 10.0   memory length: 957101   epsilon: 0.009998020008555413    steps: 488    lr: 6.553600000000004e-08     evaluation reward: 8.44\n",
      "episode: 3214   score: 9.0   memory length: 957551   epsilon: 0.009998020008555413    steps: 450    lr: 6.553600000000004e-08     evaluation reward: 8.49\n",
      "episode: 3215   score: 6.0   memory length: 957897   epsilon: 0.009998020008555413    steps: 346    lr: 6.553600000000004e-08     evaluation reward: 8.41\n",
      "episode: 3216   score: 7.0   memory length: 958240   epsilon: 0.009998020008555413    steps: 343    lr: 6.553600000000004e-08     evaluation reward: 8.42\n",
      "episode: 3217   score: 7.0   memory length: 958650   epsilon: 0.009998020008555413    steps: 410    lr: 6.553600000000004e-08     evaluation reward: 8.41\n",
      "episode: 3218   score: 15.0   memory length: 959191   epsilon: 0.009998020008555413    steps: 541    lr: 6.553600000000004e-08     evaluation reward: 8.52\n",
      "episode: 3219   score: 12.0   memory length: 959708   epsilon: 0.009998020008555413    steps: 517    lr: 6.553600000000004e-08     evaluation reward: 8.54\n",
      "episode: 3220   score: 9.0   memory length: 960036   epsilon: 0.009998020008555413    steps: 328    lr: 6.553600000000004e-08     evaluation reward: 8.49\n",
      "episode: 3221   score: 5.0   memory length: 960328   epsilon: 0.009998020008555413    steps: 292    lr: 6.553600000000004e-08     evaluation reward: 8.5\n",
      "episode: 3222   score: 13.0   memory length: 960862   epsilon: 0.009998020008555413    steps: 534    lr: 6.553600000000004e-08     evaluation reward: 8.55\n",
      "episode: 3223   score: 6.0   memory length: 961187   epsilon: 0.009998020008555413    steps: 325    lr: 6.553600000000004e-08     evaluation reward: 8.54\n",
      "episode: 3224   score: 8.0   memory length: 961574   epsilon: 0.009998020008555413    steps: 387    lr: 6.553600000000004e-08     evaluation reward: 8.42\n",
      "episode: 3225   score: 6.0   memory length: 961936   epsilon: 0.009998020008555413    steps: 362    lr: 6.553600000000004e-08     evaluation reward: 8.41\n",
      "episode: 3226   score: 9.0   memory length: 962384   epsilon: 0.009998020008555413    steps: 448    lr: 6.553600000000004e-08     evaluation reward: 8.46\n",
      "episode: 3227   score: 12.0   memory length: 962989   epsilon: 0.009998020008555413    steps: 605    lr: 6.553600000000004e-08     evaluation reward: 8.47\n",
      "episode: 3228   score: 5.0   memory length: 963297   epsilon: 0.009998020008555413    steps: 308    lr: 6.553600000000004e-08     evaluation reward: 8.41\n",
      "episode: 3229   score: 8.0   memory length: 963698   epsilon: 0.009998020008555413    steps: 401    lr: 6.553600000000004e-08     evaluation reward: 8.44\n",
      "episode: 3230   score: 11.0   memory length: 964263   epsilon: 0.009998020008555413    steps: 565    lr: 6.553600000000004e-08     evaluation reward: 8.43\n",
      "episode: 3231   score: 6.0   memory length: 964579   epsilon: 0.009998020008555413    steps: 316    lr: 6.553600000000004e-08     evaluation reward: 8.4\n",
      "episode: 3232   score: 5.0   memory length: 964886   epsilon: 0.009998020008555413    steps: 307    lr: 6.553600000000004e-08     evaluation reward: 8.41\n",
      "episode: 3233   score: 6.0   memory length: 965265   epsilon: 0.009998020008555413    steps: 379    lr: 6.553600000000004e-08     evaluation reward: 8.41\n",
      "episode: 3234   score: 8.0   memory length: 965711   epsilon: 0.009998020008555413    steps: 446    lr: 6.553600000000004e-08     evaluation reward: 8.41\n",
      "episode: 3235   score: 12.0   memory length: 966295   epsilon: 0.009998020008555413    steps: 584    lr: 6.553600000000004e-08     evaluation reward: 8.42\n",
      "episode: 3236   score: 4.0   memory length: 966556   epsilon: 0.009998020008555413    steps: 261    lr: 6.553600000000004e-08     evaluation reward: 8.37\n",
      "episode: 3237   score: 6.0   memory length: 966881   epsilon: 0.009998020008555413    steps: 325    lr: 6.553600000000004e-08     evaluation reward: 8.34\n",
      "episode: 3238   score: 7.0   memory length: 967289   epsilon: 0.009998020008555413    steps: 408    lr: 6.553600000000004e-08     evaluation reward: 8.31\n",
      "episode: 3239   score: 18.0   memory length: 967968   epsilon: 0.009998020008555413    steps: 679    lr: 6.553600000000004e-08     evaluation reward: 8.41\n",
      "episode: 3240   score: 13.0   memory length: 968440   epsilon: 0.009998020008555413    steps: 472    lr: 6.553600000000004e-08     evaluation reward: 8.43\n",
      "episode: 3241   score: 15.0   memory length: 969095   epsilon: 0.009998020008555413    steps: 655    lr: 6.553600000000004e-08     evaluation reward: 8.52\n",
      "episode: 3242   score: 6.0   memory length: 969423   epsilon: 0.009998020008555413    steps: 328    lr: 6.553600000000004e-08     evaluation reward: 8.51\n",
      "episode: 3243   score: 9.0   memory length: 969859   epsilon: 0.009998020008555413    steps: 436    lr: 6.553600000000004e-08     evaluation reward: 8.47\n",
      "episode: 3244   score: 11.0   memory length: 970405   epsilon: 0.009998020008555413    steps: 546    lr: 6.553600000000004e-08     evaluation reward: 8.47\n",
      "episode: 3245   score: 9.0   memory length: 970860   epsilon: 0.009998020008555413    steps: 455    lr: 6.553600000000004e-08     evaluation reward: 8.43\n",
      "episode: 3246   score: 16.0   memory length: 971511   epsilon: 0.009998020008555413    steps: 651    lr: 6.553600000000004e-08     evaluation reward: 8.52\n",
      "episode: 3247   score: 6.0   memory length: 971851   epsilon: 0.009998020008555413    steps: 340    lr: 6.553600000000004e-08     evaluation reward: 8.54\n",
      "episode: 3248   score: 4.0   memory length: 972108   epsilon: 0.009998020008555413    steps: 257    lr: 6.553600000000004e-08     evaluation reward: 8.51\n",
      "episode: 3249   score: 12.0   memory length: 972648   epsilon: 0.009998020008555413    steps: 540    lr: 6.553600000000004e-08     evaluation reward: 8.57\n",
      "episode: 3250   score: 3.0   memory length: 972859   epsilon: 0.009998020008555413    steps: 211    lr: 6.553600000000004e-08     evaluation reward: 8.5\n",
      "episode: 3251   score: 10.0   memory length: 973272   epsilon: 0.009998020008555413    steps: 413    lr: 6.553600000000004e-08     evaluation reward: 8.51\n",
      "episode: 3252   score: 20.0   memory length: 973937   epsilon: 0.009998020008555413    steps: 665    lr: 6.553600000000004e-08     evaluation reward: 8.65\n",
      "episode: 3253   score: 8.0   memory length: 974371   epsilon: 0.009998020008555413    steps: 434    lr: 6.553600000000004e-08     evaluation reward: 8.65\n",
      "episode: 3254   score: 8.0   memory length: 974771   epsilon: 0.009998020008555413    steps: 400    lr: 6.553600000000004e-08     evaluation reward: 8.65\n",
      "episode: 3255   score: 3.0   memory length: 975015   epsilon: 0.009998020008555413    steps: 244    lr: 6.553600000000004e-08     evaluation reward: 8.61\n",
      "episode: 3256   score: 9.0   memory length: 975470   epsilon: 0.009998020008555413    steps: 455    lr: 6.553600000000004e-08     evaluation reward: 8.62\n",
      "episode: 3257   score: 5.0   memory length: 975776   epsilon: 0.009998020008555413    steps: 306    lr: 6.553600000000004e-08     evaluation reward: 8.61\n",
      "episode: 3258   score: 2.0   memory length: 975974   epsilon: 0.009998020008555413    steps: 198    lr: 6.553600000000004e-08     evaluation reward: 8.55\n",
      "episode: 3259   score: 14.0   memory length: 976475   epsilon: 0.009998020008555413    steps: 501    lr: 6.553600000000004e-08     evaluation reward: 8.61\n",
      "episode: 3260   score: 10.0   memory length: 976833   epsilon: 0.009998020008555413    steps: 358    lr: 6.553600000000004e-08     evaluation reward: 8.57\n",
      "episode: 3261   score: 5.0   memory length: 977125   epsilon: 0.009998020008555413    steps: 292    lr: 6.553600000000004e-08     evaluation reward: 8.53\n",
      "episode: 3262   score: 9.0   memory length: 977582   epsilon: 0.009998020008555413    steps: 457    lr: 6.553600000000004e-08     evaluation reward: 8.56\n",
      "episode: 3263   score: 9.0   memory length: 978052   epsilon: 0.009998020008555413    steps: 470    lr: 6.553600000000004e-08     evaluation reward: 8.6\n",
      "episode: 3264   score: 15.0   memory length: 978641   epsilon: 0.009998020008555413    steps: 589    lr: 6.553600000000004e-08     evaluation reward: 8.62\n",
      "episode: 3265   score: 12.0   memory length: 979201   epsilon: 0.009998020008555413    steps: 560    lr: 6.553600000000004e-08     evaluation reward: 8.69\n",
      "episode: 3266   score: 7.0   memory length: 979561   epsilon: 0.009998020008555413    steps: 360    lr: 6.553600000000004e-08     evaluation reward: 8.7\n",
      "episode: 3267   score: 10.0   memory length: 980045   epsilon: 0.009998020008555413    steps: 484    lr: 6.553600000000004e-08     evaluation reward: 8.72\n",
      "episode: 3268   score: 15.0   memory length: 980583   epsilon: 0.009998020008555413    steps: 538    lr: 6.553600000000004e-08     evaluation reward: 8.81\n",
      "episode: 3269   score: 14.0   memory length: 981107   epsilon: 0.009998020008555413    steps: 524    lr: 6.553600000000004e-08     evaluation reward: 8.85\n",
      "episode: 3270   score: 15.0   memory length: 981741   epsilon: 0.009998020008555413    steps: 634    lr: 6.553600000000004e-08     evaluation reward: 8.93\n",
      "episode: 3271   score: 8.0   memory length: 982166   epsilon: 0.009998020008555413    steps: 425    lr: 6.553600000000004e-08     evaluation reward: 8.96\n",
      "episode: 3272   score: 14.0   memory length: 982692   epsilon: 0.009998020008555413    steps: 526    lr: 6.553600000000004e-08     evaluation reward: 8.99\n",
      "episode: 3273   score: 6.0   memory length: 983108   epsilon: 0.009998020008555413    steps: 416    lr: 6.553600000000004e-08     evaluation reward: 8.96\n",
      "episode: 3274   score: 12.0   memory length: 983652   epsilon: 0.009998020008555413    steps: 544    lr: 6.553600000000004e-08     evaluation reward: 9.01\n",
      "episode: 3275   score: 5.0   memory length: 983943   epsilon: 0.009998020008555413    steps: 291    lr: 6.553600000000004e-08     evaluation reward: 8.98\n",
      "episode: 3276   score: 15.0   memory length: 984579   epsilon: 0.009998020008555413    steps: 636    lr: 6.553600000000004e-08     evaluation reward: 9.1\n",
      "episode: 3277   score: 6.0   memory length: 984927   epsilon: 0.009998020008555413    steps: 348    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3278   score: 8.0   memory length: 985298   epsilon: 0.009998020008555413    steps: 371    lr: 6.553600000000004e-08     evaluation reward: 9.09\n",
      "episode: 3279   score: 10.0   memory length: 985801   epsilon: 0.009998020008555413    steps: 503    lr: 6.553600000000004e-08     evaluation reward: 9.03\n",
      "episode: 3280   score: 6.0   memory length: 986156   epsilon: 0.009998020008555413    steps: 355    lr: 6.553600000000004e-08     evaluation reward: 8.99\n",
      "episode: 3281   score: 8.0   memory length: 986537   epsilon: 0.009998020008555413    steps: 381    lr: 6.553600000000004e-08     evaluation reward: 9.0\n",
      "episode: 3282   score: 8.0   memory length: 986964   epsilon: 0.009998020008555413    steps: 427    lr: 6.553600000000004e-08     evaluation reward: 9.03\n",
      "episode: 3283   score: 6.0   memory length: 987335   epsilon: 0.009998020008555413    steps: 371    lr: 6.553600000000004e-08     evaluation reward: 8.99\n",
      "episode: 3284   score: 6.0   memory length: 987674   epsilon: 0.009998020008555413    steps: 339    lr: 6.553600000000004e-08     evaluation reward: 8.95\n",
      "episode: 3285   score: 14.0   memory length: 988231   epsilon: 0.009998020008555413    steps: 557    lr: 6.553600000000004e-08     evaluation reward: 9.01\n",
      "episode: 3286   score: 8.0   memory length: 988668   epsilon: 0.009998020008555413    steps: 437    lr: 6.553600000000004e-08     evaluation reward: 9.04\n",
      "episode: 3287   score: 11.0   memory length: 989116   epsilon: 0.009998020008555413    steps: 448    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3288   score: 12.0   memory length: 989721   epsilon: 0.009998020008555413    steps: 605    lr: 6.553600000000004e-08     evaluation reward: 9.17\n",
      "episode: 3289   score: 10.0   memory length: 990148   epsilon: 0.009998020008555413    steps: 427    lr: 6.553600000000004e-08     evaluation reward: 9.18\n",
      "episode: 3290   score: 12.0   memory length: 990596   epsilon: 0.009998020008555413    steps: 448    lr: 6.553600000000004e-08     evaluation reward: 9.23\n",
      "episode: 3291   score: 5.0   memory length: 990862   epsilon: 0.009998020008555413    steps: 266    lr: 6.553600000000004e-08     evaluation reward: 9.19\n",
      "episode: 3292   score: 9.0   memory length: 991309   epsilon: 0.009998020008555413    steps: 447    lr: 6.553600000000004e-08     evaluation reward: 9.21\n",
      "episode: 3293   score: 7.0   memory length: 991682   epsilon: 0.009998020008555413    steps: 373    lr: 6.553600000000004e-08     evaluation reward: 9.16\n",
      "episode: 3294   score: 9.0   memory length: 992153   epsilon: 0.009998020008555413    steps: 471    lr: 6.553600000000004e-08     evaluation reward: 9.1\n",
      "episode: 3295   score: 7.0   memory length: 992531   epsilon: 0.009998020008555413    steps: 378    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3296   score: 10.0   memory length: 993033   epsilon: 0.009998020008555413    steps: 502    lr: 6.553600000000004e-08     evaluation reward: 9.15\n",
      "episode: 3297   score: 14.0   memory length: 993616   epsilon: 0.009998020008555413    steps: 583    lr: 6.553600000000004e-08     evaluation reward: 9.1\n",
      "episode: 3298   score: 12.0   memory length: 994130   epsilon: 0.009998020008555413    steps: 514    lr: 6.553600000000004e-08     evaluation reward: 9.12\n",
      "episode: 3299   score: 8.0   memory length: 994515   epsilon: 0.009998020008555413    steps: 385    lr: 6.553600000000004e-08     evaluation reward: 9.11\n",
      "episode: 3300   score: 10.0   memory length: 995054   epsilon: 0.009998020008555413    steps: 539    lr: 6.553600000000004e-08     evaluation reward: 9.14\n",
      "episode: 3301   score: 4.0   memory length: 995317   epsilon: 0.009998020008555413    steps: 263    lr: 6.553600000000004e-08     evaluation reward: 9.07\n",
      "episode: 3302   score: 11.0   memory length: 995856   epsilon: 0.009998020008555413    steps: 539    lr: 6.553600000000004e-08     evaluation reward: 8.96\n",
      "episode: 3303   score: 10.0   memory length: 996333   epsilon: 0.009998020008555413    steps: 477    lr: 6.553600000000004e-08     evaluation reward: 9.0\n",
      "episode: 3304   score: 7.0   memory length: 996723   epsilon: 0.009998020008555413    steps: 390    lr: 6.553600000000004e-08     evaluation reward: 9.0\n",
      "episode: 3305   score: 6.0   memory length: 997042   epsilon: 0.009998020008555413    steps: 319    lr: 6.553600000000004e-08     evaluation reward: 8.99\n",
      "episode: 3306   score: 10.0   memory length: 997573   epsilon: 0.009998020008555413    steps: 531    lr: 6.553600000000004e-08     evaluation reward: 9.02\n",
      "episode: 3307   score: 7.0   memory length: 997977   epsilon: 0.009998020008555413    steps: 404    lr: 6.553600000000004e-08     evaluation reward: 9.03\n",
      "episode: 3308   score: 11.0   memory length: 998583   epsilon: 0.009998020008555413    steps: 606    lr: 6.553600000000004e-08     evaluation reward: 9.07\n",
      "episode: 3309   score: 7.0   memory length: 998989   epsilon: 0.009998020008555413    steps: 406    lr: 6.553600000000004e-08     evaluation reward: 9.07\n",
      "episode: 3310   score: 7.0   memory length: 999358   epsilon: 0.009998020008555413    steps: 369    lr: 6.553600000000004e-08     evaluation reward: 9.06\n",
      "episode: 3311   score: 13.0   memory length: 999835   epsilon: 0.009998020008555413    steps: 477    lr: 6.553600000000004e-08     evaluation reward: 9.1\n",
      "episode: 3312   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     evaluation reward: 9.11\n",
      "episode: 3313   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 470    lr: 2.6214400000000017e-08     evaluation reward: 9.13\n",
      "episode: 3314   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 626    lr: 2.6214400000000017e-08     evaluation reward: 9.16\n",
      "episode: 3315   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 362    lr: 2.6214400000000017e-08     evaluation reward: 9.17\n",
      "episode: 3316   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 574    lr: 2.6214400000000017e-08     evaluation reward: 9.23\n",
      "episode: 3317   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 343    lr: 2.6214400000000017e-08     evaluation reward: 9.22\n",
      "episode: 3318   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 487    lr: 2.6214400000000017e-08     evaluation reward: 9.17\n",
      "episode: 3319   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 619    lr: 2.6214400000000017e-08     evaluation reward: 9.18\n",
      "episode: 3320   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 326    lr: 2.6214400000000017e-08     evaluation reward: 9.14\n",
      "episode: 3321   score: 17.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 643    lr: 2.6214400000000017e-08     evaluation reward: 9.26\n",
      "episode: 3322   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 323    lr: 2.6214400000000017e-08     evaluation reward: 9.19\n",
      "episode: 3323   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 292    lr: 2.6214400000000017e-08     evaluation reward: 9.18\n",
      "episode: 3324   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 438    lr: 2.6214400000000017e-08     evaluation reward: 9.2\n",
      "episode: 3325   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     evaluation reward: 9.21\n",
      "episode: 3326   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 327    lr: 2.6214400000000017e-08     evaluation reward: 9.17\n",
      "episode: 3327   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 437    lr: 2.6214400000000017e-08     evaluation reward: 9.13\n",
      "episode: 3328   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 546    lr: 2.6214400000000017e-08     evaluation reward: 9.19\n",
      "episode: 3329   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 323    lr: 2.6214400000000017e-08     evaluation reward: 9.17\n",
      "episode: 3330   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 278    lr: 2.6214400000000017e-08     evaluation reward: 9.11\n",
      "episode: 3331   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 572    lr: 2.6214400000000017e-08     evaluation reward: 9.16\n",
      "episode: 3332   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 358    lr: 2.6214400000000017e-08     evaluation reward: 9.18\n",
      "episode: 3333   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 337    lr: 2.6214400000000017e-08     evaluation reward: 9.18\n",
      "episode: 3334   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 545    lr: 2.6214400000000017e-08     evaluation reward: 9.21\n",
      "episode: 3335   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 575    lr: 2.6214400000000017e-08     evaluation reward: 9.24\n",
      "episode: 3336   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 492    lr: 2.6214400000000017e-08     evaluation reward: 9.29\n",
      "episode: 3337   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 602    lr: 2.6214400000000017e-08     evaluation reward: 9.38\n",
      "episode: 3338   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 497    lr: 2.6214400000000017e-08     evaluation reward: 9.44\n",
      "episode: 3339   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 488    lr: 2.6214400000000017e-08     evaluation reward: 9.36\n",
      "episode: 3340   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 388    lr: 2.6214400000000017e-08     evaluation reward: 9.3\n",
      "episode: 3341   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 535    lr: 2.6214400000000017e-08     evaluation reward: 9.25\n",
      "episode: 3342   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 2.6214400000000017e-08     evaluation reward: 9.25\n",
      "episode: 3343   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 446    lr: 2.6214400000000017e-08     evaluation reward: 9.23\n",
      "episode: 3344   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 458    lr: 2.6214400000000017e-08     evaluation reward: 9.2\n",
      "episode: 3345   score: 3.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 213    lr: 2.6214400000000017e-08     evaluation reward: 9.14\n",
      "episode: 3346   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 328    lr: 2.6214400000000017e-08     evaluation reward: 9.04\n",
      "episode: 3347   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 521    lr: 2.6214400000000017e-08     evaluation reward: 9.08\n",
      "episode: 3348   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 327    lr: 2.6214400000000017e-08     evaluation reward: 9.1\n",
      "episode: 3349   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 441    lr: 2.6214400000000017e-08     evaluation reward: 9.06\n",
      "episode: 3350   score: 20.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 492    lr: 2.6214400000000017e-08     evaluation reward: 9.23\n",
      "episode: 3351   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 356    lr: 2.6214400000000017e-08     evaluation reward: 9.2\n",
      "episode: 3352   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 358    lr: 2.6214400000000017e-08     evaluation reward: 9.06\n",
      "episode: 3353   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 346    lr: 2.6214400000000017e-08     evaluation reward: 9.05\n",
      "episode: 3354   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 525    lr: 2.6214400000000017e-08     evaluation reward: 9.08\n",
      "episode: 3355   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 523    lr: 2.6214400000000017e-08     evaluation reward: 9.15\n",
      "episode: 3356   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 485    lr: 2.6214400000000017e-08     evaluation reward: 9.16\n",
      "episode: 3357   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 528    lr: 2.6214400000000017e-08     evaluation reward: 9.26\n",
      "episode: 3358   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 466    lr: 2.6214400000000017e-08     evaluation reward: 9.34\n",
      "episode: 3359   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 505    lr: 2.6214400000000017e-08     evaluation reward: 9.32\n",
      "episode: 3360   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 520    lr: 2.6214400000000017e-08     evaluation reward: 9.33\n",
      "episode: 3361   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 374    lr: 2.6214400000000017e-08     evaluation reward: 9.35\n",
      "episode: 3362   score: 3.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 226    lr: 2.6214400000000017e-08     evaluation reward: 9.29\n",
      "episode: 3363   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 420    lr: 2.6214400000000017e-08     evaluation reward: 9.28\n",
      "episode: 3364   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 371    lr: 2.6214400000000017e-08     evaluation reward: 9.2\n",
      "episode: 3365   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 9.16\n",
      "episode: 3366   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 393    lr: 2.6214400000000017e-08     evaluation reward: 9.2\n",
      "episode: 3367   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 281    lr: 2.6214400000000017e-08     evaluation reward: 9.15\n",
      "episode: 3368   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 307    lr: 2.6214400000000017e-08     evaluation reward: 9.06\n",
      "episode: 3369   score: 15.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 590    lr: 2.6214400000000017e-08     evaluation reward: 9.07\n",
      "episode: 3370   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 453    lr: 2.6214400000000017e-08     evaluation reward: 9.0\n",
      "episode: 3371   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 474    lr: 2.6214400000000017e-08     evaluation reward: 9.01\n",
      "episode: 3372   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 556    lr: 2.6214400000000017e-08     evaluation reward: 9.01\n",
      "episode: 3373   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 315    lr: 2.6214400000000017e-08     evaluation reward: 9.01\n",
      "episode: 3374   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 259    lr: 2.6214400000000017e-08     evaluation reward: 8.93\n",
      "episode: 3375   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 426    lr: 2.6214400000000017e-08     evaluation reward: 8.96\n",
      "episode: 3376   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 514    lr: 2.6214400000000017e-08     evaluation reward: 8.95\n",
      "episode: 3377   score: 3.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 226    lr: 2.6214400000000017e-08     evaluation reward: 8.92\n",
      "episode: 3378   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 357    lr: 2.6214400000000017e-08     evaluation reward: 8.9\n",
      "episode: 3379   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 552    lr: 2.6214400000000017e-08     evaluation reward: 8.91\n",
      "episode: 3380   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 353    lr: 2.6214400000000017e-08     evaluation reward: 8.92\n",
      "episode: 3381   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 376    lr: 2.6214400000000017e-08     evaluation reward: 8.9\n",
      "episode: 3382   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 278    lr: 2.6214400000000017e-08     evaluation reward: 8.86\n",
      "episode: 3383   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 360    lr: 2.6214400000000017e-08     evaluation reward: 8.87\n",
      "episode: 3384   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 354    lr: 2.6214400000000017e-08     evaluation reward: 8.87\n",
      "episode: 3385   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 590    lr: 2.6214400000000017e-08     evaluation reward: 8.87\n",
      "episode: 3386   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 612    lr: 2.6214400000000017e-08     evaluation reward: 8.93\n",
      "episode: 3387   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 478    lr: 2.6214400000000017e-08     evaluation reward: 8.91\n",
      "episode: 3388   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 374    lr: 2.6214400000000017e-08     evaluation reward: 8.85\n",
      "episode: 3389   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 370    lr: 2.6214400000000017e-08     evaluation reward: 8.82\n",
      "episode: 3390   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 328    lr: 2.6214400000000017e-08     evaluation reward: 8.76\n",
      "episode: 3391   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 424    lr: 2.6214400000000017e-08     evaluation reward: 8.79\n",
      "episode: 3392   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 395    lr: 2.6214400000000017e-08     evaluation reward: 8.77\n",
      "episode: 3393   score: 18.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 741    lr: 2.6214400000000017e-08     evaluation reward: 8.88\n",
      "episode: 3394   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 543    lr: 2.6214400000000017e-08     evaluation reward: 8.9\n",
      "episode: 3395   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 341    lr: 2.6214400000000017e-08     evaluation reward: 8.9\n",
      "episode: 3396   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 355    lr: 2.6214400000000017e-08     evaluation reward: 8.87\n",
      "episode: 3397   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 274    lr: 2.6214400000000017e-08     evaluation reward: 8.77\n",
      "episode: 3398   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 679    lr: 2.6214400000000017e-08     evaluation reward: 8.81\n",
      "episode: 3399   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 449    lr: 2.6214400000000017e-08     evaluation reward: 8.83\n",
      "episode: 3400   score: 19.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 703    lr: 2.6214400000000017e-08     evaluation reward: 8.92\n",
      "episode: 3401   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 520    lr: 2.6214400000000017e-08     evaluation reward: 8.98\n",
      "episode: 3402   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 434    lr: 2.6214400000000017e-08     evaluation reward: 8.95\n",
      "episode: 3403   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 244    lr: 2.6214400000000017e-08     evaluation reward: 8.89\n",
      "episode: 3404   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 247    lr: 2.6214400000000017e-08     evaluation reward: 8.86\n",
      "episode: 3405   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 361    lr: 2.6214400000000017e-08     evaluation reward: 8.87\n",
      "episode: 3406   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 361    lr: 2.6214400000000017e-08     evaluation reward: 8.84\n",
      "episode: 3407   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 363    lr: 2.6214400000000017e-08     evaluation reward: 8.83\n",
      "episode: 3408   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 519    lr: 2.6214400000000017e-08     evaluation reward: 8.83\n",
      "episode: 3409   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 477    lr: 2.6214400000000017e-08     evaluation reward: 8.86\n",
      "episode: 3410   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 277    lr: 2.6214400000000017e-08     evaluation reward: 8.83\n",
      "episode: 3411   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 456    lr: 2.6214400000000017e-08     evaluation reward: 8.79\n",
      "episode: 3412   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 424    lr: 2.6214400000000017e-08     evaluation reward: 8.79\n",
      "episode: 3413   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 321    lr: 2.6214400000000017e-08     evaluation reward: 8.73\n",
      "episode: 3414   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 343    lr: 2.6214400000000017e-08     evaluation reward: 8.66\n",
      "episode: 3415   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 309    lr: 2.6214400000000017e-08     evaluation reward: 8.64\n",
      "episode: 3416   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 605    lr: 2.6214400000000017e-08     evaluation reward: 8.65\n",
      "episode: 3417   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 347    lr: 2.6214400000000017e-08     evaluation reward: 8.67\n",
      "episode: 3418   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 345    lr: 2.6214400000000017e-08     evaluation reward: 8.63\n",
      "episode: 3419   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 425    lr: 2.6214400000000017e-08     evaluation reward: 8.58\n",
      "episode: 3420   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 467    lr: 2.6214400000000017e-08     evaluation reward: 8.63\n",
      "episode: 3421   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 492    lr: 2.6214400000000017e-08     evaluation reward: 8.58\n",
      "episode: 3422   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 390    lr: 2.6214400000000017e-08     evaluation reward: 8.59\n",
      "episode: 3423   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 257    lr: 2.6214400000000017e-08     evaluation reward: 8.58\n",
      "episode: 3424   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 494    lr: 2.6214400000000017e-08     evaluation reward: 8.61\n",
      "episode: 3425   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 378    lr: 2.6214400000000017e-08     evaluation reward: 8.61\n",
      "episode: 3426   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 259    lr: 2.6214400000000017e-08     evaluation reward: 8.6\n",
      "episode: 3427   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 344    lr: 2.6214400000000017e-08     evaluation reward: 8.57\n",
      "episode: 3428   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 395    lr: 2.6214400000000017e-08     evaluation reward: 8.53\n",
      "episode: 3429   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 580    lr: 2.6214400000000017e-08     evaluation reward: 8.6\n",
      "episode: 3430   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 497    lr: 2.6214400000000017e-08     evaluation reward: 8.65\n",
      "episode: 3431   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 552    lr: 2.6214400000000017e-08     evaluation reward: 8.65\n",
      "episode: 3432   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 408    lr: 2.6214400000000017e-08     evaluation reward: 8.67\n",
      "episode: 3433   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 8.69\n",
      "episode: 3434   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 507    lr: 2.6214400000000017e-08     evaluation reward: 8.69\n",
      "episode: 3435   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 466    lr: 2.6214400000000017e-08     evaluation reward: 8.64\n",
      "episode: 3436   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 597    lr: 2.6214400000000017e-08     evaluation reward: 8.69\n",
      "episode: 3437   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 424    lr: 2.6214400000000017e-08     evaluation reward: 8.62\n",
      "episode: 3438   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 359    lr: 2.6214400000000017e-08     evaluation reward: 8.55\n",
      "episode: 3439   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 497    lr: 2.6214400000000017e-08     evaluation reward: 8.54\n",
      "episode: 3440   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 502    lr: 2.6214400000000017e-08     evaluation reward: 8.58\n",
      "episode: 3441   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 340    lr: 2.6214400000000017e-08     evaluation reward: 8.54\n",
      "episode: 3442   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 633    lr: 2.6214400000000017e-08     evaluation reward: 8.61\n",
      "episode: 3443   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 454    lr: 2.6214400000000017e-08     evaluation reward: 8.63\n",
      "episode: 3444   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 507    lr: 2.6214400000000017e-08     evaluation reward: 8.64\n",
      "episode: 3445   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 477    lr: 2.6214400000000017e-08     evaluation reward: 8.7\n",
      "episode: 3446   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 685    lr: 2.6214400000000017e-08     evaluation reward: 8.8\n",
      "episode: 3447   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 434    lr: 2.6214400000000017e-08     evaluation reward: 8.78\n",
      "episode: 3448   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 386    lr: 2.6214400000000017e-08     evaluation reward: 8.8\n",
      "episode: 3449   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 563    lr: 2.6214400000000017e-08     evaluation reward: 8.84\n",
      "episode: 3450   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 630    lr: 2.6214400000000017e-08     evaluation reward: 8.76\n",
      "episode: 3451   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 588    lr: 2.6214400000000017e-08     evaluation reward: 8.83\n",
      "episode: 3452   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 425    lr: 2.6214400000000017e-08     evaluation reward: 8.86\n",
      "episode: 3453   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 455    lr: 2.6214400000000017e-08     evaluation reward: 8.88\n",
      "episode: 3454   score: 14.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 562    lr: 2.6214400000000017e-08     evaluation reward: 8.91\n",
      "episode: 3455   score: 18.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 678    lr: 2.6214400000000017e-08     evaluation reward: 8.99\n",
      "episode: 3456   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 8.97\n",
      "episode: 3457   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 435    lr: 2.6214400000000017e-08     evaluation reward: 8.94\n",
      "episode: 3458   score: 16.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 625    lr: 2.6214400000000017e-08     evaluation reward: 9.0\n",
      "episode: 3459   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 345    lr: 2.6214400000000017e-08     evaluation reward: 8.94\n",
      "episode: 3460   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 451    lr: 2.6214400000000017e-08     evaluation reward: 8.92\n",
      "episode: 3461   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 456    lr: 2.6214400000000017e-08     evaluation reward: 8.94\n",
      "episode: 3462   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 439    lr: 2.6214400000000017e-08     evaluation reward: 8.99\n",
      "episode: 3463   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 8.98\n",
      "episode: 3464   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 421    lr: 2.6214400000000017e-08     evaluation reward: 9.0\n",
      "episode: 3465   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 303    lr: 2.6214400000000017e-08     evaluation reward: 8.97\n",
      "episode: 3466   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 8.94\n",
      "episode: 3467   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 354    lr: 2.6214400000000017e-08     evaluation reward: 8.95\n",
      "episode: 3468   score: 4.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 279    lr: 2.6214400000000017e-08     evaluation reward: 8.93\n",
      "episode: 3469   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 572    lr: 2.6214400000000017e-08     evaluation reward: 8.89\n",
      "episode: 3470   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 502    lr: 2.6214400000000017e-08     evaluation reward: 8.9\n",
      "episode: 3471   score: 12.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 483    lr: 2.6214400000000017e-08     evaluation reward: 8.93\n",
      "episode: 3472   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 283    lr: 2.6214400000000017e-08     evaluation reward: 8.84\n",
      "episode: 3473   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 338    lr: 2.6214400000000017e-08     evaluation reward: 8.84\n",
      "episode: 3474   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 391    lr: 2.6214400000000017e-08     evaluation reward: 8.88\n",
      "episode: 3475   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 289    lr: 2.6214400000000017e-08     evaluation reward: 8.85\n",
      "episode: 3476   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 440    lr: 2.6214400000000017e-08     evaluation reward: 8.79\n",
      "episode: 3477   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 404    lr: 2.6214400000000017e-08     evaluation reward: 8.84\n",
      "episode: 3478   score: 5.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 290    lr: 2.6214400000000017e-08     evaluation reward: 8.83\n",
      "episode: 3479   score: 2.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 198    lr: 2.6214400000000017e-08     evaluation reward: 8.74\n",
      "episode: 3480   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 375    lr: 2.6214400000000017e-08     evaluation reward: 8.75\n",
      "episode: 3481   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 371    lr: 2.6214400000000017e-08     evaluation reward: 8.75\n",
      "episode: 3482   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 407    lr: 2.6214400000000017e-08     evaluation reward: 8.79\n",
      "episode: 3483   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 406    lr: 2.6214400000000017e-08     evaluation reward: 8.8\n",
      "episode: 3484   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 387    lr: 2.6214400000000017e-08     evaluation reward: 8.81\n",
      "episode: 3485   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 426    lr: 2.6214400000000017e-08     evaluation reward: 8.75\n",
      "episode: 3486   score: 3.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 213    lr: 2.6214400000000017e-08     evaluation reward: 8.64\n",
      "episode: 3487   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 367    lr: 2.6214400000000017e-08     evaluation reward: 8.62\n",
      "episode: 3488   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 366    lr: 2.6214400000000017e-08     evaluation reward: 8.63\n",
      "episode: 3489   score: 3.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 226    lr: 2.6214400000000017e-08     evaluation reward: 8.59\n",
      "episode: 3490   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 405    lr: 2.6214400000000017e-08     evaluation reward: 8.6\n",
      "episode: 3491   score: 11.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 540    lr: 2.6214400000000017e-08     evaluation reward: 8.63\n",
      "episode: 3492   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 492    lr: 2.6214400000000017e-08     evaluation reward: 8.64\n",
      "episode: 3493   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 484    lr: 2.6214400000000017e-08     evaluation reward: 8.55\n",
      "episode: 3494   score: 13.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 584    lr: 2.6214400000000017e-08     evaluation reward: 8.57\n",
      "episode: 3495   score: 9.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 418    lr: 2.6214400000000017e-08     evaluation reward: 8.59\n",
      "episode: 3496   score: 10.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 513    lr: 2.6214400000000017e-08     evaluation reward: 8.62\n",
      "episode: 3497   score: 6.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 324    lr: 2.6214400000000017e-08     evaluation reward: 8.64\n",
      "episode: 3498   score: 7.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 383    lr: 2.6214400000000017e-08     evaluation reward: 8.55\n",
      "episode: 3499   score: 8.0   memory length: 1000000   epsilon: 0.009998020008555413    steps: 421    lr: 2.6214400000000017e-08     evaluation reward: 8.53\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards, episodes = [], []\n",
    "best_eval_reward = 0\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    d = False\n",
    "    state = env.reset()\n",
    "    next_state = state\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "\n",
    "        # Perform a fire action if ball is no longer on screen to continue onto next life\n",
    "        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "        state = next_state\n",
    "        next_state, reward, done, info = env.step(action + 1)\n",
    "        \n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "        terminal_state = check_live(life, info['lives'])\n",
    "\n",
    "        life = info['lives']\n",
    "        r = np.clip(reward, -1, 1) \n",
    "        r = reward\n",
    "\n",
    "        # Store the transition in memory \n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "        # Start training after random sample generation\n",
    "        if(frame >= train_frame):\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network only for Double DQN only\n",
    "            if double_dqn and (frame % update_target_network_frequency)== 0:\n",
    "                agent.update_target_net()\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "            \n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.xlabel('Episodes')\n",
    "            pylab.ylabel('Rewards') \n",
    "            pylab.title('Episodes vs Reward')\n",
    "            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n",
    "            \n",
    "            # every episode, plot the play time\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
    "                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n",
    "\n",
    "            # if the mean of scores of last 100 episode is bigger than 8 save model\n",
    "            ### Change this save condition to whatever you prefer ###\n",
    "            if np.mean(evaluation_reward) >= 8 and np.mean(evaluation_reward) > best_eval_reward:\n",
    "                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n",
    "                best_eval_reward = np.mean(evaluation_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Agent Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n",
    "\n",
    "Please save your model before running this portion of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "#from gym.wrappers.monitor import Monitor\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "# Displaying the game live\n",
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "    \n",
    "# Recording the game and replaying the game afterwards\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = Display(visible=0, size=(300, 200))\n",
    "display.start()\n",
    "\n",
    "# Load agent\n",
    "# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n",
    "agent.epsilon = 0.0 # Set agent to only exploit the best action\n",
    "\n",
    "env = gym.make('BreakoutDeterministic-v5')\n",
    "env = wrap_env(env)\n",
    "\n",
    "done = False\n",
    "score = 0\n",
    "step = 0\n",
    "state = env.reset()\n",
    "next_state = state\n",
    "life = number_lives\n",
    "history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "get_init_state(history, state)\n",
    "\n",
    "while not done:\n",
    "    \n",
    "    # Render breakout\n",
    "    env.render()\n",
    "#     show_state(env,step) # uncommenting this provides another way to visualize the game\n",
    "\n",
    "    step += 1\n",
    "    frame += 1\n",
    "\n",
    "    # Perform a fire action if ball is no longer on screen\n",
    "    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "        action = 0\n",
    "    else:\n",
    "        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
    "    state = next_state\n",
    "    \n",
    "    next_state, reward, done, info = env.step(action + 1)\n",
    "        \n",
    "    frame_next_state = get_frame(next_state)\n",
    "    history[4, :, :] = frame_next_state\n",
    "    terminal_state = check_live(life, info['lives'])\n",
    "        \n",
    "    life = info['lives']\n",
    "    r = np.clip(reward, -1, 1) \n",
    "    r = reward\n",
    "\n",
    "    # Store the transition in memory \n",
    "    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "    # Start training after random sample generation\n",
    "    score += reward\n",
    "    \n",
    "    history[:4, :, :] = history[1:, :, :]\n",
    "env.close()\n",
    "show_video()\n",
    "display.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
